{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5459c28",
   "metadata": {},
   "source": [
    "### Check if loading checkpoints from remote server (Linux) works when loading locally in Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "89273efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8782f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a9e58d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[3] = \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "067a4a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[1, 3] = \"**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e95d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "32a2a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1 * \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7743090d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d23de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bbdb7309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>**</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2   3\n",
       "0  1  2  3   *\n",
       "1  4  5  6  **"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "60e83228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0b69d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_str(col):\n",
    "    if is_numeric_dtype(col):\n",
    "        return col.mean()\n",
    "    else:\n",
    "        return col.str.count(\"\\*\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cce3e659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.5, 1: 3.5, 2: 4.5, 3: 1.5}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.apply(mean_str).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d2b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625d372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bf93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_month_years(dic, dates):\n",
    "    \"\"\"Checks whether all end of month indeces in the dictionary 'dic'\n",
    "    are in the correct year. Also, checks whether all indeces are in\n",
    "    consecutive order. 31.12.2019[31.01.2020,......,31.12.2020, 31.01.2021]\n",
    "    \n",
    "    The last month of the eom indeces overlaps with the first entry in\n",
    "    the next year.\n",
    "\n",
    "    ---\n",
    "    Example:\n",
    "        If a year has 12 months in the data, the end of month indeces should \n",
    "        have length 13. The first index is the first \"row\" of the year, \n",
    "        the last index is the first row of the next year.\n",
    "    \"\"\"\n",
    "    for year in dic.keys():\n",
    "        len_dic = len(dic[year])\n",
    "        for idx, eom_idx in enumerate(dic[year]):\n",
    "            # Special case: last eom_idx is first eom_idx of next year.\n",
    "            if idx == len_dic - 1: #idx uses zero indexing.\n",
    "                if int(year) != dates[eom_idx-1].year or (idx)!= dates[eom_idx-1].month:\n",
    "                    return False\n",
    "            elif int(year) != dates[eom_idx].year or (idx+1) != dates[eom_idx].month:\n",
    "                return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ead3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "\n",
    "# Binary y label generator.\n",
    "def binary_categorize(y):\n",
    "    \"\"\"\n",
    "    Input: continuous target variable \n",
    "\n",
    "    Output: 1 for positive returns, \n",
    "            0 for negative returns\n",
    "    \"\"\"\n",
    "    # threshold 0%\n",
    "    if y > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Multiclass y label generator.\n",
    "def multi_categorize(y: float, classes: int):\n",
    "    \"\"\"\n",
    "    Creates categorical labels from continuous values.\n",
    "\n",
    "        Args:\n",
    "            y (float):      continuous target variable (option return)\n",
    "            classes (int):  number of classes to create\n",
    "        Returns:\n",
    "            (int):          class assignment\n",
    "        CAREFUL: classes have to be between [0, C) for F.crossentropyloss.\n",
    "    \"\"\"\n",
    "    if classes == 3:\n",
    "        # thresholds: +/- 5%\n",
    "        if y > 0.05:\n",
    "            return 2\n",
    "        elif y < -0.05:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    elif classes == 5:\n",
    "        # thresholds: +/- 2.5% and +/- 5%\n",
    "        if y > 0.05:\n",
    "            return 4\n",
    "        elif (y > 0.025 and y <= 0.05):\n",
    "            return 3\n",
    "        elif (y >= -0.05 and y < -0.025):\n",
    "            return 1\n",
    "        elif (y < -0.05):\n",
    "            return 0\n",
    "        else:\n",
    "            return 2 # all returns \\elin [-0.025, 0.025]\n",
    "    # elif classes==10:\n",
    "    #     if y > 0.05:\n",
    "    #         return 9\n",
    "    #     elif (y > 0.04 and y <= 0.05):\n",
    "    #         return 8\n",
    "    #     elif (y > 0.03 and y <= 0.04):\n",
    "    #         return 7\n",
    "    #     elif (y > 0.02 and y <= 0.03):\n",
    "    #         return 6\n",
    "    #     elif (y > 0.01 and y <= 0.02):\n",
    "    #         return 5\n",
    "    #     elif (y >= -0.02 and y < -0.01):\n",
    "    #         return 3\n",
    "    #     elif (y >= -0.03 and y < -0.02):\n",
    "    #         return 2\n",
    "    #     elif (y >= -0.04 and y < -0.03):\n",
    "    #         return 1\n",
    "    #     elif (y >= -0.05 and y < -0.05):\n",
    "    #         return 0\n",
    "    #     else:\n",
    "    #         return 4\n",
    "    else:\n",
    "        raise ValueError(\"Only multi for 3 or 5 classes implemented right now.\")\n",
    "\n",
    "\n",
    "class YearEndIndeces:\n",
    "    \"\"\"Generator for indices where years change.\n",
    "\n",
    "        Args:\n",
    "            dates (pandas.Series):      series of datetimes,\n",
    "            init_train_length (int):    initial train length,\n",
    "            val_length (int):           validation length\n",
    "    \"\"\"\n",
    "    def __init__(self, dates, init_train_length, val_length, test_length):\n",
    "        # Find indeces where years change.\n",
    "        self.val_length = val_length\n",
    "        self.test_length = test_length\n",
    "        # Get end of month indeces for slicing.\n",
    "        # TECHNICALLY its start of month indeces, i.e. first row of January 31,\n",
    "        # but because for slicing [:idx], idx is not included, we name it end of\n",
    "        # year here.\n",
    "        self.eoy_idx =  np.where((dates.dt.year.diff() == 1))[0]\n",
    "        # Append last row as end of year of last year.\n",
    "        self.eoy_idx = np.append(self.eoy_idx, len(dates))\n",
    "\n",
    "        assert init_train_length + val_length + test_length <= len(self.eoy_idx), \\\n",
    "            (\"defined train and val are larger than eoy_indeces generated\")\n",
    "        assert init_train_length > 0, \"init_train_length must be strictly greater than 0\"\n",
    "\n",
    "        # The 4th idx in eoy_idx is the end of year 5. -> Subtract 1.\n",
    "        self.train_length_zeroindex = init_train_length - 1\n",
    "\n",
    "        self.train_eoy = self.eoy_idx[self.train_length_zeroindex:-(val_length+test_length)]\n",
    "        self.val_eoy = self.eoy_idx[self.train_length_zeroindex + val_length:-test_length]\n",
    "        # For generate_idx():\n",
    "        self.test_eoy = self.eoy_idx[self.train_length_zeroindex + val_length + test_length:]\n",
    "\n",
    "    # def generate(self):\n",
    "    #     for i in range(len(self.eoy_idx) - (self.train_start_idx + self.val_length)):\n",
    "    #         yield (list(range(self.train_eoy[i])),\n",
    "    #                list(range(self.train_eoy[i], self.val_eoy[i])))\n",
    "\n",
    "    def generate_idx(self):\n",
    "        for i in range(len(self.eoy_idx) - (self.train_length_zeroindex + self.val_length \n",
    "                        + self.test_length)):\n",
    "            yield ({\"train\": self.train_eoy[i], \n",
    "                    \"val\": self.val_eoy[i], \n",
    "                    \"test\": self.test_eoy[i]}\n",
    "                )\n",
    "\n",
    "\n",
    "class YearMonthEndIndeces:\n",
    "    \"\"\"Generator for indices where months change.\n",
    "\n",
    "        Args:\n",
    "            dates (pandas.Series):      series of datetimes,\n",
    "            init_train_length (int):    initial train length,\n",
    "            val_length (int):           validation length\n",
    "    \"\"\"\n",
    "    def __init__(self, dates, init_train_length, val_length, test_length):\n",
    "        # self.val_length = val_length\n",
    "        # self.test_length = test_length\n",
    "        # Get end of month indeces for slicing.\n",
    "        # TECHNICALLY its start of month indeces, i.e. first row of January 31,\n",
    "        # but because for slicing [:idx], idx is not included, we name it end of\n",
    "        # year here.\n",
    "        self.eom_idx =  np.concatenate([\n",
    "                        np.where((dates.dt.month.diff() == 1))[0], \n",
    "                        np.where((dates.dt.month.diff() == -11))[0] #Dec->Jan\n",
    "                        ])\n",
    "        # Sort, since Dec->Jan months indeces are only concatenated at the end.\n",
    "        self.eom_idx.sort()\n",
    "        # Append last row as end of month of last month.\n",
    "        self.eom_idx = np.append(self.eom_idx, len(dates))\n",
    "\n",
    "        # End of year indeces\n",
    "        self.eoy_idx =  np.where((dates.dt.year.diff() == 1))[0]\n",
    "        self.eoy_idx = np.append(self.eoy_idx, len(dates))\n",
    "\n",
    "        # Careful: -2 because November (-> cao (2021) return calc.) and December 2021 is not in dataset.\n",
    "        assert (26 * 12 - 2 == len(self.eom_idx)), (\"Some end of month indeces are missing.\")\n",
    "        assert init_train_length > 0, \"init_train_length must be strictly greater than 0.\"\n",
    "\n",
    "        # The 4th idx in eoy_idx is the end of year 5. -> Subtract 1.\n",
    "        self.train_length_zeroindex = init_train_length - 1\n",
    "\n",
    "        # Get eoy indeces where we predicted on AND FIRST ENTRY IS EOY_VAL == SOY_TEST\n",
    "        self.test_eoy = self.eoy_idx[self.train_length_zeroindex + val_length:]\n",
    "\n",
    "        # Get first end of month idx of year X until first end of month of year Y\n",
    "        # a prediction was made.\n",
    "        years_predicted = np.arange(1996 + init_train_length + val_length, 2021 + 1) #upper limit not included.\n",
    "        self.month_idx_per_year = {}\n",
    "        for i, eoy_idx in enumerate(self.test_eoy[:-1]): #-1 because [last_index:last_index+13] not needed.\n",
    "            idx_in_idx = np.where(np.in1d(self.eom_idx, eoy_idx))[0].item() #only one eom_idx equals one eoy_idx\n",
    "            # + 13, so that slicing is from start of year until +12 months (end of year).\n",
    "            self.month_idx_per_year[years_predicted[i]] = self.eom_idx[idx_in_idx:idx_in_idx+13]\n",
    "\n",
    "        # Check that dictionary years are correct and that months are consecutive.\n",
    "        assert check_month_years(self.month_idx_per_year, dates=dates), (\"Years of end \"\n",
    "        \"of month indices are wrong or the months are not consecutive.\")\n",
    "\n",
    "    def get_indeces(self):\n",
    "        # Return Tuple.\n",
    "        return (self.test_eoy, self.month_idx_per_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    \"\"\"Dataset Loader for Pytorch Lightning (Neural Network).\"\"\"\n",
    "    def __init__(self,\n",
    "                 path: str, # will be converted to Path in __init__\n",
    "                 year_idx: int,\n",
    "                 dataset: str,\n",
    "                 batch_size: int,\n",
    "                 init_train_length: int,\n",
    "                 val_length: int,\n",
    "                 test_length: int,\n",
    "                #  start_val: str, \n",
    "                #  start_test: str,\n",
    "                 label_fn: str,\n",
    "                 custom_data: pd.DataFrame = None,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"path\"])\n",
    "        \n",
    "        # If the data is provided at initialization, use it. (E.g. used in feature importance)\n",
    "        if custom_data is not None:\n",
    "            self.data = custom_data\n",
    "        else:\n",
    "            path = Path(path)\n",
    "            self.data = load_data(path, dataset)\n",
    "\n",
    "        # Get year train, val, test split indeces.\n",
    "        splitter = YearEndIndeces(\n",
    "                                self.data[\"date\"], \n",
    "                                init_train_length=init_train_length, \n",
    "                                val_length=val_length,\n",
    "                                test_length=test_length,\n",
    "                                )\n",
    "        eoy_indeces = list(splitter.generate_idx())\n",
    "        self.eoy_train = eoy_indeces[year_idx][\"train\"]\n",
    "        self.eoy_val = eoy_indeces[year_idx][\"val\"]\n",
    "        self.eoy_test = eoy_indeces[year_idx][\"test\"]\n",
    "\n",
    "        # Truncate data to only use current train, val and test.\n",
    "        self.data = self.data.iloc[:self.eoy_test]\n",
    "        assert len(self.data) == self.eoy_test, \"length of data is not equal to eoy_test\"\n",
    "            \n",
    "        # # feature engineer data\n",
    "        # self.data = feature_engineer(self.data)\n",
    "        \n",
    "        # Get the y vector.\n",
    "        self.y = self.data[\"option_ret\"]\n",
    "        # Classify returns (floats) into classes.\n",
    "        if label_fn == \"binary\":\n",
    "            self.y = self.y.apply(binary_categorize)\n",
    "        elif label_fn == \"multi3\":\n",
    "            self.y = self.y.apply(multi_categorize, classes=3)\n",
    "        elif label_fn == \"multi5\":\n",
    "            self.y = self.y.apply(multi_categorize, classes=5)\n",
    "        else:\n",
    "            raise ValueError(\"Specify label_fn as either 'binary' or 'multi'\")\n",
    "        # Get the features X.\n",
    "        self.X = self.data.drop([\"option_ret\"], axis=1)\n",
    "        \n",
    "        # Save dates and drop it from X.\n",
    "        self.dates = self.X[\"date\"]\n",
    "        self.X = self.X.drop([\"date\"], axis=1)\n",
    "        \n",
    "        # Convert X and y to torch tensors (for GPU).\n",
    "        self.X = torch.from_numpy(self.X.values).float() #-> will be standardized in setup, so do it there.\n",
    "        self.y = torch.from_numpy(self.y.values)\n",
    "        \n",
    "    def setup(self, stage: str = None):\n",
    "        # Training data.\n",
    "        # self.X_train = self.X[self.dates < self.hparams.start_val]\n",
    "        self.X_train = self.X[:self.eoy_train]\n",
    "        self.y_train = self.y[:len(self.X_train)]\n",
    "        \n",
    "        # Validation data.\n",
    "        # mask = (self.dates >= self.hparams.start_val) & (self.dates < self.hparams.start_test)\n",
    "        # self.X_val = self.X[mask]\n",
    "        self.X_val = self.X[self.eoy_train:self.eoy_val]\n",
    "        self.y_val = self.y[len(self.X_train):len(self.X_train)+len(self.X_val)]\n",
    "        \n",
    "        # Test data.\n",
    "        self.X_test = self.X[self.eoy_val:self.eoy_test]\n",
    "        self.y_test = self.y[-len(self.X_test):]\n",
    "        \n",
    "        assert (len(self.X_train)+len(self.X_val)+len(self.X_test)) == len(self.data), \\\n",
    "            \"sum of X train, val, test is not equal length of dataset\"\n",
    "        assert (len(self.y_train)+len(self.y_val)+len(self.y_test) == len(self.data)), \\\n",
    "        \"sum of y train, val, test is not equal to length of dataset\"\n",
    "        \n",
    "        # Get mean and std of X_train.\n",
    "        mean = torch.mean(self.X_train, axis=0)\n",
    "        std = torch.std(self.X_train, axis=0)\n",
    "        \n",
    "        # Standardize X_train, X_val and X_test with mean/std from X_train.\n",
    "        self.X_train = (self.X_train - mean) / std\n",
    "        self.X_val = (self.X_val - mean) / std\n",
    "        self.X_test = (self.X_test - mean) / std\n",
    "\n",
    "        # Save important variables to pass to model class.\n",
    "        # Input dim of features (int).\n",
    "        self.input_dim = self.X_train.shape[1]\n",
    "        # Number of classes (int).\n",
    "        self.num_classes = len(self.y_train.unique())\n",
    "        # Class weights (torch.tensor).\n",
    "        self.class_weights = len(self.y_train) / self.y_train.unique(return_counts=True)[1]\n",
    "\n",
    "        if self.hparams.custom_data is None:\n",
    "            print(\"*****************************************************************************************\")\n",
    "            print(\"Current TORCH dataset information:\")\n",
    "            print(\"---\")\n",
    "            print(\"class counts: \", self.y_train.unique(return_counts=True))\n",
    "            print(\"class_weights:\", self.class_weights)\n",
    "            print(\"device of class_weights:\", self.class_weights.device)\n",
    "            print(\"---\")\n",
    "            print(f\"# of input data: {len(self.data)} with shape: {self.data.shape}\")\n",
    "            print(f\"# of training samples: {len(self.y_train)} with X_train of shape: {self.X_train.shape}\")\n",
    "            print(f\"# of validation samples: {len(self.y_val)} with X_val of shape: {self.X_val.shape}\")\n",
    "            print(f\"# of test samples: {len(self.y_test)} with X_test of shape: {self.X_test.shape}\")\n",
    "            print(\"---\")\n",
    "            print(f\"train start date: \", self.dates.iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "                \", train end date: \", self.dates.iloc[:self.eoy_train].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "            print(f\"val start date: \", self.dates.iloc[self.eoy_train:self.eoy_val].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "                \", val end date: \", self.dates.iloc[self.eoy_train:self.eoy_val].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "            print(f\"test start date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "                \", test end date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "            print(\"*****************************************************************************************\")\n",
    "        else:\n",
    "            print(\"*****************************************************************************************\")\n",
    "            print(f\"test start date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "                \", test end date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "\n",
    "\n",
    "    def example(self):\n",
    "        \"\"\"Returns a random training example.\"\"\"        \n",
    "        idx = np.random.randint(0, len(self.X_train))\n",
    "        x, y = self.X_train[idx], self.y_train[idx]\n",
    "        return (x, y)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size,\n",
    "                         num_workers=0, #uses just the main worker, see https://stackoverflow.com/questions/71713719/runtimeerror-dataloader-worker-pids-15876-2756-exited-unexpectedly\n",
    "                         # there are issues occuring on windows where PID workers exit unexpectedly.\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True, #shuffle training data\n",
    "                         )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(self.X_val, self.y_val)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size,\n",
    "                         num_workers=0,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=False,\n",
    "                         )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = TensorDataset(self.X_test, self.y_test)\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size,\n",
    "                         num_workers=0,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=False, #must not shuffle here!\n",
    "                         )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        dataset = self.X_test # predict_step expects tensor not a list\n",
    "        return DataLoader(dataset, batch_size=self.hparams.batch_size,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=True,\n",
    "                        shuffle=False, #must not shuffle here!\n",
    "                        )\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"DataModule for Lightning\")\n",
    "        parser.add_argument(\"--batch_size\", type=int, default=512)\n",
    "        return parent_parser\n",
    "\n",
    "\n",
    "#****************************************************************************************\n",
    "\n",
    "class Dataset():\n",
    "    \"\"\"Dataset for non-torch classifiers. Provides train, val and test set\n",
    "    in numpy. Can also output predefinded cv splits for gridsearch.\"\"\"\n",
    "    def __init__(self, \n",
    "                path: str, \n",
    "                year_idx: int, \n",
    "                dataset: str, \n",
    "                init_train_length: int, \n",
    "                val_length: int,\n",
    "                test_length: int,\n",
    "                label_fn: str,\n",
    "                custom_data: pd.DataFrame = None,\n",
    "                ):\n",
    "        \n",
    "        # If the data is provided at initialization, use it. (E.g. used in feature importance)\n",
    "        if custom_data is not None:\n",
    "            self.data = custom_data\n",
    "        else:\n",
    "            path = Path(path)\n",
    "            self.data = load_data(path, dataset)\n",
    "\n",
    "        # Get year train, val, test split indeces.\n",
    "        splitter = YearEndIndeces(\n",
    "                                self.data[\"date\"], \n",
    "                                init_train_length=init_train_length, \n",
    "                                val_length=val_length, \n",
    "                                test_length=test_length,\n",
    "                                )\n",
    "        eoy_indeces = list(splitter.generate_idx())\n",
    "        self.eoy_train = eoy_indeces[year_idx][\"train\"]\n",
    "        self.eoy_val = eoy_indeces[year_idx][\"val\"]\n",
    "        self.eoy_test = eoy_indeces[year_idx][\"test\"]\n",
    "        \n",
    "        # Truncate data to only use train, val and current test.\n",
    "        self.data = self.data.iloc[:self.eoy_test]\n",
    "        assert len(self.data) == self.eoy_test, \"length of data is not equal to eoy_test\"\n",
    "            \n",
    "        # feature engineer data\n",
    "        # self.data = feature_engineer(self.data)\n",
    "        \n",
    "        # Get the y vector.\n",
    "        self.y = self.data[\"option_ret\"]\n",
    "        # Classify returns (floats) into classes.\n",
    "        if label_fn == \"binary\":\n",
    "            self.y = self.y.apply(binary_categorize)\n",
    "        elif label_fn == \"multi3\":\n",
    "            self.y = self.y.apply(multi_categorize, classes=3)\n",
    "        elif label_fn == \"multi5\":\n",
    "            self.y = self.y.apply(multi_categorize, classes=5)\n",
    "        else:\n",
    "            raise ValueError(\"Specify label_fn as either 'binary' or 'multi'\")\n",
    "        # Get the features X.\n",
    "        self.X = self.data.drop([\"option_ret\"], axis=1)\n",
    "        \n",
    "        # Save dates and drop it from X.\n",
    "        self.dates = self.X[\"date\"]\n",
    "        self.X = self.X.drop([\"date\"], axis=1)\n",
    "        \n",
    "#         # to torch Tensor\n",
    "#         self.X = torch.from_numpy(self.X.values).float() #-> will be standardized in setup, so do it there.\n",
    "#         self.y = torch.from_numpy(self.y.values)\n",
    "\n",
    "        # Convert X and y to numpy arrays.\n",
    "        self.X = self.X.values #-> will be standardized in setup, so do it there.\n",
    "        self.y = self.y.values\n",
    "    \n",
    "        ############################### setup #########################################################\n",
    "        # Training data.\n",
    "        self.X_train = self.X[:self.eoy_train]\n",
    "        self.y_train = self.y[:len(self.X_train)]\n",
    "        \n",
    "        # Validation data.\n",
    "        self.X_val = self.X[self.eoy_train:self.eoy_val]\n",
    "        self.y_val = self.y[len(self.X_train):len(self.X_train)+len(self.X_val)]\n",
    "        \n",
    "        # Test data.\n",
    "        self.X_test = self.X[self.eoy_val:self.eoy_test]\n",
    "        self.y_test = self.y[-len(self.X_test):]\n",
    "        \n",
    "        assert (len(self.X_train)+len(self.X_val)+len(self.X_test)) == len(self.data), \\\n",
    "            \"sum of X train, val, test is not equal length of dataset\"\n",
    "        assert (len(self.y_train)+len(self.y_val)+len(self.y_test) == len(self.data)), \\\n",
    "        \"sum of y train, val, test is not equal to length of dataset\"\n",
    "\n",
    "        \n",
    "        # --> StandardScaler is instead used!\n",
    "#         #standardize X_train\n",
    "#         mean = torch.mean(self.X_train, axis=0)\n",
    "#         std = torch.std(self.X_train, axis=0)\n",
    "        \n",
    "#         # Standardize X_train, X_val and X_test with mean/std from X_train\n",
    "#         self.X_train = (self.X_train - mean) / std\n",
    "#         self.X_val = (self.X_val - mean) / std\n",
    "#         self.X_test = (self.X_test - mean) / std\n",
    "\n",
    "        # Save variables\n",
    "        # Input dim of features (int).\n",
    "        self.input_dim = self.X_train.shape[1]\n",
    "        # Number of classes (int).\n",
    "        self.num_classes = len(np.unique(self.y_train))\n",
    "\n",
    "        # Class weights (dict).\n",
    "        # self.class_weights = len(self.y_train) / np.unique(self.y_train, return_counts=True)[1]\n",
    "        # calculate \"balanced\" class weights manually (class_weight=\"balanced\" not possible for TuneSearch)\n",
    "        weights = compute_class_weight('balanced', classes=np.unique(self.y_train), y=self.y_train)\n",
    "        labels = np.unique(self.y_train)\n",
    "        self.class_weights = {}\n",
    "        for i in range(len(labels)):\n",
    "            self.class_weights[labels[i]] = weights[i]\n",
    "\n",
    "        if custom_data is None:\n",
    "            print(\"*****************************************************************************************\")\n",
    "            print(\"Current NUMPY dataset information:\")\n",
    "            print(\"---\")\n",
    "            print(\"class counts: \", np.unique(self.y_train, return_counts=True))\n",
    "            print(\"class_weights:\", self.class_weights)\n",
    "            print(\"---\")\n",
    "            print(f\"# of input data: {len(self.data)} with shape: {self.data.shape}\")\n",
    "            print(f\"# of training samples: {len(self.y_train)} with X_train of shape: {self.X_train.shape}\")\n",
    "            print(f\"# of validation samples: {len(self.y_val)} with X_val of shape: {self.X_val.shape}\")\n",
    "            print(f\"# of test samples: {len(self.y_test)} with X_test of shape: {self.X_test.shape}\")\n",
    "            print(\"---\")\n",
    "            print(f\"train start date: \", self.dates.iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "                \", train end date: \", self.dates.iloc[:self.eoy_train].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "            print(f\"val start date: \", self.dates.iloc[self.eoy_train:self.eoy_val].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "                \", val end date: \", self.dates.iloc[self.eoy_train:self.eoy_val].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "            print(f\"test start date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "                \", test end date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "            print(\"*****************************************************************************************\")\n",
    "        else:\n",
    "            print(\"*****************************************************************************************\")\n",
    "            print(f\"test start date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "                \", test end date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "            print(\"*****************************************************************************************\")\n",
    "        \n",
    "    def get_datasets(self):\n",
    "        return self.X_train, self.X_val, self.X_test\n",
    "    \n",
    "    def get_cv_data(self):\n",
    "        \"\"\"For scikitlearn classifiers: return datasets and predefined cv split \n",
    "        needed for gridsearchcv (only 1 train/val split)\"\"\"\n",
    "        # careful: if predicting on X_val later... -> cheating\n",
    "        X = np.concatenate((self.X_train, self.X_val))\n",
    "        y = np.concatenate((self.y_train, self.y_val))\n",
    "        ps = PredefinedSplit(np.concatenate((np.zeros(len(self.X_train)) - 1, np.ones(len(self.X_val)))))\n",
    "        \n",
    "        assert (self.X_train.shape[0] + self.X_val.shape[0] == X.shape[0] and \n",
    "                (self.X_train.shape[1] == self.X_val.shape[1] == X.shape[1]))\n",
    "        assert ps.get_n_splits() == 1, \"There should only be 1 train/ val split in PredefinedSplit.\"\n",
    "        \n",
    "        return X, y, ps\n",
    "\n",
    "    def get_train_val(self):\n",
    "        \"\"\"Used in xgboost trainer.\"\"\"\n",
    "        return self.X_train, self.X_val, self.y_train, self.y_val\n",
    "\n",
    "    def get_test(self):\n",
    "        return self.X_test, self.y_test\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"Dataset for Scikitlearn + xgboost\")\n",
    "        # parser.add_argument(\"--batch_size\", type=int, default=512)\n",
    "        return parent_parser\n",
    "\n",
    "\n",
    "def load_data(path_data: Path, dataset: str):\n",
    "    \"\"\"Loads specific dataset from path, depending on specified size.\"\"\"\n",
    "    if dataset == \"small\":\n",
    "        return pd.read_parquet(path_data/\"final_df_call_cao_small.parquet\")\n",
    "    elif dataset == \"medium\":\n",
    "        return pd.read_parquet(path_data/\"final_df_call_cao_med_fillmean.parquet\")\n",
    "    elif dataset == \"big\":\n",
    "        return pd.read_parquet(path_data/\"final_df_call_cao_big_fillmean.parquet\")\n",
    "    else:\n",
    "        raise ValueError(\"Specify dataset as either 'small', 'medium' or big'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e486ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class FFN(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                input_dim: int,\n",
    "                num_classes: int,\n",
    "                class_weights: torch.Tensor,\n",
    "                no_class_weights: bool,\n",
    "                learning_rate: float,\n",
    "                hidden_dim: int,\n",
    "                n_hidden: int,\n",
    "                batch_norm: bool,\n",
    "                dropout: bool,\n",
    "                drop_prob: float,\n",
    "                # config: dict = None,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        # Init variables are saved, so that model can be reloaded cleanly if necessary\n",
    "        # self.save_hyperparameters(ignore=[\"class_weights\"])\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        middle_layers = []\n",
    "        for _ in range(self.hparams.n_hidden):\n",
    "            middle_layers.append(nn.Linear(self.hparams.hidden_dim, self.hparams.hidden_dim))\n",
    "            if self.hparams.batch_norm:\n",
    "                middle_layers.append(nn.BatchNorm1d(self.hparams.hidden_dim))\n",
    "            middle_layers.append(nn.ReLU(inplace=True))\n",
    "            if self.hparams.dropout:\n",
    "                middle_layers.append(nn.Dropout(p=self.hparams.drop_prob))\n",
    "\n",
    "        #model\n",
    "        self.first = nn.Sequential(nn.Linear(self.hparams.input_dim, self.hparams.hidden_dim), \n",
    "                                    nn.ReLU(inplace=True))\n",
    "        self.middle = nn.Sequential(*middle_layers)  \n",
    "        self.last = nn.Linear(self.hparams.hidden_dim, self.hparams.num_classes)\n",
    "        \n",
    "        #sample weights\n",
    "        if not self.hparams.no_class_weights:\n",
    "            self.class_weights = class_weights\n",
    "            self.class_weights = self.class_weights.cuda() # Move to cuda, otherwise mismatch of devices # in train/val\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        # print(\"---\")\n",
    "        # print(\"class_weights:\", self.class_weights)\n",
    "        # print(\"device of class_weights:\", self.class_weights.device)\n",
    "        # print(\"device of class:\", self.device)\n",
    "        # print(\"---\")\n",
    "\n",
    "        #metrics\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.train_bal_acc = torchmetrics.Accuracy(\n",
    "        num_classes=self.hparams.num_classes, average=\"macro\") # should be equal to sklearn bal. acc.\n",
    "\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "        self.val_bal_acc= torchmetrics.Accuracy(\n",
    "            num_classes=self.hparams.num_classes, average=\"macro\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.last(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x) #logits\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y, weight=self.class_weights)\n",
    "        # Logging is done \"log_every_n_steps\" times (default=50 steps)\n",
    "        self.log(\"loss/loss\", loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        \n",
    "        self.train_acc(y_hat, y)\n",
    "        self.log(\"acc/train\", self.train_acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        self.train_bal_acc(y_hat, y)\n",
    "        self.log(\"bal_acc/train\", self.train_bal_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x) #logits\n",
    "        \n",
    "#         self.log(\"hp_metric\", torch.mean(y_hat.argmax(dim=-1).float()).item(), prog_bar=True) # average prediction class\n",
    "        self.log(\"mean_pred\", torch.mean(y_hat.argmax(dim=-1).float()).item(), prog_bar=True)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y, weight=self.class_weights)\n",
    "        self.log(\"loss/val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        self.val_acc(y_hat, y)\n",
    "        self.log(\"acc/val\", self.val_acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        self.val_bal_acc(y_hat, y)\n",
    "        self.log(\"bal_acc/val\", self.val_bal_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return {\"val_loss\": loss}\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        self.st_total = time.time()\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.st = time.time()\n",
    "        self.steps = self.global_step\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        elapsed = time.time() - self.st\n",
    "        steps_done = self.global_step - self.steps\n",
    "        self.log(\"time/step\", elapsed / steps_done)\n",
    "\n",
    "    def on_train_end(self):\n",
    "        elapsed = time.time() - self.st_total\n",
    "        print(f\"Total Training Time: {time.strftime('%H:%M:%S', time.gmtime(elapsed))}\")\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y, weight=self.class_weights)\n",
    "\n",
    "        self.log(\"loss/test_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        return self(batch)\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"FFN\")\n",
    "        parser.add_argument(\"--no_class_weights\", action='store_true')\n",
    "        parser.add_argument(\"--hidden_dim\", type=int, default=100)\n",
    "        parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=1e-2)\n",
    "        parser.add_argument(\"--n_hidden\", type=int, default=0)\n",
    "        parser.add_argument(\"--no_batch_norm\", action='store_false')\n",
    "        parser.add_argument(\"--no_dropout\", action='store_false')\n",
    "        parser.add_argument(\"--drop_prob\", type=float, default=0.5)\n",
    "\n",
    "        return parent_parser\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestmodelpath = Path(r\"C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\data\\20220908133630\\train2006_val2008\")/\"best_ckpt2009\"\n",
    "bestmodelpath = Path(r\"C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\data\\20220908133630\\train2018_val2020\")/\"best_ckpt2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFN.load_from_checkpoint(bestmodelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11b959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399af45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFN.load_from_checkpoint(bestmodelpath)\n",
    "dm = DataModule(\n",
    "    path=r\"C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\data\", #Set to None.\n",
    "    year_idx=0, #Important.\n",
    "    dataset=\"small\", #Set to None.\n",
    "    batch_size=100000000, #Predict in one step.\n",
    "    init_train_length=10,\n",
    "    val_length=2,\n",
    "    test_length=1,\n",
    "    label_fn=\"multi5\",\n",
    "    custom_data=None, #Provide data directly.\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    deterministic=True,\n",
    "    gpus=1, #gpu fixed to be one here.\n",
    "    logger=False, #deactivate logging for prediction\n",
    "    enable_progress_bar=False,\n",
    ")\n",
    "# Predict.\n",
    "preds = trainer.predict(model=model, datamodule=dm) #returns list of batch predictions.\n",
    "preds = torch.cat(preds) #preds is a list already of [batch_size, num_classes]. \n",
    "preds_argmax = preds.argmax(dim=1).numpy()\n",
    "preds_argmax_df = pd.DataFrame(preds_argmax, columns=[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_argmax_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac224eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
