{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(r\"C:\\Users\\Mathiass\\OneDrive - Universität Zürich UZH\\Documents\\mt_literature\\data\\VIX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix = pd.read_csv(path/\"VIX_History.csv\", parse_dates=[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-04</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01-05</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01-08</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171</th>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>26.26</td>\n",
       "      <td>29.63</td>\n",
       "      <td>26.05</td>\n",
       "      <td>27.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8172</th>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>31.37</td>\n",
       "      <td>35.05</td>\n",
       "      <td>31.29</td>\n",
       "      <td>34.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8173</th>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>33.01</td>\n",
       "      <td>34.00</td>\n",
       "      <td>32.06</td>\n",
       "      <td>32.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>32.39</td>\n",
       "      <td>32.77</td>\n",
       "      <td>27.76</td>\n",
       "      <td>29.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>30.35</td>\n",
       "      <td>34.82</td>\n",
       "      <td>30.35</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE   OPEN   HIGH    LOW  CLOSE\n",
       "0    1990-01-02  17.24  17.24  17.24  17.24\n",
       "1    1990-01-03  18.19  18.19  18.19  18.19\n",
       "2    1990-01-04  19.22  19.22  19.22  19.22\n",
       "3    1990-01-05  20.11  20.11  20.11  20.11\n",
       "4    1990-01-08  20.26  20.26  20.26  20.26\n",
       "...         ...    ...    ...    ...    ...\n",
       "8171 2022-06-10  26.26  29.63  26.05  27.75\n",
       "8172 2022-06-13  31.37  35.05  31.29  34.02\n",
       "8173 2022-06-14  33.01  34.00  32.06  32.69\n",
       "8174 2022-06-15  32.39  32.77  27.76  29.62\n",
       "8175 2022-06-16  30.35  34.82  30.35  32.95\n",
       "\n",
       "[8176 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  21,   40,   62,   82,  104,  125,  146,  169,  188,  211,  232,\n",
       "        274,  293,  312,  334,  356,  376,  398,  420,  440,  463,  483,\n",
       "        526,  545,  567,  588,  608,  630,  652,  673,  694,  716,  736,\n",
       "        778,  797,  820,  841,  861,  883,  904,  926,  947,  968,  989,\n",
       "       1032, 1051, 1074, 1093, 1114, 1136, 1156, 1179, 1200, 1221, 1242,\n",
       "       1284, 1303, 1326, 1345, 1367, 1389, 1409, 1432, 1452, 1474, 1495,\n",
       "       1537, 1557, 1578, 1599, 1621, 1641, 1663, 1685, 1705, 1728, 1748,\n",
       "       1790, 1809, 1829, 1851, 1872, 1893, 1915, 1936, 1957, 1980, 1998,\n",
       "       2040, 2059, 2081, 2102, 2122, 2144, 2166, 2187, 2208, 2230, 2250,\n",
       "       2291, 2310, 2333, 2354, 2374, 2396, 2417, 2439, 2460, 2481, 2502,\n",
       "       2543, 2563, 2586, 2605, 2627, 2649, 2669, 2692, 2712, 2734, 2755,\n",
       "       2796, 2815, 2837, 2857, 2879, 2900, 2921, 2944, 2959, 2982, 3003,\n",
       "       3044, 3063, 3083, 3105, 3127, 3147, 3169, 3191, 3211, 3234, 3254,\n",
       "       3296, 3315, 3336, 3357, 3378, 3399, 3421, 3442, 3463, 3486, 3505,\n",
       "       3547, 3566, 3589, 3610, 3630, 3652, 3673, 3695, 3716, 3737, 3758,\n",
       "       3800, 3819, 3841, 3862, 3883, 3905, 3925, 3948, 3969, 3990, 4011,\n",
       "       4052, 4071, 4094, 4113, 4134, 4156, 4176, 4199, 4219, 4241, 4262,\n",
       "       4302, 4321, 4343, 4363, 4385, 4406, 4427, 4450, 4469, 4492, 4513,\n",
       "       4554, 4574, 4594, 4616, 4637, 4658, 4680, 4701, 4722, 4745, 4764,\n",
       "       4806, 4825, 4847, 4868, 4888, 4910, 4932, 4953, 4974, 4996, 5016,\n",
       "       5057, 5076, 5099, 5120, 5140, 5162, 5183, 5205, 5226, 5247, 5268,\n",
       "       5310, 5329, 5352, 5372, 5393, 5415, 5435, 5458, 5479, 5500, 5521,\n",
       "       5562, 5582, 5604, 5624, 5646, 5667, 5688, 5711, 5730, 5751, 5772,\n",
       "       5813, 5832, 5852, 5874, 5896, 5916, 5938, 5960, 5980, 6003, 6023,\n",
       "       6065, 6084, 6105, 6126, 6147, 6168, 6190, 6211, 6232, 6255, 6274,\n",
       "       6316, 6335, 6357, 6378, 6398, 6420, 6442, 6463, 6484, 6506, 6526,\n",
       "       6567, 6587, 6609, 6630, 6651, 6673, 6693, 6716, 6737, 6758, 6779,\n",
       "       6820, 6839, 6862, 6881, 6903, 6925, 6945, 6968, 6988, 7010, 7031,\n",
       "       7072, 7091, 7112, 7133, 7155, 7176, 7197, 7220, 7239, 7262, 7283,\n",
       "       7323, 7342, 7363, 7384, 7406, 7426, 7448, 7470, 7490, 7513, 7533,\n",
       "       7575, 7594, 7616, 7637, 7657, 7679, 7701, 7722, 7743, 7765, 7785,\n",
       "       7826, 7845, 7868, 7889, 7909, 7931, 7952, 7974, 7995, 8016, 8037,\n",
       "       8079, 8098, 8121, 8141, 8163], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(vix[\"DATE\"].dt.month.diff() == 1)[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vix.iloc[np.where(vix[\"DATE\"].dt.month.diff() == 1)[0] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index(\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-31</th>\n",
       "      <td>25.36</td>\n",
       "      <td>25.36</td>\n",
       "      <td>25.36</td>\n",
       "      <td>25.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-02-28</th>\n",
       "      <td>21.99</td>\n",
       "      <td>21.99</td>\n",
       "      <td>21.99</td>\n",
       "      <td>21.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-03-30</th>\n",
       "      <td>19.73</td>\n",
       "      <td>19.73</td>\n",
       "      <td>19.73</td>\n",
       "      <td>19.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-04-30</th>\n",
       "      <td>19.52</td>\n",
       "      <td>19.52</td>\n",
       "      <td>19.52</td>\n",
       "      <td>19.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-31</th>\n",
       "      <td>17.37</td>\n",
       "      <td>17.37</td>\n",
       "      <td>17.37</td>\n",
       "      <td>17.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-31</th>\n",
       "      <td>28.36</td>\n",
       "      <td>29.41</td>\n",
       "      <td>24.71</td>\n",
       "      <td>24.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28</th>\n",
       "      <td>32.44</td>\n",
       "      <td>33.51</td>\n",
       "      <td>28.43</td>\n",
       "      <td>30.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>19.68</td>\n",
       "      <td>21.48</td>\n",
       "      <td>19.54</td>\n",
       "      <td>20.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-29</th>\n",
       "      <td>28.97</td>\n",
       "      <td>34.34</td>\n",
       "      <td>28.54</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>27.47</td>\n",
       "      <td>28.35</td>\n",
       "      <td>25.94</td>\n",
       "      <td>26.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             OPEN   HIGH    LOW  CLOSE\n",
       "DATE                                  \n",
       "1990-01-31  25.36  25.36  25.36  25.36\n",
       "1990-02-28  21.99  21.99  21.99  21.99\n",
       "1990-03-30  19.73  19.73  19.73  19.73\n",
       "1990-04-30  19.52  19.52  19.52  19.52\n",
       "1990-05-31  17.37  17.37  17.37  17.37\n",
       "...           ...    ...    ...    ...\n",
       "2022-01-31  28.36  29.41  24.71  24.83\n",
       "2022-02-28  32.44  33.51  28.43  30.15\n",
       "2022-03-31  19.68  21.48  19.54  20.56\n",
       "2022-04-29  28.97  34.34  28.54  33.40\n",
       "2022-05-31  27.47  28.35  25.94  26.19\n",
       "\n",
       "[357 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index = test.index + MonthEnd(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "1990-01-31    25.36\n",
       "1990-02-28    21.99\n",
       "1990-03-31    19.73\n",
       "1990-04-30    19.52\n",
       "1990-05-31    17.37\n",
       "              ...  \n",
       "2022-01-31    24.83\n",
       "2022-02-28    30.15\n",
       "2022-03-31    20.56\n",
       "2022-04-30    33.40\n",
       "2022-05-31    26.19\n",
       "Name: CLOSE, Length: 357, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"CLOSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix.iloc[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            ...\n",
       "            6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "           dtype='int64', name='DATE', length=8176)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\logs\\tune\\transformer_loops\\20220902144538\\train2018_val2020\"\n",
    "path = Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_transf_ckpt(loop_dir: Path):\n",
    "    \"\"\"Delete transformer model checkpoints after saving best, to not overload drive storage.\"\"\"\n",
    "    for file in loop_dir.iterdir():\n",
    "        if file.is_dir():\n",
    "#             print(file)\n",
    "            del_ckpt(file) #recursion\n",
    "        else:\n",
    "            if file.name == \"checkpoint\":\n",
    "                file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_transf_ckpt(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "value = decimal.Decimal(\"42.12345\")\n",
    "print(f'Result: {value:{\"0.2f\" if value < 100 else \"8.3\"}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Mathiass\\OneDrive - Universität Zürich UZH\\Documents\\mt_literature\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "data = pd.read_parquet(path+\"\\sp500_op_ret.parquet\")\n",
    "e_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read without chunks: \", (e_time-s_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise ZeroDivisionError\n",
    "except ZeroDivisionError as err:\n",
    "    try:\n",
    "        raise ZeroDivisionError\n",
    "    except:\n",
    "        raise ZeroDivisionError(\"second error\") from err\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y, z):\n",
    "    print(x + y + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = datetime.now() - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = b.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(divmod(t, 60)[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayss = 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days, rem = divmod(t, dayss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divmod(rem, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourss = 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours, secs = divmod(rem, hourss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(total_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"secid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data.iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data3.groupby(\"date\").nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3[\"date\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data3[\"secid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"secid\"] == 101375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data3[data3[\"secid\"] == 101375].nunique()[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many datapoints per time does each stock have?\n",
    "ts_per_secid = []\n",
    "unique_secid = data3[\"secid\"].unique()\n",
    "\n",
    "for i in unique_secid:\n",
    "    unique_dates = data3[data3[\"secid\"] == i].nunique()[\"date\"]\n",
    "    ts_per_secid.append((i, unique_dates))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of stocks that have at least one entry in each date\n",
    "df = pd.DataFrame(ts_per_secid)\n",
    "len(df[df[1] == 311])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = list(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save number of stocks that have at least one entry in each date\n",
    "secid_complete = df[df[1] == 311][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nr of unique stocks\n",
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secid_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data[\"secid\"].isin(secid_complete)].head(40).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data[\"secid\"].isin(secid_complete)].tail(20).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data[data[\"secid\"].isin(secid_complete)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Call to 1, Put to 0\n",
    "data_complete.loc[data_complete[\"cp_flag\"] == \"C\", \"cp_flag\"] = 1\n",
    "data_complete.loc[data_complete[\"cp_flag\"] == \"P\", \"cp_flag\"] = 0\n",
    "# Convert object type to int or date\n",
    "data_complete[\"cp_flag\"] = data_complete[\"cp_flag\"].astype(int)\n",
    "data_complete[\"date\"] = pd.to_datetime(data_complete[\"date\"])\n",
    "data_complete[\"exdate\"] = pd.to_datetime(data_complete[\"exdate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete.groupby([\"secid\", \"date\"]).agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_complete.groupby([\"secid\", \"date\"]).agg(\"mean\").sort_values(\"date\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(data_complete.groupby(\"date\").agg(\"count\") == 33).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10263 / 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_complete.groupby(\"date\").agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data averaged over stocks and date (311 rows) -> for Time Series prediction\n",
    "y = data_complete[\"option_ret\"]\n",
    "X = data_complete.drop([\"option_ret\", \"secid\", \"optionid\", \"days_no_trading\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data (3825531 rows) -> for Cross-sectional analysis\n",
    "# Set Call to 1, Put to 0\n",
    "# data.loc[data[\"cp_flag\"] == \"C\", \"cp_flag\"] = 1\n",
    "# data.loc[data[\"cp_flag\"] == \"P\", \"cp_flag\"] = 0\n",
    "# Convert object type to int or date\n",
    "# data[\"cp_flag\"] = data[\"cp_flag\"].astype(int)\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data[\"exdate\"] = pd.to_datetime(data[\"exdate\"])\n",
    "# bring dates to end of month dates (in order to correctly merge with other datasets)\n",
    "data[\"date\"] = data[\"date\"] + MonthEnd(0)\n",
    "# split off y\n",
    "data = data.drop(data[data[\"option_ret\"].isnull()].index) # remove 138 NaN option returns\n",
    "data = data.reset_index(drop=True)\n",
    "y = data[\"option_ret\"]\n",
    "X = data.drop([\"option_ret\", \"secid\", \"optionid\", \"days_no_trading\", \"date\", \"exdate\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # only use certain features?\n",
    "# X = X[[\"cp_flag\", \"impl_volatility\", \"delta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv data\n",
    "s_time = time.time()\n",
    "mapping_table = pd.read_csv(path+\"\\mapping_table.csv\")\n",
    "e_time = time.time()\n",
    "print(\"Read without chunks: \", (e_time-s_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.merge(mapping_table, on=\"secid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct format important here, otherwise will see month as day and vice versa\n",
    "df[\"sdate\"] = pd.to_datetime(df[\"sdate\"], format = \"%d/%m/%Y %H:%M\")\n",
    "df[\"edate\"] = pd.to_datetime(df[\"edate\"], format = \"%d/%m/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filter = df[(df[\"date\"] >= df[\"sdate\"]) & ((df[\"date\"] <= df[\"edate\"]) | (df[\"edate\"] >= \"2020-12-31\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3818687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(df_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should have 3825393 rows (4 more than below)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should have 3825389 rows\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(data[[\"optionid\", \"date\"]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = set(df_filter[[\"optionid\", \"date\"]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = list(data[\"optionid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = list(df_filter[\"optionid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(set(e) - set(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = set([x[0] for x in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = set([x[0] for x in c]) - set(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[data[\"optionid\"].isin(u)][data[data[\"optionid\"].isin(u)][\"secid\"] == 102362                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filter[df_filter[\"optionid\"].isin(u)][df_filter[df_filter[\"optionid\"].isin(u)][\"secid\"] == 102362 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter[\"edate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 observations are dropped because permno is ambiguous in the 94 char. feature list (Moodys spin off)\n",
    "data[data[\"optionid\"].isin(u)][\"secid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data[\"optionid\"].isin(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PARQUET data (3sec instead of 38sec -> speedup of 10x)\n",
    "s_time = time.time()\n",
    "data2 = pd.read_parquet(path+\"\\Gu2020_datashare\\datashare.parquet\")\n",
    "e_time = time.time()\n",
    "print(\"Read without chunks: \", (e_time-s_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lag features by -1 to align with option features\n",
    "data2[\"DATE\"] = pd.to_datetime(data2[\"DATE\"].astype(str), format='%Y%m%d') - MonthEnd(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[data2[\"permno\"] == 48506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data2.loc[data2[\"permno\"] == 93429, \"sic2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually insert SIC codes\n",
    "data2.loc[data2[\"permno\"] == 18312, \"sic2\"] = 28 #Moderna https://sec.report/CIK/0001682852\n",
    "data2.loc[data2[\"permno\"] == 18428, \"sic2\"] = 28 #Dow Inc https://sec.report/Ticker/DOW\n",
    "data2.loc[data2[\"permno\"] == 93429, \"sic2\"] = 62 #CBOE Global Markets https://sec.report/Ticker/CBOE\n",
    "data2.loc[data2[\"permno\"] == 18143, \"sic2\"] = 28 #Linde https://sec.report/CIK/0001707925\n",
    "data2.loc[data2[\"permno\"] == 19285, \"sic2\"] = 35 #Carrier Global Corp https://sec.report/Ticker/CARR\n",
    "data2.loc[data2[\"permno\"] == 18592, \"sic2\"] = 1 #Corteva https://sec.report/CIK/0001755672\n",
    "data2.loc[data2[\"permno\"] == 17942, \"sic2\"] = 20 #Keurig Dr Pepper https://sec.report/Ticker/kdp\n",
    "data2.loc[data2[\"permno\"] == 18420, \"sic2\"] = 48 #FOX Corp https://sec.report/Ticker/foxa\n",
    "data2.loc[data2[\"permno\"] == 20057, \"sic2\"] = 28 #Viatris https://sec.report/Ticker/foxa\n",
    "data2.loc[data2[\"permno\"] == 15850, \"sic2\"] = 72 #Match Group https://sec.report/Ticker/mtch\n",
    "data2.loc[data2[\"permno\"] == 32791, \"sic2\"] = 35 #Weatherford https://sec.report/Ticker/wft\n",
    "data2.loc[data2[\"permno\"] == 19286, \"sic2\"] = 36 #OTIS https://sec.report/Ticker/OTIS\n",
    "data2.loc[data2[\"permno\"] == 17700, \"sic2\"] = 73 #Ceridian https://sec.report/Ticker/CDAY\n",
    "data2.loc[data2[\"permno\"] == 18724, \"sic2\"] = 39 #Amcor https://sec.report/Ticker/AMCR\n",
    "data2.loc[data2[\"permno\"] == 38850, \"sic2\"] = 24 #Skyline https://sec.report/Ticker/sky\n",
    "data2.loc[data2[\"permno\"] == 19807, \"sic2\"] = 38 #Vontier https://sec.report/Ticker/VNT\n",
    "data2.loc[data2[\"permno\"] == 78840, \"sic2\"] = 48 #IAC Interactive Corp ->sp500 const. list\n",
    "# ----\n",
    "data2.loc[data2[\"permno\"] == 81594, \"sic2\"] = 13 #Dynegy, only 8 were NaN, rest was =13\n",
    "data2.loc[data2[\"permno\"] == 88601, \"sic2\"] = 49 #Mirant, first 4 were NaN, rest =49\n",
    "data2.loc[data2[\"permno\"] == 80913, \"sic2\"] = 73 #ACS, last month NaN, rest =73\n",
    "data2.loc[data2[\"permno\"] == 44652, \"sic2\"] = 54 #American Stores Company, last month NaN, rest =54\n",
    "data2.loc[data2[\"permno\"] == 76563, \"sic2\"] = 54 #Meyer Fred Inc., last month NaN, rest =54\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data starts at 1996-01-31\n",
    "df = data2[data2[\"DATE\"] > \"1995-12-31\"]\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={\"DATE\": \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique set of dates to loop over and take mean/median of all stocks in that month\n",
    "date_unique = list(df[\"date\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL MISSING VALUES. COMMENT THIS OUT FOR ORIGINAL DF_FINAL.PARQUET. loop over each date and fill NA\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(date_unique):\n",
    "    df[df[\"date\"] == i] = df[df[\"date\"] == i].fillna(df[df[\"date\"] == i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[6419, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % missing values in stock characteristics?\n",
    "np.sum(np.sum(df.isnull())) / (df.shape[0] * df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"date\"] == date_unique[0]].mean(axis=0, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"date\"] == date_unique[0]][\"beta\"][655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check what should be inserted by for loop\n",
    "df[df[\"date\"] == date_unique[0]].fillna(df[df[\"date\"] == date_unique[0]].mean(axis=0, numeric_only=False))[\"beta\"][655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what should be inserted by for loop\n",
    "df[df[\"date\"] == date_unique[0]][\"std_turn\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9909510930939289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"permno\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# final dataset \"INNER\" -> REMOVE VALUES THAT HAVE NO 94 CHARACTERISTICS, \"left\" -> how to impute?\n",
    "final_df = df_filter.merge(df, on=[\"date\", \"permno\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"permno\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"secid\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df[\"permno\"] == 56266]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permno_unique = list(final_df[\"permno\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permno_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[final_df[\"permno\"] == 56266, \"chatoia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sum(final_df.loc[final_df[\"permno\"] == 56266, :].isnull()).sort_values()[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put option returns at the end\n",
    "opt_ret = final_df.pop(\"option_ret\")\n",
    "final_df[\"option_ret\"] = opt_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> How to save this table so that one can efficiently get it back? feather? pickle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows got remove from the inner joing\n",
    "len(df_filter) - len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many \"sic2\" NaNs per \"secid\"\n",
    "final_df[final_df[\"sic2\"].isnull()][\"secid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE FINAL DF TO PARQUET\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.compose import make_column_transformer\n",
    "\n",
    "# onehotencoder = make_column_transformer((OneHotEncoder(), [\"cp_flag\", \"sic2\"]), remainder=\"drop\")\n",
    "# transformed = onehotencoder.fit_transform(final_df)\n",
    "# transformed_df = pd.DataFrame(transformed.toarray(), columns=onehotencoder.transformers_[0][1].get_feature_names_out([\"cp_flag\", \"sic2\"]))\n",
    "\n",
    "# # drop old columns cp_flag, sic2\n",
    "# final_df = final_df.drop([\"cp_flag\", \"sic2\"], axis=1)\n",
    "\n",
    "# # concatenate both dataframes (memory intensive?)\n",
    "# final_df = pd.concat([final_df, transformed_df], axis=1)\n",
    "\n",
    "# # sort values by date! (secondly by secid -> but better to shuffle within date later)\n",
    "# final_df = final_df.sort_values([\"date\", \"secid\"]).reset_index(drop=True)\n",
    "\n",
    "# # remove useless columns for dataanalsis\n",
    "# final_df = final_df.drop([\"secid\", \"optionid\", \"exdate\", \"sdate\", \"edate\", \"permno\", \"index\"], axis=1)\n",
    "\n",
    "# # to parquet (no r -> doesnt work somehow, \\f gets transformed to \\x0c)\n",
    "# final_df.to_parquet(fr\"{path}\\final_df_filledmean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final file\n",
    "final_df = pd.read_parquet(path+\"final_df_filledmean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"option_ret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "121 + 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sic2 = final_df[\"sic2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sic2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df[[\"sic2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoder_df = pd.DataFrame(encoder.fit_transform(final_df[[\"sic2\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3823386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea:\n",
    "\n",
    "- classification vs. regression. -> use of SVM/SVR as additional models\n",
    "- classif: prediction of up/neutral/down (+1/0/-1) ?\n",
    "- add sentiment columns to each option? -> sentiment analysis of past stock price history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "- Get more Data?: Generate samples with generative models? (diffusion models)?\n",
    "- Fully Convolutional / Convolutional Nets for varying input size per point in time? or for additional feature for each row\n",
    "- Use underlying stock/ option time series as additional column features? But what about missing history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "137ad5de30c222602b906d427f317b23725154a9d2ac1dd9f95e9d3b5697fcc3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
