{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Mathiass\\OneDrive - Universität Zürich UZH\\Documents\\mt_literature\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "data = pd.read_parquet(path+\"\\sp500_op_ret.parquet\")\n",
    "e_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read without chunks:  1.3819060325622559 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Read without chunks: \", (e_time-s_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = datetime.now() - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = b.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.162222"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(divmod(t, 60)[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayss = 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "days, rem = divmod(t, dayss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 51)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divmod(rem, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourss = 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours, secs = divmod(rem, hourss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict[\"days\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict[\"hours\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict[\"secs\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'days': 1, 'hours': 2, 'secs': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict[\"loop1\"] = time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loop1': {'days': 1, 'hours': 2, 'secs': 3}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days</th>\n",
       "      <th>hours</th>\n",
       "      <th>secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loop1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       days  hours  secs\n",
       "loop1     1      2     3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(total_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"secid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data.iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data3.groupby(\"date\").nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3[\"date\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data3[\"secid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"secid\"] == 101375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data3[data3[\"secid\"] == 101375].nunique()[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many datapoints per time does each stock have?\n",
    "ts_per_secid = []\n",
    "unique_secid = data3[\"secid\"].unique()\n",
    "\n",
    "for i in unique_secid:\n",
    "    unique_dates = data3[data3[\"secid\"] == i].nunique()[\"date\"]\n",
    "    ts_per_secid.append((i, unique_dates))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of stocks that have at least one entry in each date\n",
    "df = pd.DataFrame(ts_per_secid)\n",
    "len(df[df[1] == 311])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = list(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save number of stocks that have at least one entry in each date\n",
    "secid_complete = df[df[1] == 311][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nr of unique stocks\n",
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secid_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data[\"secid\"].isin(secid_complete)].head(40).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data[\"secid\"].isin(secid_complete)].tail(20).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data[data[\"secid\"].isin(secid_complete)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Call to 1, Put to 0\n",
    "data_complete.loc[data_complete[\"cp_flag\"] == \"C\", \"cp_flag\"] = 1\n",
    "data_complete.loc[data_complete[\"cp_flag\"] == \"P\", \"cp_flag\"] = 0\n",
    "# Convert object type to int or date\n",
    "data_complete[\"cp_flag\"] = data_complete[\"cp_flag\"].astype(int)\n",
    "data_complete[\"date\"] = pd.to_datetime(data_complete[\"date\"])\n",
    "data_complete[\"exdate\"] = pd.to_datetime(data_complete[\"exdate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete.groupby([\"secid\", \"date\"]).agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_complete.groupby([\"secid\", \"date\"]).agg(\"mean\").sort_values(\"date\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(data_complete.groupby(\"date\").agg(\"count\") == 33).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10263 / 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_complete.groupby(\"date\").agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data averaged over stocks and date (311 rows) -> for Time Series prediction\n",
    "y = data_complete[\"option_ret\"]\n",
    "X = data_complete.drop([\"option_ret\", \"secid\", \"optionid\", \"days_no_trading\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data (3825531 rows) -> for Cross-sectional analysis\n",
    "# Set Call to 1, Put to 0\n",
    "# data.loc[data[\"cp_flag\"] == \"C\", \"cp_flag\"] = 1\n",
    "# data.loc[data[\"cp_flag\"] == \"P\", \"cp_flag\"] = 0\n",
    "# Convert object type to int or date\n",
    "# data[\"cp_flag\"] = data[\"cp_flag\"].astype(int)\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data[\"exdate\"] = pd.to_datetime(data[\"exdate\"])\n",
    "# bring dates to end of month dates (in order to correctly merge with other datasets)\n",
    "data[\"date\"] = data[\"date\"] + MonthEnd(0)\n",
    "# split off y\n",
    "data = data.drop(data[data[\"option_ret\"].isnull()].index) # remove 138 NaN option returns\n",
    "data = data.reset_index(drop=True)\n",
    "y = data[\"option_ret\"]\n",
    "X = data.drop([\"option_ret\", \"secid\", \"optionid\", \"days_no_trading\", \"date\", \"exdate\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # only use certain features?\n",
    "# X = X[[\"cp_flag\", \"impl_volatility\", \"delta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv data\n",
    "s_time = time.time()\n",
    "mapping_table = pd.read_csv(path+\"\\mapping_table.csv\")\n",
    "e_time = time.time()\n",
    "print(\"Read without chunks: \", (e_time-s_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.merge(mapping_table, on=\"secid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct format important here, otherwise will see month as day and vice versa\n",
    "df[\"sdate\"] = pd.to_datetime(df[\"sdate\"], format = \"%d/%m/%Y %H:%M\")\n",
    "df[\"edate\"] = pd.to_datetime(df[\"edate\"], format = \"%d/%m/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filter = df[(df[\"date\"] >= df[\"sdate\"]) & ((df[\"date\"] <= df[\"edate\"]) | (df[\"edate\"] >= \"2020-12-31\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3818687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(df_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should have 3825393 rows (4 more than below)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should have 3825389 rows\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(data[[\"optionid\", \"date\"]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = set(df_filter[[\"optionid\", \"date\"]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = list(data[\"optionid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = list(df_filter[\"optionid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(set(e) - set(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = set([x[0] for x in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = set([x[0] for x in c]) - set(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[data[\"optionid\"].isin(u)][data[data[\"optionid\"].isin(u)][\"secid\"] == 102362                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filter[df_filter[\"optionid\"].isin(u)][df_filter[df_filter[\"optionid\"].isin(u)][\"secid\"] == 102362 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter[\"edate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 observations are dropped because permno is ambiguous in the 94 char. feature list (Moodys spin off)\n",
    "data[data[\"optionid\"].isin(u)][\"secid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data[\"optionid\"].isin(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PARQUET data (3sec instead of 38sec -> speedup of 10x)\n",
    "s_time = time.time()\n",
    "data2 = pd.read_parquet(path+\"\\Gu2020_datashare\\datashare.parquet\")\n",
    "e_time = time.time()\n",
    "print(\"Read without chunks: \", (e_time-s_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lag features by -1 to align with option features\n",
    "data2[\"DATE\"] = pd.to_datetime(data2[\"DATE\"].astype(str), format='%Y%m%d') - MonthEnd(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[data2[\"permno\"] == 48506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data2.loc[data2[\"permno\"] == 93429, \"sic2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually insert SIC codes\n",
    "data2.loc[data2[\"permno\"] == 18312, \"sic2\"] = 28 #Moderna https://sec.report/CIK/0001682852\n",
    "data2.loc[data2[\"permno\"] == 18428, \"sic2\"] = 28 #Dow Inc https://sec.report/Ticker/DOW\n",
    "data2.loc[data2[\"permno\"] == 93429, \"sic2\"] = 62 #CBOE Global Markets https://sec.report/Ticker/CBOE\n",
    "data2.loc[data2[\"permno\"] == 18143, \"sic2\"] = 28 #Linde https://sec.report/CIK/0001707925\n",
    "data2.loc[data2[\"permno\"] == 19285, \"sic2\"] = 35 #Carrier Global Corp https://sec.report/Ticker/CARR\n",
    "data2.loc[data2[\"permno\"] == 18592, \"sic2\"] = 1 #Corteva https://sec.report/CIK/0001755672\n",
    "data2.loc[data2[\"permno\"] == 17942, \"sic2\"] = 20 #Keurig Dr Pepper https://sec.report/Ticker/kdp\n",
    "data2.loc[data2[\"permno\"] == 18420, \"sic2\"] = 48 #FOX Corp https://sec.report/Ticker/foxa\n",
    "data2.loc[data2[\"permno\"] == 20057, \"sic2\"] = 28 #Viatris https://sec.report/Ticker/foxa\n",
    "data2.loc[data2[\"permno\"] == 15850, \"sic2\"] = 72 #Match Group https://sec.report/Ticker/mtch\n",
    "data2.loc[data2[\"permno\"] == 32791, \"sic2\"] = 35 #Weatherford https://sec.report/Ticker/wft\n",
    "data2.loc[data2[\"permno\"] == 19286, \"sic2\"] = 36 #OTIS https://sec.report/Ticker/OTIS\n",
    "data2.loc[data2[\"permno\"] == 17700, \"sic2\"] = 73 #Ceridian https://sec.report/Ticker/CDAY\n",
    "data2.loc[data2[\"permno\"] == 18724, \"sic2\"] = 39 #Amcor https://sec.report/Ticker/AMCR\n",
    "data2.loc[data2[\"permno\"] == 38850, \"sic2\"] = 24 #Skyline https://sec.report/Ticker/sky\n",
    "data2.loc[data2[\"permno\"] == 19807, \"sic2\"] = 38 #Vontier https://sec.report/Ticker/VNT\n",
    "data2.loc[data2[\"permno\"] == 78840, \"sic2\"] = 48 #IAC Interactive Corp ->sp500 const. list\n",
    "# ----\n",
    "data2.loc[data2[\"permno\"] == 81594, \"sic2\"] = 13 #Dynegy, only 8 were NaN, rest was =13\n",
    "data2.loc[data2[\"permno\"] == 88601, \"sic2\"] = 49 #Mirant, first 4 were NaN, rest =49\n",
    "data2.loc[data2[\"permno\"] == 80913, \"sic2\"] = 73 #ACS, last month NaN, rest =73\n",
    "data2.loc[data2[\"permno\"] == 44652, \"sic2\"] = 54 #American Stores Company, last month NaN, rest =54\n",
    "data2.loc[data2[\"permno\"] == 76563, \"sic2\"] = 54 #Meyer Fred Inc., last month NaN, rest =54\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data starts at 1996-01-31\n",
    "df = data2[data2[\"DATE\"] > \"1995-12-31\"]\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={\"DATE\": \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique set of dates to loop over and take mean/median of all stocks in that month\n",
    "date_unique = list(df[\"date\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL MISSING VALUES. COMMENT THIS OUT FOR ORIGINAL DF_FINAL.PARQUET. loop over each date and fill NA\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(date_unique):\n",
    "    df[df[\"date\"] == i] = df[df[\"date\"] == i].fillna(df[df[\"date\"] == i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[6419, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % missing values in stock characteristics?\n",
    "np.sum(np.sum(df.isnull())) / (df.shape[0] * df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"date\"] == date_unique[0]].mean(axis=0, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"date\"] == date_unique[0]][\"beta\"][655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check what should be inserted by for loop\n",
    "df[df[\"date\"] == date_unique[0]].fillna(df[df[\"date\"] == date_unique[0]].mean(axis=0, numeric_only=False))[\"beta\"][655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what should be inserted by for loop\n",
    "df[df[\"date\"] == date_unique[0]][\"std_turn\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9909510930939289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"permno\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# final dataset \"INNER\" -> REMOVE VALUES THAT HAVE NO 94 CHARACTERISTICS, \"left\" -> how to impute?\n",
    "final_df = df_filter.merge(df, on=[\"date\", \"permno\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"permno\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"secid\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df[\"permno\"] == 56266]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permno_unique = list(final_df[\"permno\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permno_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[final_df[\"permno\"] == 56266, \"chatoia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sum(final_df.loc[final_df[\"permno\"] == 56266, :].isnull()).sort_values()[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put option returns at the end\n",
    "opt_ret = final_df.pop(\"option_ret\")\n",
    "final_df[\"option_ret\"] = opt_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> How to save this table so that one can efficiently get it back? feather? pickle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows got remove from the inner joing\n",
    "len(df_filter) - len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many \"sic2\" NaNs per \"secid\"\n",
    "final_df[final_df[\"sic2\"].isnull()][\"secid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE FINAL DF TO PARQUET\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.compose import make_column_transformer\n",
    "\n",
    "# onehotencoder = make_column_transformer((OneHotEncoder(), [\"cp_flag\", \"sic2\"]), remainder=\"drop\")\n",
    "# transformed = onehotencoder.fit_transform(final_df)\n",
    "# transformed_df = pd.DataFrame(transformed.toarray(), columns=onehotencoder.transformers_[0][1].get_feature_names_out([\"cp_flag\", \"sic2\"]))\n",
    "\n",
    "# # drop old columns cp_flag, sic2\n",
    "# final_df = final_df.drop([\"cp_flag\", \"sic2\"], axis=1)\n",
    "\n",
    "# # concatenate both dataframes (memory intensive?)\n",
    "# final_df = pd.concat([final_df, transformed_df], axis=1)\n",
    "\n",
    "# # sort values by date! (secondly by secid -> but better to shuffle within date later)\n",
    "# final_df = final_df.sort_values([\"date\", \"secid\"]).reset_index(drop=True)\n",
    "\n",
    "# # remove useless columns for dataanalsis\n",
    "# final_df = final_df.drop([\"secid\", \"optionid\", \"exdate\", \"sdate\", \"edate\", \"permno\", \"index\"], axis=1)\n",
    "\n",
    "# # to parquet (no r -> doesnt work somehow, \\f gets transformed to \\x0c)\n",
    "# final_df.to_parquet(fr\"{path}\\final_df_filledmean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final file\n",
    "final_df = pd.read_parquet(path+\"final_df_filledmean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"option_ret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "121 + 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sic2 = final_df[\"sic2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sic2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df[[\"sic2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoder_df = pd.DataFrame(encoder.fit_transform(final_df[[\"sic2\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3823386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea:\n",
    "\n",
    "- classification vs. regression. -> use of SVM/SVR as additional models\n",
    "- classif: prediction of up/neutral/down (+1/0/-1) ?\n",
    "- add sentiment columns to each option? -> sentiment analysis of past stock price history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "- Get more Data?: Generate samples with generative models? (diffusion models)?\n",
    "- Fully Convolutional / Convolutional Nets for varying input size per point in time? or for additional feature for each row\n",
    "- Use underlying stock/ option time series as additional column features? But what about missing history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "137ad5de30c222602b906d427f317b23725154a9d2ac1dd9f95e9d3b5697fcc3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
