{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45cd5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40adbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.integration.xgboost import TuneReportCheckpointCallback\n",
    "\n",
    "import pytorch_lightning as pl #for \"seed everything\"\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9caffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9160d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    data: pandas.DataFrame that must have specific columns.\n",
    "\n",
    "    \"\"\"\n",
    "    # Bid-Ask spread: (Ask - Bid) / Ask\n",
    "    data[\"best_bid\"] = (data[\"best_offer\"] - data[\"best_bid\"]) / (data[\"best_offer\"])\n",
    "    data = data.rename(columns={\"best_bid\": \"ba_spread_option\"}).drop([\"best_offer\"], axis=1)\n",
    "\n",
    "    # Gamma: multiply by spotprice and divide by 100\n",
    "    data[\"gamma\"] = data[\"gamma\"] * data[\"spotprice\"] / 100 #following Bali et al. (2021)\n",
    "\n",
    "    # Theta: scale by spotprice\n",
    "    data[\"theta\"] = data[\"theta\"] / data[\"spotprice\"] #following Bali et al. (2021)\n",
    "\n",
    "    # Vega: scale by spotprice\n",
    "    data[\"vega\"] = data[\"vega\"] / data[\"spotprice\"] #following Bali et al. (2021)\n",
    "\n",
    "    # Time to Maturity: cale by number of days in year: 365\n",
    "    data[\"days_to_exp\"] = data[\"days_to_exp\"] / 365\n",
    "\n",
    "    # Moneyness: Strike / Spot (K / S)\n",
    "    data[\"strike_price\"] = data[\"strike_price\"] / data[\"spotprice\"] # K / S\n",
    "    data = data.rename(columns={\"strike_price\": \"moneyness\"})\n",
    "\n",
    "    # Forward Price ratio: Forward / Spot\n",
    "    data[\"forwardprice\"] = data[\"forwardprice\"] / data[\"spotprice\"]\n",
    "\n",
    "    # Drop redundant/ unimportant columns\n",
    "    data = data.drop([\"cfadj\", \"days_no_trading\", \"spotprice\", \"adj_spot\"], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "# binary y label generator\n",
    "def binary_categorize(y):\n",
    "    \"\"\"\n",
    "    Input: continuous target variable \n",
    "\n",
    "    Output: 1 for positive returns, \n",
    "            0 for negative returns\n",
    "    \"\"\"\n",
    "    if y > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# multiclass y label generator\n",
    "def multi_categorize(y):\n",
    "    \"\"\"\n",
    "    Input: continuous target variable\n",
    "    CAREFUL: classes have to be between [0, C) for F.crossentropyloss.\n",
    "    \n",
    "    Output: multi class\n",
    "    \"\"\"\n",
    "    if y > 0.05:\n",
    "        return 2\n",
    "    elif y < -0.05:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "class CVSplitter:\n",
    "    \"\"\" Generator for data splits\n",
    "    Args:\n",
    "    dates: pandas.Series of datetime,\n",
    "    init_train_length: int,\n",
    "    val_length: int\n",
    "    \"\"\"\n",
    "    def __init__(self, dates, init_train_length=1, val_length=2, test_length=1):\n",
    "        # find indeces where years change (will ignore last year end in dates)\n",
    "        self.val_length = val_length\n",
    "        self.test_length = test_length\n",
    "        self.eoy_idx =  np.where((dates.dt.year.diff() == 1))[0]\n",
    "        self.eoy_idx = np.append(self.eoy_idx, len(dates)) #append end of year of last year in dates\n",
    "\n",
    "        assert init_train_length + val_length + test_length <= len(self.eoy_idx) + 1, \\\n",
    "        \"defined train and val are larger than number of years in dataset\"\n",
    "        assert init_train_length > 0, \"init_train_length must be strictly greater than 0\"\n",
    "\n",
    "        # align the 4th idx to be the end of the 5th year...\n",
    "        self.train_start_idx = init_train_length - 1\n",
    "\n",
    "        self.train_eoy = self.eoy_idx[self.train_start_idx:-(val_length+test_length)]\n",
    "        self.val_eoy = self.eoy_idx[self.train_start_idx + val_length:-test_length]\n",
    "        # For generate_idx():\n",
    "        self.test_eoy = self.eoy_idx[self.train_start_idx + val_length + test_length:]\n",
    "\n",
    "    def generate(self):\n",
    "        for i in range(len(self.eoy_idx) - (self.train_start_idx + self.val_length)):\n",
    "            yield (list(range(self.train_eoy[i])),\n",
    "                   list(range(self.train_eoy[i], self.val_eoy[i])))\n",
    "\n",
    "    def generate_idx(self):\n",
    "        for i in range(len(self.eoy_idx) - (self.train_start_idx + self.val_length \n",
    "                        + self.test_length)):\n",
    "            yield ({\"train\": self.train_eoy[i], \n",
    "                    \"val\": self.val_eoy[i], \n",
    "                    \"test\": self.test_eoy[i]}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from disk\n",
    "path = Path(r\"C:\\Users\\Mathiass\\OneDrive - Universität Zürich UZH\\Documents\\mt_literature\\data\")\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, path=path, year_idx=0, dataset=\"small\", init_train_length=20, val_length=2, label_fn=\"binary\"):\n",
    "        if dataset == \"small\":\n",
    "            self.data = pd.read_parquet(path/\"final_df_filledmean_small.parquet\")\n",
    "        elif dataset == \"big\":\n",
    "            self.data = pd.read_parquet(path/\"final_df_filledmean.parquet\")\n",
    "        else:\n",
    "            raise ValueError(\"Specify dataset as either 'small' or 'big'\")\n",
    "\n",
    "        # get splits\n",
    "        splitter = CVSplitter(self.data[\"date\"], init_train_length=init_train_length, \n",
    "                                val_length=val_length, test_length=1)\n",
    "        eoy_indeces = list(splitter.generate_idx())\n",
    "        self.eoy_train = eoy_indeces[year_idx][\"train\"]\n",
    "        self.eoy_val = eoy_indeces[year_idx][\"val\"]\n",
    "        self.eoy_test = eoy_indeces[year_idx][\"test\"]\n",
    "        \n",
    "        # Truncate data\n",
    "        self.data = self.data.iloc[:self.eoy_test]\n",
    "        assert len(self.data) == self.eoy_test, \"length of data is not equal to eoy_test\"\n",
    "            \n",
    "        # feature engineer data\n",
    "        self.data = feature_engineer(self.data)\n",
    "        \n",
    "        # create y\n",
    "        self.y = self.data[\"option_ret\"]\n",
    "        # make classification problem\n",
    "        if label_fn == \"binary\":\n",
    "            self.y = self.y.apply(binary_categorize)\n",
    "        elif label_fn == \"multi\":\n",
    "            self.y = self.y.apply(multi_categorize)\n",
    "        else:\n",
    "            raise ValueError(\"Specify label_fn as either 'binary' or 'multi'\")\n",
    "        # create X\n",
    "        self.X = self.data.drop([\"option_ret\"], axis=1)\n",
    "        \n",
    "        # save dates and drop\n",
    "        self.dates = self.X[\"date\"]\n",
    "        self.X = self.X.drop([\"date\"], axis=1)\n",
    "        \n",
    "#         # to torch Tensor\n",
    "#         self.X = torch.from_numpy(self.X.values).float() #-> will be standardized in setup, so do it there.\n",
    "#         self.y = torch.from_numpy(self.y.values)\n",
    "\n",
    "        # to numpy\n",
    "        self.X = self.X.values #-> will be standardized in setup, so do it there.\n",
    "        self.y = self.y.values\n",
    "    \n",
    "        ############################### setup #########################################################\n",
    "        # train\n",
    "        self.X_train = self.X[:self.eoy_train]\n",
    "        self.y_train = self.y[:len(self.X_train)]\n",
    "        \n",
    "        #val\n",
    "        self.X_val = self.X[self.eoy_train:self.eoy_val]\n",
    "        self.y_val = self.y[len(self.X_train):len(self.X_train)+len(self.X_val)]\n",
    "        \n",
    "        # test\n",
    "        self.X_test = self.X[self.eoy_val:self.eoy_test]\n",
    "        self.y_test = self.y[-len(self.X_test):]\n",
    "        \n",
    "        assert (len(self.X_train)+len(self.X_val)+len(self.X_test)) == len(self.data), \\\n",
    "            \"sum of X train, val, test is not equal length of dataset\"\n",
    "        assert (len(self.y_train)+len(self.y_val)+len(self.y_test) == len(self.data)), \\\n",
    "        \"sum of y train, val, test is not equal to length of dataset\"\n",
    "        \n",
    "#         #standardize X_train\n",
    "#         mean = torch.mean(self.X_train, axis=0)\n",
    "#         std = torch.std(self.X_train, axis=0)\n",
    "        \n",
    "#         # Standardize X_train, X_val and X_test with mean/std from X_train\n",
    "#         self.X_train = (self.X_train - mean) / std\n",
    "#         self.X_val = (self.X_val - mean) / std\n",
    "#         self.X_test = (self.X_test - mean) / std\n",
    "\n",
    "        # Save variables\n",
    "        # input dim\n",
    "        self.input_dim = self.X_train.shape[1]\n",
    "        # number of classes\n",
    "        self.num_classes = len(np.unique(self.y_train))\n",
    "#         class weights\n",
    "        self.class_weights = len(self.y_train) / np.unique(self.y_train, return_counts=True)[1]\n",
    "        \n",
    "        print(\"*****************************************************************************************\")\n",
    "        print(\"Current dataset information:\")\n",
    "        print(\"---\")\n",
    "        print(\"class_weights:\", self.class_weights)\n",
    "        print(\"---\")\n",
    "        print(f\"# of input data: {len(self.data)} with shape: {self.data.shape}\")\n",
    "        print(f\"# of training samples: {len(self.y_train)} with X_train of shape: {self.X_train.shape}\")\n",
    "        print(f\"# of validation samples: {len(self.y_val)} with X_val of shape: {self.X_val.shape}\")\n",
    "        print(f\"# of test samples: {len(self.y_test)} with X_test of shape: {self.X_test.shape}\")\n",
    "        print(\"---\")\n",
    "        print(f\"train start date: \", self.dates.iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", train end date: \", self.dates.iloc[:self.eoy_train].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(f\"val start date: \", self.dates.iloc[self.eoy_train:self.eoy_val].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", val end date: \", self.dates.iloc[self.eoy_train:self.eoy_val].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(f\"test start date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", test end date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(\"*****************************************************************************************\")\n",
    "        \n",
    "    def get_datasets(self):\n",
    "        return self.X_train, self.X_val, self.X_test\n",
    "    \n",
    "    def get_train_val_xgb(self):\n",
    "        return self.X_train, self.X_val, self.y_train, self.y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696fe75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bal_acc_xgb(preds: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
    "    y = dtrain.get_label() # get true y as np.array\n",
    "    # if more than 2 classes\n",
    "    if len(preds.shape) > 1:\n",
    "        raise NotImplementedError(\"Implement Softmax here\")\n",
    "    else:\n",
    "        # if 2 classes, round the probabilities\n",
    "        preds = np.round(preds)\n",
    "    \n",
    "    val_bal_acc = balanced_accuracy_score(y, preds)\n",
    "    \n",
    "    return 'val_bal_acc', val_bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a241882",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "data = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = data.get_train_val_xgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset()\n",
    "X_train, X_val, y_train, y_val = data.get_train_val_xgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd861280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = len(y_train) / np.unique(y_train, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f266d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. / 0.56205813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47457e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights / weights[weights.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f98acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3895877 / 0.78102907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eccd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_array = np.ones(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20157bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, val in enumerate(y_train):\n",
    "#     w_array[i] = class_weights[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fdef1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def train(config, data):\n",
    "    # Load dataset\n",
    "#     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "#     # Split into train and test set\n",
    "#     train_x, test_x, train_y, test_y = train_test_split(\n",
    "#         data, labels, test_size=0.25)\n",
    "\n",
    "#     pl.seed_everything(42, workers=True)\n",
    "    \n",
    "#     data = Dataset()\n",
    "    X_train, X_val, y_train, y_val = data.get_train_val_xgb()\n",
    "    \n",
    "    # Build input matrices for XGBoost\n",
    "    D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    D_val = xgb.DMatrix(X_val, label=y_val)\n",
    "    # Train the classifier\n",
    "    results = {}\n",
    "    bst = xgb.train(\n",
    "        config,\n",
    "        D_train,\n",
    "        evals=[(D_train, \"train\"), (D_val, \"eval\")],\n",
    "        evals_result=results,\n",
    "#         verbose_eval=False,\n",
    "#         num_boost_round=1, #*************************************************************************\n",
    "        callbacks=[TuneReportCheckpointCallback(filename=\"model.xgb\")],\n",
    "        custom_metric=bal_acc_xgb,\n",
    "        num_boost_round=100,\n",
    "    )\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0c8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_best_model_checkpoint(analysis):\n",
    "    best_bst = xgb.Booster()\n",
    "    best_bst.load_model(os.path.join(analysis.best_checkpoint, \"model.xgb\"))\n",
    "    accuracy = 1. - analysis.best_result[\"eval-error\"]\n",
    "    print(f\"Best model parameters: {analysis.best_config}\")\n",
    "    print(f\"Best model total accuracy: {accuracy:.4f}\")\n",
    "    return best_bst\n",
    "\n",
    "\n",
    "def tune_xgboost():\n",
    "    search_space = {\n",
    "        # You can mix constants with search space objects.\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "        \"seed\": 42,\n",
    "        'tree_method' : 'gpu_hist', # to use GPU\n",
    "#         \"single_precision_histogram\": True, #may improve speed, in particular on older architectures.\n",
    "        'disable_default_eval_metric': 1,\n",
    "        \"max_depth\": tune.randint(1, 9),\n",
    "        \"min_child_weight\": tune.choice([1, 2, 3]),\n",
    "        \"subsample\": tune.uniform(0.5, 1.0),\n",
    "        \"eta\": tune.loguniform(1e-4, 1e-1),\n",
    "    }\n",
    "    \n",
    "    data = Dataset()\n",
    "    \n",
    "    train_fn_with_parameters = tune.with_parameters(train,\n",
    "                                                    data=data\n",
    "                                                )\n",
    "    \n",
    "    # This will enable aggressive early stopping of bad trials.\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=3,  # 10 training iterations\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "\n",
    "    analysis = tune.run(\n",
    "        train_fn_with_parameters,\n",
    "        metric=\"eval-logloss\",\n",
    "        mode=\"min\",\n",
    "        # You can add \"gpu\": 0.1 to allocate GPUs\n",
    "        resources_per_trial={\"cpu\": 4, \"gpu\": 0.5},\n",
    "        config=search_space,\n",
    "        num_samples=2,\n",
    "        scheduler=scheduler\n",
    "    \n",
    "    )\n",
    "\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518176b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_bst.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc5ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis = tune_xgboost()\n",
    "\n",
    "best_bst = get_best_model_checkpoint(analysis)\n",
    "\n",
    "# You could now do further predictions with\n",
    "# best_bst.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset()\n",
    "X_train, X_val, y_train, y_val = data.get_train_val_xgb()\n",
    "# Build input matrices for XGBoost\n",
    "D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "D_val = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bst.predict(D_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c66c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(best_bst.predict(D_val).reshape(-1, 1), axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ac788",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(best_bst.predict(D_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa425f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(y_val, best_bst.predict(D_val).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17sec, 4gpu, 0.5gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16.99, 4 cpu, no gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total run time: 28.79 seconds (28.61 seconds for the tuning loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial name\tstatus\tloc\teta\tmax_depth\tmin_child_weight\tsubsample\titer\ttotal time (s)\ttrain-logloss\ttrain-error\ttrain-val_bal_acc\n",
    "# train_e9566_00000\tTERMINATED\t127.0.0.1:2424\t0.021831\t7\t1\t0.591717\t10\t23.8794\t0.67544\t0.352338\t0.515156\n",
    "# train_e9566_00001\tTERMINATED\t127.0.0.1:1592\t0.00238642\t2\t3\t0.549987\t1\t8.44267\t0.692946\t0.359819\t0.5\n",
    "# train_e9566_00002\tTERMINATED\t127.0.0.1:4856\t0.0812325\t8\t3\t0.510292\t10\t23.9471\t0.647541\t0.345555\t0.525421\n",
    "# train_e9566_00003\tTERMINATED\t127.0.0.1:11448\t0.000354988\t6\t2\t0.590912\t1\t8.15133\t0.693114\t0.357855\t0.513158\n",
    "# train_e9566_00004\tTERMINATED\t127.0.0.1:1896\t0.000747631\t6\t1\t0.715973\t1\t8.64184\t0.693078\t0.357727\t0.51345\n",
    "# train_e9566_00005\tTERMINATED\t127.0.0.1:15140\t0.022674\t2\t3\t0.728035\t2\t9.73432\t0.689457\t0.359819\t0.5\n",
    "# train_e9566_00006\tTERMINATED\t127.0.0.1:11076\t0.00664714\t7\t1\t0.523225\t1\t8.55218\t0.692498\t0.355293\t0.512156\n",
    "# train_e9566_00007\tTERMINATED\t127.0.0.1:6392\t0.0788671\t7\t2\t0.974443\t10\t24.4164\t0.650617\t0.348126\t0.520765\n",
    "# train_e9566_00008\tTERMINATED\t127.0.0.1:24340\t0.0112901\t1\t2\t0.548836\t1\t8.17584\t0.692232\t0.359819\t0.5\n",
    "# train_e9566_00009\tTERMINATED\t127.0.0.1:18876\t0.000331203\t7\t1\t0.916597\t1\t8.0835\t0.693115\t0.355767\t0.511753\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d30015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_best_model_checkpoint(analysis):\n",
    "#     best_bst = xgb.Booster()\n",
    "#     best_bst.load_model(os.path.join(analysis.best_checkpoint, \"model.xgb\")) # CHANGE THIS TO BEST OVERALL CKPT\n",
    "#     accuracy = 1. - analysis.best_result[\"eval-error\"]\n",
    "#     print(f\"Best model parameters: {analysis.best_config}\")\n",
    "#     print(f\"Best model total accuracy: {accuracy:.4f}\")\n",
    "#     return best_bst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a63dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5cebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = analysis.get_best_trial(\"train-error\", \"max\", scope=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fba400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis.get_best_checkpoint(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d234cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.dataframe(metric=\"eval-val_bal_acc\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e556d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683aa938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
