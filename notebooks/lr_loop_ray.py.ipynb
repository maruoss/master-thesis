{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082587ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1161467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune import CLIReporter\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff29d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3151c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    data: pandas.DataFrame that must have specific columns.\n",
    "\n",
    "    \"\"\"\n",
    "    # Bid-Ask spread: (Ask - Bid) / Ask\n",
    "    data[\"best_bid\"] = (data[\"best_offer\"] - data[\"best_bid\"]) / (data[\"best_offer\"])\n",
    "    data = data.rename(columns={\"best_bid\": \"ba_spread_option\"}).drop([\"best_offer\"], axis=1)\n",
    "\n",
    "    # Gamma: multiply by spotprice and divide by 100\n",
    "    data[\"gamma\"] = data[\"gamma\"] * data[\"spotprice\"] / 100 #following Bali et al. (2021)\n",
    "\n",
    "    # Theta: scale by spotprice\n",
    "    data[\"theta\"] = data[\"theta\"] / data[\"spotprice\"] #following Bali et al. (2021)\n",
    "\n",
    "    # Vega: scale by spotprice\n",
    "    data[\"vega\"] = data[\"vega\"] / data[\"spotprice\"] #following Bali et al. (2021)\n",
    "\n",
    "    # Time to Maturity: cale by number of days in year: 365\n",
    "    data[\"days_to_exp\"] = data[\"days_to_exp\"] / 365\n",
    "\n",
    "    # Moneyness: Strike / Spot (K / S)\n",
    "    data[\"strike_price\"] = data[\"strike_price\"] / data[\"spotprice\"] # K / S\n",
    "    data = data.rename(columns={\"strike_price\": \"moneyness\"})\n",
    "\n",
    "    # Forward Price ratio: Forward / Spot\n",
    "    data[\"forwardprice\"] = data[\"forwardprice\"] / data[\"spotprice\"]\n",
    "\n",
    "    # Drop redundant/ unimportant columns\n",
    "    data = data.drop([\"cfadj\", \"days_no_trading\", \"spotprice\", \"adj_spot\"], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd83d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary y label generator\n",
    "def binary_categorize(y):\n",
    "    \"\"\"\n",
    "    Input: continuous target variable \n",
    "\n",
    "    Output: 1 for positive returns, \n",
    "            0 for negative returns\n",
    "    \"\"\"\n",
    "    if y > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# multiclass y label generator\n",
    "def multi_categorize(y):\n",
    "    \"\"\"\n",
    "    Input: continuous target variable\n",
    "    CAREFUL: classes have to be between [0, C) for F.crossentropyloss.\n",
    "    \n",
    "    Output: multi class\n",
    "    \"\"\"\n",
    "    if y > 0.05:\n",
    "        return 2\n",
    "    elif y < -0.05:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaea3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVSplitter:\n",
    "    \"\"\" Generator for data splits\n",
    "    Args:\n",
    "    dates: pandas.Series of datetime,\n",
    "    init_train_length: int,\n",
    "    val_length: int\n",
    "    \"\"\"\n",
    "    def __init__(self, dates, init_train_length=10, val_length=2, test_length=1):\n",
    "        # find indeces where years change (will ignore last year end in dates)\n",
    "        self.val_length = val_length\n",
    "        self.test_length = test_length\n",
    "        self.eoy_idx =  np.where((dates.dt.year.diff() == 1))[0]\n",
    "        self.eoy_idx = np.append(self.eoy_idx, len(dates)) #append end of year of last year in dates\n",
    "\n",
    "        assert init_train_length + val_length + test_length <= len(self.eoy_idx) + 1, \\\n",
    "        \"defined train and val are larger than number of years in dataset\"\n",
    "        assert init_train_length > 0, \"init_train_length must be strictly greater than 0\"\n",
    "\n",
    "        # align the 4th idx to be the end of the 5th year...\n",
    "        self.train_start_idx = init_train_length - 1\n",
    "\n",
    "        self.train_eoy = self.eoy_idx[self.train_start_idx:-(val_length+test_length)]\n",
    "        self.val_eoy = self.eoy_idx[self.train_start_idx + val_length:-test_length]\n",
    "        # For generate_idx():\n",
    "        self.test_eoy = self.eoy_idx[self.train_start_idx + val_length + test_length:]\n",
    "\n",
    "    def generate(self):\n",
    "        for i in range(len(self.eoy_idx) - (self.train_start_idx + self.val_length)):\n",
    "            yield (list(range(self.train_eoy[i])),\n",
    "                   list(range(self.train_eoy[i], self.val_eoy[i])))\n",
    "\n",
    "    def generate_idx(self):\n",
    "        for i in range(len(self.eoy_idx) - (self.train_start_idx + self.val_length \n",
    "                        + self.test_length)):\n",
    "            yield ({\"train\": self.train_eoy[i], \n",
    "                    \"val\": self.val_eoy[i], \n",
    "                    \"test\": self.test_eoy[i]}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "787b79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from disk\n",
    "path = Path(r\"C:\\Users\\Mathiass\\OneDrive - UniversitÃ¤t ZÃ¼rich UZH\\Documents\\mt_literature\\data\")\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, path=path, year_idx=0, dataset=\"small\", init_train_length=23, val_length=2, label_fn=\"binary\"):\n",
    "        if dataset == \"small\":\n",
    "            self.data = pd.read_parquet(path/\"final_df_filledmean_small.parquet\")\n",
    "        elif dataset == \"big\":\n",
    "            self.data = pd.read_parquet(path/\"final_df_filledmean.parquet\")\n",
    "        else:\n",
    "            raise ValueError(\"Specify dataset as either 'small' or 'big'\")\n",
    "\n",
    "        # get splits\n",
    "        splitter = CVSplitter(self.data[\"date\"], init_train_length=init_train_length, \n",
    "                                val_length=val_length, test_length=1)\n",
    "        eoy_indeces = list(splitter.generate_idx())\n",
    "        self.eoy_train = eoy_indeces[year_idx][\"train\"]\n",
    "        self.eoy_val = eoy_indeces[year_idx][\"val\"]\n",
    "        self.eoy_test = eoy_indeces[year_idx][\"test\"]\n",
    "        \n",
    "        # Truncate data\n",
    "        self.data = self.data.iloc[:self.eoy_test]\n",
    "        assert len(self.data) == self.eoy_test, \"length of data is not equal to eoy_test\"\n",
    "            \n",
    "        # feature engineer data\n",
    "        self.data = feature_engineer(self.data)\n",
    "        \n",
    "        # create y\n",
    "        self.y = self.data[\"option_ret\"]\n",
    "        # make classification problem\n",
    "        if label_fn == \"binary\":\n",
    "            self.y = self.y.apply(binary_categorize)\n",
    "        elif label_fn == \"multi\":\n",
    "            self.y = self.y.apply(multi_categorize)\n",
    "        else:\n",
    "            raise ValueError(\"Specify label_fn as either 'binary' or 'multi'\")\n",
    "        # create X\n",
    "        self.X = self.data.drop([\"option_ret\"], axis=1)\n",
    "        \n",
    "        # save dates and drop\n",
    "        self.dates = self.X[\"date\"]\n",
    "        self.X = self.X.drop([\"date\"], axis=1)\n",
    "        \n",
    "#         # to torch Tensor\n",
    "#         self.X = torch.from_numpy(self.X.values).float() #-> will be standardized in setup, so do it there.\n",
    "#         self.y = torch.from_numpy(self.y.values)\n",
    "\n",
    "        # to numpy\n",
    "        self.X = self.X.values #-> will be standardized in setup, so do it there.\n",
    "        self.y = self.y.values\n",
    "    \n",
    "        ############################### setup #########################################################\n",
    "        # train\n",
    "        # self.X_train = self.X[self.dates < self.hparams.start_val]\n",
    "        self.X_train = self.X[:self.eoy_train]\n",
    "        self.y_train = self.y[:len(self.X_train)]\n",
    "        \n",
    "        #val\n",
    "        # mask = (self.dates >= self.hparams.start_val) & (self.dates < self.hparams.start_test)\n",
    "        # self.X_val = self.X[mask]\n",
    "        self.X_val = self.X[self.eoy_train:self.eoy_val]\n",
    "        self.y_val = self.y[len(self.X_train):len(self.X_train)+len(self.X_val)]\n",
    "        \n",
    "        # test\n",
    "        self.X_test = self.X[self.eoy_val:self.eoy_test]\n",
    "        self.y_test = self.y[-len(self.X_test):]\n",
    "        \n",
    "        assert (len(self.X_train)+len(self.X_val)+len(self.X_test)) == len(self.data), \\\n",
    "            \"sum of X train, val, test is not equal length of dataset\"\n",
    "        assert (len(self.y_train)+len(self.y_val)+len(self.y_test) == len(self.data)), \\\n",
    "        \"sum of y train, val, test is not equal to length of dataset\"\n",
    "        \n",
    "#         #standardize X_train\n",
    "#         mean = torch.mean(self.X_train, axis=0)\n",
    "#         std = torch.std(self.X_train, axis=0)\n",
    "        \n",
    "#         # Standardize X_train, X_val and X_test with mean/std from X_train\n",
    "#         self.X_train = (self.X_train - mean) / std\n",
    "#         self.X_val = (self.X_val - mean) / std\n",
    "#         self.X_test = (self.X_test - mean) / std\n",
    "\n",
    "        # Save variables\n",
    "        # input dim\n",
    "        self.input_dim = self.X_train.shape[1]\n",
    "        # number of classes\n",
    "        self.num_classes = len(np.unique(self.y_train))\n",
    "#         class weights\n",
    "        self.class_weights = len(self.y_train) / np.unique(self.y_train, return_counts=True)[1]\n",
    "        \n",
    "        print(\"*****************************************************************************************\")\n",
    "        print(\"Current dataset information:\")\n",
    "        print(\"---\")\n",
    "        print(\"class_weights:\", self.class_weights)\n",
    "        print(\"---\")\n",
    "        print(f\"# of input data: {len(self.data)} with shape: {self.data.shape}\")\n",
    "        print(f\"# of training samples: {len(self.y_train)} with X_train of shape: {self.X_train.shape}\")\n",
    "        print(f\"# of validation samples: {len(self.y_val)} with X_val of shape: {self.X_val.shape}\")\n",
    "        print(f\"# of test samples: {len(self.y_test)} with X_test of shape: {self.X_test.shape}\")\n",
    "        print(\"---\")\n",
    "        print(f\"train start date: \", self.dates.iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", train end date: \", self.dates.iloc[:self.eoy_train].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(f\"val start date: \", self.dates.iloc[self.eoy_train:self.eoy_val].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", val end date: \", self.dates.iloc[self.eoy_train:self.eoy_val].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(f\"test start date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", test end date: \", self.dates.iloc[self.eoy_val:self.eoy_test].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(\"*****************************************************************************************\")\n",
    "        \n",
    "    def get_datasets(self):\n",
    "        return self.X_train, self.X_val, self.X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67adb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_lr_tune(config, data):\n",
    "    # needed for reproducibility, will seed trainer (init of weights in NN?)\n",
    "    pl.seed_everything(42, workers=True)\n",
    "\n",
    "    data = data\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(), \n",
    "                        SGDClassifier(\n",
    "                        max_iter=config[\"num_epochs\"],\n",
    "                        class_weight=\"balanced\",\n",
    "                        alpha=config[\"alpha\"],\n",
    "#                         epsilon=config[\"epsilon\"],\n",
    "                        tol=1e-3,\n",
    "                        verbose=3,\n",
    "                        n_jobs=-1,\n",
    "                        ))\n",
    "    \n",
    "    clf.fit(data.X_train, data.y_train)\n",
    "    \n",
    "    y_pred = clf.predict(data.X_val)\n",
    "    \n",
    "    val_bal_acc = balanced_accuracy_score(data.y_val, y_pred)\n",
    "    \n",
    "    tune.report(val_bal_acc=val_bal_acc)\n",
    "\n",
    "    return {\"val_bal_acc\": val_bal_acc}\n",
    "\n",
    "\n",
    "def lr_tune():\n",
    "    \n",
    "    # Example parameters to tune from SGDClassifier\n",
    "    config = {\n",
    "                \"alpha\": tune.choice([1e-4, 1e-1, 1]),\n",
    "                \"num_epochs\": tune.choice([100, 1000]),\n",
    "#               \"epsilon\": [0.01, 0.1\n",
    "             }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=1,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=[\"alpha\"],\n",
    "        metric_columns=[\"val_bal_acc\"])\n",
    "    \n",
    "    data = Dataset()\n",
    "\n",
    "    train_fn_with_parameters = tune.with_parameters(inner_lr_tune,\n",
    "                                                    data=data,\n",
    "#                                                     args=args,\n",
    "#                                                     year_idx=year_idx,\n",
    "#                                                     ckpt_path=ckpt_path,\n",
    "                                                   )\n",
    "    resources_per_trial = {\"cpu\": 8, \"gpu\": 0}\n",
    "\n",
    "    # Set logging directory for tune.run\n",
    "    log_dir = \"./logs/tune/lr_loops\"\n",
    "    time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "#     # name = time+\"_\"+string_from_config(config) # config into path \n",
    "#     # CAREFUL: will give error if directory path is too large\n",
    "#     train_year_end = 1996 + args.init_train_length + year_idx - 1\n",
    "#     val_year_end = train_year_end + args.val_length\n",
    "#     years = f\"train{train_year_end}_val{val_year_end}\"\n",
    "    name = time\n",
    "\n",
    "#     # save config space as .json\n",
    "#     summary_path = Path.cwd()/log_dir/time\n",
    "#     summary_path.mkdir(exist_ok=True, parents=True)\n",
    "#     with open(summary_path/\"config.json\", 'w') as f:\n",
    "#         json.dump(serialize_config(config), fp=f, indent=3)\n",
    "\n",
    "#     # save args to json\n",
    "#     args_dict = serialize_args(args.__dict__) #functions are not serializable\n",
    "#     with open(summary_path/'args.json', 'w') as f:\n",
    "#         json.dump(args_dict, f, indent=3)\n",
    "\n",
    "\n",
    "    analysis = tune.run(train_fn_with_parameters,\n",
    "        local_dir=log_dir,\n",
    "        resources_per_trial=resources_per_trial,\n",
    "        metric=\"val_bal_acc\",\n",
    "        mode=\"max\",\n",
    "        config=config,\n",
    "        num_samples=10,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        name=name,\n",
    "        fail_fast=True, # stop all trials as soon as any trial errors\n",
    "#         keep_checkpoints_num=1, # only keep best checkpoint\n",
    "#         checkpoint_score_attr=\"min-val_loss\",\n",
    "        )\n",
    "\n",
    "#     print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "    \n",
    "#     best_last_trial = analysis.get_best_trial(\"val_bal_acc\", \"max\", \"last\") #change \"last\" to \"all\" for global min\n",
    "# #     print(\"Best trial among last epoch config: {}\".format(best_last_trial.config))\n",
    "# #     print(\"Best trial >>last epoch<< validation loss: {}\".format(\n",
    "# #         best_last_trial.last_result[\"val_loss\"]))\n",
    "#     print(\"Best trial >>last epoch<< validation balanced accuracy: {}\".format(\n",
    "#         best_last_trial.last_result[\"val_bal_acc\"]))\n",
    "    \n",
    "\n",
    "#     best_result_per_trial_df = analysis.dataframe(metric=\"val_loss\", \n",
    "#                                             mode=\"min\").sort_values(\"val_loss\")\n",
    "#     # save df to folder?\n",
    "#     best_result = best_result_per_trial_df.iloc[0, :].to_dict() #take best values of best trial\n",
    "\n",
    "#     # test prediction: best checkpoint out of all trials\n",
    "#     best_trial = analysis.get_best_trial(\"val_loss\", \"min\", scope=\"all\")\n",
    "#     if args.refit:\n",
    "#         config = best_trial.config\n",
    "#         ckpt_path = Path(analysis.get_best_checkpoint(best_trial).get_internal_representation()[1], \"checkpoint\")\n",
    "    \n",
    "#     if not args.no_predict:\n",
    "#         best_path = Path(analysis.get_best_checkpoint(best_trial).get_internal_representation()[1], \"checkpoint\")\n",
    "#         print(f\"Loading model from path at {ckpt_path}\")\n",
    "#         model = FFN.load_from_checkpoint(best_path)\n",
    "#         dm = MyDataModule_Loop(\n",
    "#             path=args.path_data,\n",
    "#             year_idx=year_idx,\n",
    "#             dataset=args.dataset,\n",
    "#             batch_size=1, #any number, doesnt matter for predict\n",
    "#             init_train_length=args.init_train_length,\n",
    "#             val_length=args.val_length,\n",
    "#             label_fn=args.label_fn,\n",
    "#             # config=model.hparams.config, # so that config is not hyperparam search again\n",
    "#         )\n",
    "#         trainer = pl.Trainer(\n",
    "#             deterministic=True,\n",
    "#             gpus=args.gpus_per_trial,\n",
    "#         )\n",
    "#         preds = trainer.predict(model=model, datamodule=dm)\n",
    "#         preds_argmax = preds[0].argmax(dim=1).numpy() # assumes batchsize is whole testset\n",
    "#         preds_argmax_df = pd.DataFrame(preds_argmax, columns=[\"pred\"])\n",
    "#         test_year_end = val_year_end + args.test_length\n",
    "#         # prediction path\n",
    "#         save_to_dir = Path(Path.cwd(),log_dir, name, f\"prediction{test_year_end}.csv\")\n",
    "#         preds_argmax_df.to_csv(save_to_dir, index_label=\"id\")\n",
    "        \n",
    "#     return best_result, summary_path, ckpt_path, config \n",
    "    #dictionary of best metrics and config, path\n",
    "    return analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a9ce35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************\n",
      "Current dataset information:\n",
      "---\n",
      "class_weights: [1.56424512 2.77227938]\n",
      "---\n",
      "# of input data: 3823386 with shape: (3823386, 17)\n",
      "# of training samples: 2780818 with X_train of shape: (2780818, 15)\n",
      "# of validation samples: 647992 with X_val of shape: (647992, 15)\n",
      "# of test samples: 394576 with X_test of shape: (394576, 15)\n",
      "---\n",
      "train start date:  1996-01-31 , train end date:  2018-12-31\n",
      "val start date:  2019-01-31 , val end date:  2020-12-31\n",
      "test start date:  2021-01-31 , test end date:  2021-11-30\n",
      "*****************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 15:21:28,100\tWARNING function_runner.py:603 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2022-07-20 15:21:28,232\tWARNING tune.py:668 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n",
      "2022-07-20 15:21:28,403\tERROR syncer.py:147 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-20 15:21:28 (running for 00:00:00.18)\n",
      "Memory usage on this node: 8.9/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+---------------------------+----------+----------------+---------+\n",
      "| Trial name                | status   | loc            |   alpha |\n",
      "|---------------------------+----------+----------------+---------|\n",
      "| inner_lr_tune_dc9c1_00000 | RUNNING  | 127.0.0.1:5300 |  1      |\n",
      "| inner_lr_tune_dc9c1_00001 | PENDING  |                |  0.1    |\n",
      "| inner_lr_tune_dc9c1_00002 | PENDING  |                |  1      |\n",
      "| inner_lr_tune_dc9c1_00003 | PENDING  |                |  0.1    |\n",
      "| inner_lr_tune_dc9c1_00004 | PENDING  |                |  1      |\n",
      "| inner_lr_tune_dc9c1_00005 | PENDING  |                |  1      |\n",
      "| inner_lr_tune_dc9c1_00006 | PENDING  |                |  0.1    |\n",
      "| inner_lr_tune_dc9c1_00007 | PENDING  |                |  0.1    |\n",
      "| inner_lr_tune_dc9c1_00008 | PENDING  |                |  0.0001 |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING  |                |  0.1    |\n",
      "+---------------------------+----------+----------------+---------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012499, T: 2780818, Avg. loss: 0.992015\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.57 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012516, T: 5561636, Avg. loss: 0.992007\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.16 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012546, T: 8342454, Avg. loss: 0.992031\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.73 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012571, T: 11123272, Avg. loss: 0.992066\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.29 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012578, T: 13904090, Avg. loss: 0.992029\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.85 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012567, T: 16684908, Avg. loss: 0.992018\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.40 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 3.40 seconds\n",
      "Result for inner_lr_tune_dc9c1_00000:\n",
      "  date: 2022-07-20_15-21-38\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.004813194274902\n",
      "  time_this_iter_s: 5.004813194274902\n",
      "  time_total_s: 5.004813194274902\n",
      "  timestamp: 1658323298\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00000\n",
      "  val_bal_acc: 0.518135881424077\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:21:38 (running for 00:00:10.61)\n",
      "Memory usage on this node: 9.7/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+---------------------------+----------+----------------+---------+---------------+\n",
      "| Trial name                | status   | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+----------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00000 | RUNNING  | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | PENDING  |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00002 | PENDING  |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00003 | PENDING  |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00004 | PENDING  |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00005 | PENDING  |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00006 | PENDING  |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00007 | PENDING  |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00008 | PENDING  |                |  0.0001 |               |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING  |                |  0.1    |               |\n",
      "+---------------------------+----------+----------------+---------+---------------+\n",
      "\n",
      "\n",
      "Result for inner_lr_tune_dc9c1_00000:\n",
      "  date: 2022-07-20_15-21-38\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 0_alpha=1,num_epochs=100\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.004813194274902\n",
      "  time_this_iter_s: 5.004813194274902\n",
      "  time_total_s: 5.004813194274902\n",
      "  timestamp: 1658323298\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00000\n",
      "  val_bal_acc: 0.518135881424077\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.105420, T: 2780818, Avg. loss: 0.982937\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.68 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103530, T: 5561636, Avg. loss: 0.984454\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.25 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103973, T: 8342454, Avg. loss: 0.984431\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.85 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103983, T: 11123272, Avg. loss: 0.984622\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.39 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104379, T: 13904090, Avg. loss: 0.984533\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.93 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104679, T: 16684908, Avg. loss: 0.984387\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.54 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 3.54 seconds\n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:21:43 (running for 00:00:15.70)\n",
      "Memory usage on this node: 9.9/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00001 | RUNNING    | 127.0.0.1:5300 |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00002 | PENDING    |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00003 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00004 | PENDING    |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00005 | PENDING    |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00006 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00007 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00008 | PENDING    |                |  0.0001 |               |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n",
      "Result for inner_lr_tune_dc9c1_00001:\n",
      "  date: 2022-07-20_15-21-44\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.13308048248291\n",
      "  time_this_iter_s: 5.13308048248291\n",
      "  time_total_s: 5.13308048248291\n",
      "  timestamp: 1658323304\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00001\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for inner_lr_tune_dc9c1_00001:\n",
      "  date: 2022-07-20_15-21-44\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 1_alpha=0.1000,num_epochs=100\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.13308048248291\n",
      "  time_this_iter_s: 5.13308048248291\n",
      "  time_total_s: 5.13308048248291\n",
      "  timestamp: 1658323304\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00001\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012499, T: 2780818, Avg. loss: 0.992015\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.68 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012516, T: 5561636, Avg. loss: 0.992007\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.34 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012546, T: 8342454, Avg. loss: 0.992031\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.98 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012571, T: 11123272, Avg. loss: 0.992066\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.58 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012578, T: 13904090, Avg. loss: 0.992029\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.12 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012567, T: 16684908, Avg. loss: 0.992018\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.66 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 3.66 seconds\n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:21:49 (running for 00:00:20.91)\n",
      "Memory usage on this node: 9.9/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00002 | RUNNING    | 127.0.0.1:5300 |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00003 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00004 | PENDING    |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00005 | PENDING    |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00006 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00007 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00008 | PENDING    |                |  0.0001 |               |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n",
      "Result for inner_lr_tune_dc9c1_00002:\n",
      "  date: 2022-07-20_15-21-49\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.1993327140808105\n",
      "  time_this_iter_s: 5.1993327140808105\n",
      "  time_total_s: 5.1993327140808105\n",
      "  timestamp: 1658323309\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00002\n",
      "  val_bal_acc: 0.518135881424077\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for inner_lr_tune_dc9c1_00002:\n",
      "  date: 2022-07-20_15-21-49\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 2_alpha=1,num_epochs=100\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.1993327140808105\n",
      "  time_this_iter_s: 5.1993327140808105\n",
      "  time_total_s: 5.1993327140808105\n",
      "  timestamp: 1658323309\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00002\n",
      "  val_bal_acc: 0.518135881424077\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.105420, T: 2780818, Avg. loss: 0.982937\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.72 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103530, T: 5561636, Avg. loss: 0.984454\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.39 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103973, T: 8342454, Avg. loss: 0.984431\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.96 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103983, T: 11123272, Avg. loss: 0.984622\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.55 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104379, T: 13904090, Avg. loss: 0.984533\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.10 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:21:54 (running for 00:00:26.14)\n",
      "Memory usage on this node: 10.0/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00003 | RUNNING    | 127.0.0.1:5300 |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00004 | PENDING    |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00005 | PENDING    |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00006 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00007 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00008 | PENDING    |                |  0.0001 |               |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00002 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104679, T: 16684908, Avg. loss: 0.984387\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.67 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 3.67 seconds\n",
      "Result for inner_lr_tune_dc9c1_00003:\n",
      "  date: 2022-07-20_15-21-54\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.176681995391846\n",
      "  time_this_iter_s: 5.176681995391846\n",
      "  time_total_s: 5.176681995391846\n",
      "  timestamp: 1658323314\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00003\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for inner_lr_tune_dc9c1_00003:\n",
      "  date: 2022-07-20_15-21-54\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 3_alpha=0.1000,num_epochs=1000\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.176681995391846\n",
      "  time_this_iter_s: 5.176681995391846\n",
      "  time_total_s: 5.176681995391846\n",
      "  timestamp: 1658323314\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00003\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012499, T: 2780818, Avg. loss: 0.992015\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.67 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012516, T: 5561636, Avg. loss: 0.992007\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.27 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012546, T: 8342454, Avg. loss: 0.992031\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.82 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012571, T: 11123272, Avg. loss: 0.992066\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.38 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012578, T: 13904090, Avg. loss: 0.992029\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.93 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012567, T: 16684908, Avg. loss: 0.992018\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.49 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 3.49 seconds\n",
      "Result for inner_lr_tune_dc9c1_00004:\n",
      "  date: 2022-07-20_15-21-59\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 4.954103946685791\n",
      "  time_this_iter_s: 4.954103946685791\n",
      "  time_total_s: 4.954103946685791\n",
      "  timestamp: 1658323319\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00004\n",
      "  val_bal_acc: 0.518135881424077\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:21:59 (running for 00:00:31.31)\n",
      "Memory usage on this node: 9.8/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00004 | RUNNING    | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00005 | PENDING    |                |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00006 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00007 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00008 | PENDING    |                |  0.0001 |               |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00002 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00003 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n",
      "Result for inner_lr_tune_dc9c1_00004:\n",
      "  date: 2022-07-20_15-21-59\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 4_alpha=1,num_epochs=1000\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 4.954103946685791\n",
      "  time_this_iter_s: 4.954103946685791\n",
      "  time_total_s: 4.954103946685791\n",
      "  timestamp: 1658323319\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00004\n",
      "  val_bal_acc: 0.518135881424077\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012499, T: 2780818, Avg. loss: 0.992015\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.65 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012516, T: 5561636, Avg. loss: 0.992007\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.26 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012546, T: 8342454, Avg. loss: 0.992031\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.85 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012571, T: 11123272, Avg. loss: 0.992066\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.43 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012578, T: 13904090, Avg. loss: 0.992029\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.99 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.11, NNZs: 15, Bias: 0.012567, T: 16684908, Avg. loss: 0.992018\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.55 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 3.55 seconds\n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:22:04 (running for 00:00:36.39)\n",
      "Memory usage on this node: 10.0/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00005 | RUNNING    | 127.0.0.1:5300 |  1      |               |\n",
      "| inner_lr_tune_dc9c1_00006 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00007 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00008 | PENDING    |                |  0.0001 |               |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00002 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00003 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00004 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n",
      "Result for inner_lr_tune_dc9c1_00005:\n",
      "  date: 2022-07-20_15-22-04\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.056656360626221\n",
      "  time_this_iter_s: 5.056656360626221\n",
      "  time_total_s: 5.056656360626221\n",
      "  timestamp: 1658323324\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00005\n",
      "  val_bal_acc: 0.518135881424077\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for inner_lr_tune_dc9c1_00005:\n",
      "  date: 2022-07-20_15-22-04\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 5_alpha=1,num_epochs=100\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.056656360626221\n",
      "  time_this_iter_s: 5.056656360626221\n",
      "  time_total_s: 5.056656360626221\n",
      "  timestamp: 1658323324\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00005\n",
      "  val_bal_acc: 0.518135881424077\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.105420, T: 2780818, Avg. loss: 0.982937\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.65 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103530, T: 5561636, Avg. loss: 0.984454\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.25 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103973, T: 8342454, Avg. loss: 0.984431\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.78 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103983, T: 11123272, Avg. loss: 0.984622\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.32 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104379, T: 13904090, Avg. loss: 0.984533\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.86 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104679, T: 16684908, Avg. loss: 0.984387\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.38 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 3.38 seconds\n",
      "Result for inner_lr_tune_dc9c1_00006:\n",
      "  date: 2022-07-20_15-22-09\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 4.878317356109619\n",
      "  time_this_iter_s: 4.878317356109619\n",
      "  time_total_s: 4.878317356109619\n",
      "  timestamp: 1658323329\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00006\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for inner_lr_tune_dc9c1_00006:\n",
      "  date: 2022-07-20_15-22-09\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 6_alpha=0.1000,num_epochs=100\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 4.878317356109619\n",
      "  time_this_iter_s: 4.878317356109619\n",
      "  time_total_s: 4.878317356109619\n",
      "  timestamp: 1658323329\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00006\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:22:09 (running for 00:00:41.40)\n",
      "Memory usage on this node: 9.4/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00007 | RUNNING    | 127.0.0.1:5300 |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00008 | PENDING    |                |  0.0001 |               |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00002 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00003 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00004 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00005 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00006 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.105420, T: 2780818, Avg. loss: 0.982937\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.64 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103530, T: 5561636, Avg. loss: 0.984454\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.21 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103973, T: 8342454, Avg. loss: 0.984431\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.76 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103983, T: 11123272, Avg. loss: 0.984622\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.31 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104379, T: 13904090, Avg. loss: 0.984533\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.86 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104679, T: 16684908, Avg. loss: 0.984387\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.41 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 3.41 seconds\n",
      "Result for inner_lr_tune_dc9c1_00007:\n",
      "  date: 2022-07-20_15-22-14\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 4.895936489105225\n",
      "  time_this_iter_s: 4.895936489105225\n",
      "  time_total_s: 4.895936489105225\n",
      "  timestamp: 1658323334\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00007\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for inner_lr_tune_dc9c1_00007:\n",
      "  date: 2022-07-20_15-22-14\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 7_alpha=0.1000,num_epochs=100\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 4.895936489105225\n",
      "  time_this_iter_s: 4.895936489105225\n",
      "  time_total_s: 4.895936489105225\n",
      "  timestamp: 1658323334\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00007\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.54, NNZs: 15, Bias: 0.051532, T: 2780818, Avg. loss: 1.067967\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.68 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.63, NNZs: 15, Bias: 0.117019, T: 5561636, Avg. loss: 0.983015\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.26 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.56, NNZs: 15, Bias: 0.075266, T: 8342454, Avg. loss: 0.986419\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.83 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.61, NNZs: 15, Bias: 0.145016, T: 11123272, Avg. loss: 0.987935\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.40 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.62, NNZs: 15, Bias: 0.106584, T: 13904090, Avg. loss: 0.988992\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.97 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.65, NNZs: 15, Bias: 0.107164, T: 16684908, Avg. loss: 0.989361\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.53 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 7\n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:22:19 (running for 00:00:51.40)\n",
      "Memory usage on this node: 10.2/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00008 | RUNNING    | 127.0.0.1:5300 |  0.0001 |               |\n",
      "| inner_lr_tune_dc9c1_00009 | PENDING    |                |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00002 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00003 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00004 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00005 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00006 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00007 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.64, NNZs: 15, Bias: 0.149392, T: 19465726, Avg. loss: 0.989925\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 4.11 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 7 epochs took 4.11 seconds\n",
      "Result for inner_lr_tune_dc9c1_00008:\n",
      "  date: 2022-07-20_15-22-20\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.591873407363892\n",
      "  time_this_iter_s: 5.591873407363892\n",
      "  time_total_s: 5.591873407363892\n",
      "  timestamp: 1658323340\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00008\n",
      "  val_bal_acc: 0.5083944495302217\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for inner_lr_tune_dc9c1_00008:\n",
      "  date: 2022-07-20_15-22-20\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 8_alpha=0.0001,num_epochs=100\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.591873407363892\n",
      "  time_this_iter_s: 5.591873407363892\n",
      "  time_total_s: 5.591873407363892\n",
      "  timestamp: 1658323340\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00008\n",
      "  val_bal_acc: 0.5083944495302217\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 1\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.105420, T: 2780818, Avg. loss: 0.982937\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 0.71 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 2\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103530, T: 5561636, Avg. loss: 0.984454\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 1.48 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 3\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103973, T: 8342454, Avg. loss: 0.984431\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.19 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 4\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.103983, T: 11123272, Avg. loss: 0.984622\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 2.87 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 5\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104379, T: 13904090, Avg. loss: 0.984533\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 3.56 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m -- Epoch 6\n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:22:25 (running for 00:00:57.05)\n",
      "Memory usage on this node: 10.3/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00009 | RUNNING    | 127.0.0.1:5300 |  0.1    |               |\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00002 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00003 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00004 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00005 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00006 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00007 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00008 | TERMINATED | 127.0.0.1:5300 |  0.0001 |      0.508394 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Norm: 0.49, NNZs: 15, Bias: 0.104679, T: 16684908, Avg. loss: 0.984387\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Total training time: 4.18 seconds.\n",
      "\u001b[2m\u001b[36m(inner_lr_tune pid=5300)\u001b[0m Convergence after 6 epochs took 4.18 seconds\n",
      "Result for inner_lr_tune_dc9c1_00009:\n",
      "  date: 2022-07-20_15-22-25\n",
      "  done: false\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.726902723312378\n",
      "  time_this_iter_s: 5.726902723312378\n",
      "  time_total_s: 5.726902723312378\n",
      "  timestamp: 1658323345\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00009\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for inner_lr_tune_dc9c1_00009:\n",
      "  date: 2022-07-20_15-22-25\n",
      "  done: true\n",
      "  experiment_id: 4bbc8164df634919b5183aad5e458b1e\n",
      "  experiment_tag: 9_alpha=0.1000,num_epochs=100\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 5300\n",
      "  time_since_restore: 5.726902723312378\n",
      "  time_this_iter_s: 5.726902723312378\n",
      "  time_total_s: 5.726902723312378\n",
      "  timestamp: 1658323345\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: dc9c1_00009\n",
      "  val_bal_acc: 0.5083311837995531\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-20 15:22:26 (running for 00:00:57.79)\n",
      "Memory usage on this node: 9.5/15.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/5.41 GiB heap, 0.0/2.71 GiB objects\n",
      "Current best trial: dc9c1_00000 with val_bal_acc=0.518135881424077 and parameters={'alpha': 1}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune\\lr_loops\\20220720152120\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "| Trial name                | status     | loc            |   alpha |   val_bal_acc |\n",
      "|---------------------------+------------+----------------+---------+---------------|\n",
      "| inner_lr_tune_dc9c1_00000 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00001 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00002 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00003 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00004 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00005 | TERMINATED | 127.0.0.1:5300 |  1      |      0.518136 |\n",
      "| inner_lr_tune_dc9c1_00006 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00007 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "| inner_lr_tune_dc9c1_00008 | TERMINATED | 127.0.0.1:5300 |  0.0001 |      0.508394 |\n",
      "| inner_lr_tune_dc9c1_00009 | TERMINATED | 127.0.0.1:5300 |  0.1    |      0.508331 |\n",
      "+---------------------------+------------+----------------+---------+---------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 15:22:26,135\tINFO tune.py:747 -- Total run time: 58.04 seconds (57.78 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-20 15:22:26,183\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\python.exe\" C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=61993 --object-store-name=tcp://127.0.0.1:64005 --raylet-name=tcp://127.0.0.1:64299 --redis-address=None --storage=None --temp-dir=C:\\Users\\Mathiass\\AppData\\Local\\Temp\\ray --metrics-agent-port=64240 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:63954 --redis-password=5241590000000000 --startup-token=8 --runtime-env-hash=137120697\n"
     ]
    }
   ],
   "source": [
    "analysis = lr_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd0e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60.82 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4d2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dc9c1_00000': {'val_bal_acc': 0.518135881424077,\n",
       "  'time_this_iter_s': 5.004813194274902,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00000',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-21-38',\n",
       "  'timestamp': 1658323298,\n",
       "  'time_total_s': 5.004813194274902,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 1, 'num_epochs': 100},\n",
       "  'time_since_restore': 5.004813194274902,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '0_alpha=1,num_epochs=100'},\n",
       " 'dc9c1_00001': {'val_bal_acc': 0.5083311837995531,\n",
       "  'time_this_iter_s': 5.13308048248291,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00001',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-21-44',\n",
       "  'timestamp': 1658323304,\n",
       "  'time_total_s': 5.13308048248291,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 0.1, 'num_epochs': 100},\n",
       "  'time_since_restore': 5.13308048248291,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '1_alpha=0.1000,num_epochs=100'},\n",
       " 'dc9c1_00002': {'val_bal_acc': 0.518135881424077,\n",
       "  'time_this_iter_s': 5.1993327140808105,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00002',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-21-49',\n",
       "  'timestamp': 1658323309,\n",
       "  'time_total_s': 5.1993327140808105,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 1, 'num_epochs': 100},\n",
       "  'time_since_restore': 5.1993327140808105,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '2_alpha=1,num_epochs=100'},\n",
       " 'dc9c1_00003': {'val_bal_acc': 0.5083311837995531,\n",
       "  'time_this_iter_s': 5.176681995391846,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00003',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-21-54',\n",
       "  'timestamp': 1658323314,\n",
       "  'time_total_s': 5.176681995391846,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 0.1, 'num_epochs': 1000},\n",
       "  'time_since_restore': 5.176681995391846,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '3_alpha=0.1000,num_epochs=1000'},\n",
       " 'dc9c1_00004': {'val_bal_acc': 0.518135881424077,\n",
       "  'time_this_iter_s': 4.954103946685791,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00004',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-21-59',\n",
       "  'timestamp': 1658323319,\n",
       "  'time_total_s': 4.954103946685791,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 1, 'num_epochs': 1000},\n",
       "  'time_since_restore': 4.954103946685791,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '4_alpha=1,num_epochs=1000'},\n",
       " 'dc9c1_00005': {'val_bal_acc': 0.518135881424077,\n",
       "  'time_this_iter_s': 5.056656360626221,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00005',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-22-04',\n",
       "  'timestamp': 1658323324,\n",
       "  'time_total_s': 5.056656360626221,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 1, 'num_epochs': 100},\n",
       "  'time_since_restore': 5.056656360626221,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '5_alpha=1,num_epochs=100'},\n",
       " 'dc9c1_00006': {'val_bal_acc': 0.5083311837995531,\n",
       "  'time_this_iter_s': 4.878317356109619,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00006',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-22-09',\n",
       "  'timestamp': 1658323329,\n",
       "  'time_total_s': 4.878317356109619,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 0.1, 'num_epochs': 100},\n",
       "  'time_since_restore': 4.878317356109619,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '6_alpha=0.1000,num_epochs=100'},\n",
       " 'dc9c1_00007': {'val_bal_acc': 0.5083311837995531,\n",
       "  'time_this_iter_s': 4.895936489105225,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00007',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-22-14',\n",
       "  'timestamp': 1658323334,\n",
       "  'time_total_s': 4.895936489105225,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 0.1, 'num_epochs': 100},\n",
       "  'time_since_restore': 4.895936489105225,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '7_alpha=0.1000,num_epochs=100'},\n",
       " 'dc9c1_00008': {'val_bal_acc': 0.5083944495302217,\n",
       "  'time_this_iter_s': 5.591873407363892,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00008',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-22-20',\n",
       "  'timestamp': 1658323340,\n",
       "  'time_total_s': 5.591873407363892,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 0.0001, 'num_epochs': 100},\n",
       "  'time_since_restore': 5.591873407363892,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '8_alpha=0.0001,num_epochs=100'},\n",
       " 'dc9c1_00009': {'val_bal_acc': 0.5083311837995531,\n",
       "  'time_this_iter_s': 5.726902723312378,\n",
       "  'done': True,\n",
       "  'timesteps_total': None,\n",
       "  'episodes_total': None,\n",
       "  'training_iteration': 1,\n",
       "  'trial_id': 'dc9c1_00009',\n",
       "  'experiment_id': '4bbc8164df634919b5183aad5e458b1e',\n",
       "  'date': '2022-07-20_15-22-25',\n",
       "  'timestamp': 1658323345,\n",
       "  'time_total_s': 5.726902723312378,\n",
       "  'pid': 5300,\n",
       "  'hostname': 'Mathias',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'alpha': 0.1, 'num_epochs': 100},\n",
       "  'time_since_restore': 5.726902723312378,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1,\n",
       "  'warmup_time': 0.005000591278076172,\n",
       "  'experiment_tag': '9_alpha=0.1000,num_epochs=100'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03750396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f945b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf603e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_bal_acc</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>config/alpha</th>\n",
       "      <th>config/num_epochs</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.508331</td>\n",
       "      <td>5.133080</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00001</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-21-44</td>\n",
       "      <td>1658323304</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>5.133080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.508331</td>\n",
       "      <td>5.176682</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00003</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-21-54</td>\n",
       "      <td>1658323314</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>5.176682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.508331</td>\n",
       "      <td>4.878317</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00006</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-22-09</td>\n",
       "      <td>1658323329</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>4.878317</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.508331</td>\n",
       "      <td>4.895936</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00007</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-22-14</td>\n",
       "      <td>1658323334</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>4.895936</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.508331</td>\n",
       "      <td>5.726903</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00009</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-22-25</td>\n",
       "      <td>1658323345</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>5.726903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>100</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.508394</td>\n",
       "      <td>5.591873</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00008</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-22-20</td>\n",
       "      <td>1658323340</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>5.591873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518136</td>\n",
       "      <td>5.004813</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00000</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-21-38</td>\n",
       "      <td>1658323298</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>5.004813</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.518136</td>\n",
       "      <td>5.199333</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00002</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-21-49</td>\n",
       "      <td>1658323309</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>5.199333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.518136</td>\n",
       "      <td>4.954104</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00004</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-21-59</td>\n",
       "      <td>1658323319</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>4.954104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1000</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.518136</td>\n",
       "      <td>5.056656</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9c1_00005</td>\n",
       "      <td>4bbc8164df634919b5183aad5e458b1e</td>\n",
       "      <td>2022-07-20_15-22-04</td>\n",
       "      <td>1658323324</td>\n",
       "      <td>...</td>\n",
       "      <td>5300</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>5.056656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_bal_acc  time_this_iter_s   done  timesteps_total  episodes_total  \\\n",
       "1     0.508331          5.133080  False              NaN             NaN   \n",
       "3     0.508331          5.176682  False              NaN             NaN   \n",
       "6     0.508331          4.878317  False              NaN             NaN   \n",
       "7     0.508331          4.895936  False              NaN             NaN   \n",
       "9     0.508331          5.726903  False              NaN             NaN   \n",
       "8     0.508394          5.591873  False              NaN             NaN   \n",
       "0     0.518136          5.004813  False              NaN             NaN   \n",
       "2     0.518136          5.199333  False              NaN             NaN   \n",
       "4     0.518136          4.954104  False              NaN             NaN   \n",
       "5     0.518136          5.056656  False              NaN             NaN   \n",
       "\n",
       "   training_iteration     trial_id                     experiment_id  \\\n",
       "1                   1  dc9c1_00001  4bbc8164df634919b5183aad5e458b1e   \n",
       "3                   1  dc9c1_00003  4bbc8164df634919b5183aad5e458b1e   \n",
       "6                   1  dc9c1_00006  4bbc8164df634919b5183aad5e458b1e   \n",
       "7                   1  dc9c1_00007  4bbc8164df634919b5183aad5e458b1e   \n",
       "9                   1  dc9c1_00009  4bbc8164df634919b5183aad5e458b1e   \n",
       "8                   1  dc9c1_00008  4bbc8164df634919b5183aad5e458b1e   \n",
       "0                   1  dc9c1_00000  4bbc8164df634919b5183aad5e458b1e   \n",
       "2                   1  dc9c1_00002  4bbc8164df634919b5183aad5e458b1e   \n",
       "4                   1  dc9c1_00004  4bbc8164df634919b5183aad5e458b1e   \n",
       "5                   1  dc9c1_00005  4bbc8164df634919b5183aad5e458b1e   \n",
       "\n",
       "                  date   timestamp  ...   pid  hostname    node_ip  \\\n",
       "1  2022-07-20_15-21-44  1658323304  ...  5300   Mathias  127.0.0.1   \n",
       "3  2022-07-20_15-21-54  1658323314  ...  5300   Mathias  127.0.0.1   \n",
       "6  2022-07-20_15-22-09  1658323329  ...  5300   Mathias  127.0.0.1   \n",
       "7  2022-07-20_15-22-14  1658323334  ...  5300   Mathias  127.0.0.1   \n",
       "9  2022-07-20_15-22-25  1658323345  ...  5300   Mathias  127.0.0.1   \n",
       "8  2022-07-20_15-22-20  1658323340  ...  5300   Mathias  127.0.0.1   \n",
       "0  2022-07-20_15-21-38  1658323298  ...  5300   Mathias  127.0.0.1   \n",
       "2  2022-07-20_15-21-49  1658323309  ...  5300   Mathias  127.0.0.1   \n",
       "4  2022-07-20_15-21-59  1658323319  ...  5300   Mathias  127.0.0.1   \n",
       "5  2022-07-20_15-22-04  1658323324  ...  5300   Mathias  127.0.0.1   \n",
       "\n",
       "  time_since_restore  timesteps_since_restore  iterations_since_restore  \\\n",
       "1           5.133080                        0                         1   \n",
       "3           5.176682                        0                         1   \n",
       "6           4.878317                        0                         1   \n",
       "7           4.895936                        0                         1   \n",
       "9           5.726903                        0                         1   \n",
       "8           5.591873                        0                         1   \n",
       "0           5.004813                        0                         1   \n",
       "2           5.199333                        0                         1   \n",
       "4           4.954104                        0                         1   \n",
       "5           5.056656                        0                         1   \n",
       "\n",
       "   warmup_time  config/alpha  config/num_epochs  \\\n",
       "1     0.005001        0.1000                100   \n",
       "3     0.005001        0.1000               1000   \n",
       "6     0.005001        0.1000                100   \n",
       "7     0.005001        0.1000                100   \n",
       "9     0.005001        0.1000                100   \n",
       "8     0.005001        0.0001                100   \n",
       "0     0.005001        1.0000                100   \n",
       "2     0.005001        1.0000                100   \n",
       "4     0.005001        1.0000               1000   \n",
       "5     0.005001        1.0000                100   \n",
       "\n",
       "                                              logdir  \n",
       "1  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "3  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "6  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "7  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "9  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "8  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "0  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "2  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "4  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "5  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.dataframe(metric=\"val_bal_acc\", mode=\"max\").sort_values(\"val_bal_acc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9742c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inner_lr_tune_dc9c1_00000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.get_best_trial(\"val_bal_acc\", \"max\", \"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8135a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022-07-14 16:54:58,923\tWARNING worker.py:1404 -- Warning: The actor ImplicitFunc is very large (74 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5dc231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4d97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561b72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad63cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caeac47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347192a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3eb82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bf8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d796fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2b1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e5bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f277e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c8d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
