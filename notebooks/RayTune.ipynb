{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6207475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn import functional as F\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score #equal to torchmetrics.accuracy(average=\"macro\")\n",
    "\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune import CLIReporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d341a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mathiass\\\\Documents\\\\Projects\\\\master-thesis\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca88da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in tune: will seed hyperparam search space\n",
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73e517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mathiass\\\\OneDrive - Universität Zürich UZH\\\\Documents\\\\mt_literature\\\\data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"C:\\Users\\Mathiass\\OneDrive - Universität Zürich UZH\\Documents\\mt_literature\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b7c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "path_data = pathlib.Path(r\"C:\\Users\\Mathiass\\OneDrive - Universität Zürich UZH\\Documents\\mt_literature\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a240229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    data: pandas.DataFrame that must have specific columns.\n",
    "\n",
    "    \"\"\"\n",
    "    # Bid-Ask spread: (Ask - Bid) / Ask\n",
    "    data[\"best_bid\"] = (data[\"best_offer\"] - data[\"best_bid\"]) / (data[\"best_offer\"])\n",
    "    data = data.rename(columns={\"best_bid\": \"ba_spread_option\"}).drop([\"best_offer\"], axis=1)\n",
    "\n",
    "    # Gamma: multiply by spotprice and divide by 100\n",
    "    data[\"gamma\"] = data[\"gamma\"] * data[\"spotprice\"] / 100 #following Bali et al. (2021)\n",
    "\n",
    "    # Theta: scale by spotprice\n",
    "    data[\"theta\"] = data[\"theta\"] / data[\"spotprice\"] #following Bali et al. (2021)\n",
    "\n",
    "    # Vega: scale by spotprice\n",
    "    data[\"vega\"] = data[\"vega\"] / data[\"spotprice\"] #following Bali et al. (2021)\n",
    "\n",
    "    # Time to Maturity: cale by number of days in year: 365\n",
    "    data[\"days_to_exp\"] = data[\"days_to_exp\"] / 365\n",
    "\n",
    "    # Moneyness: Strike / Spot (K / S)\n",
    "    data[\"strike_price\"] = data[\"strike_price\"] / data[\"spotprice\"] # K / S\n",
    "    data = data.rename(columns={\"strike_price\": \"moneyness\"})\n",
    "\n",
    "    # Forward Price ratio: Forward / Spot\n",
    "    data[\"forwardprice\"] = data[\"forwardprice\"] / data[\"spotprice\"]\n",
    "\n",
    "    # Drop redundant/ unimportant columns\n",
    "    data = data.drop([\"cfadj\", \"days_no_trading\", \"spotprice\", \"adj_spot\"], axis=1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc52b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass y label function\n",
    "def binary_categorize(y):\n",
    "    if y > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d36bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass y label function\n",
    "def multi_categorize(y):\n",
    "    if y > 0.05:\n",
    "        return 2\n",
    "    elif y < -0.05:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98076a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 dataset: str,\n",
    "#                  batch_size: int, \n",
    "                 start_val: str, \n",
    "                 start_test: str,\n",
    "                 label_fn: str,\n",
    "                 config: dict,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"path\"])\n",
    "        \n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "        \n",
    "        # read data from disk\n",
    "        if dataset == \"small\":\n",
    "            self.data = pd.read_parquet(path/\"final_df_filledmean_small.parquet\")\n",
    "        elif dataset == \"big\":\n",
    "            self.data = pd.read_parquet(path/\"final_df_filledmean.parquet\")\n",
    "        else:\n",
    "            raise ValueError(\"Specify dataset as either 'small' or 'big'\")\n",
    "            \n",
    "        # feature engineer data\n",
    "        self.data = feature_engineer(self.data)\n",
    "        \n",
    "        # create y\n",
    "        self.y = self.data[\"option_ret\"]\n",
    "        # make classification problem\n",
    "        if label_fn == \"binary\":\n",
    "            self.y = self.y.apply(binary_categorize)\n",
    "        elif label_fn == \"multi\":\n",
    "            self.y = self.y.apply(multi_categorize)\n",
    "        else:\n",
    "            raise ValueError(\"Specify label_fn as either 'binary' or 'multi'\")\n",
    "        # create X\n",
    "        self.X = self.data.drop([\"option_ret\"], axis=1)\n",
    "        \n",
    "        # save dates and drop\n",
    "        self.dates = self.X[\"date\"]\n",
    "        self.X = self.X.drop([\"date\"], axis=1)\n",
    "        \n",
    "        # to torch Tensor\n",
    "        self.X = torch.from_numpy(self.X.values).float() #-> will be standardized in setup, so do it there.\n",
    "        self.y = torch.from_numpy(self.y.values)\n",
    "        \n",
    "    def setup(self, stage: str = None):\n",
    "        # train\n",
    "        self.X_train = self.X[self.dates < self.hparams.start_val]\n",
    "        self.y_train = self.y[:len(self.X_train)]\n",
    "        \n",
    "        #val\n",
    "        mask = (self.dates >= self.hparams.start_val) & (self.dates < self.hparams.start_test)\n",
    "        self.X_val = self.X[mask]\n",
    "        self.y_val = self.y[len(self.X_train):len(self.X_train)+len(self.X_val)]\n",
    "        \n",
    "        # test\n",
    "        self.X_test = self.X[self.dates >= self.hparams.start_test]\n",
    "        self.y_test = self.y[-len(self.X_test):]\n",
    "        \n",
    "        assert (np.sum(len(self.X_train)+len(self.X_val)+len(self.X_test)) == len(self.data)), \"sum of samples of splits\\\n",
    "        is not equal length of dataset\"\n",
    "        \n",
    "        #standardize X_train\n",
    "        mean = torch.mean(self.X_train, axis=0)\n",
    "        std = torch.std(self.X_train, axis=0)\n",
    "        \n",
    "        # Standardize X_train, X_val and X_test with mean/std from X_train\n",
    "        self.X_train = (self.X_train - mean) / std\n",
    "        self.X_val = (self.X_val - mean) / std\n",
    "        self.X_test = (self.X_test - mean) / std\n",
    "\n",
    "        # Save variables to pass to model class\n",
    "        # input dim\n",
    "        self.input_dim = self.X_train.shape[1]\n",
    "        # number of classes\n",
    "        self.num_classes = len(self.y_train.unique())\n",
    "        # class weights\n",
    "        self.class_weights = len(self.y_train) / self.y_train.unique(return_counts=True)[1]\n",
    "\n",
    "        print(\"class_weights:\", self.class_weights)\n",
    "        print(\"device of class_weights:\", self.class_weights.device)\n",
    "        print(\"---\")\n",
    "        print(f\"# of input data: {len(self.data)} with shape: {self.data.shape}\")\n",
    "        print(f\"# of training samples: {len(self.y_train)} with X_train of shape: {self.X_train.shape}\")\n",
    "        print(f\"# of validation samples: {len(self.y_val)} with X_val of shape: {self.X_val.shape}\")\n",
    "        print(f\"# of test samples: {len(self.y_test)} with X_test of shape: {self.X_test.shape}\")\n",
    "        print(f\"train start date: \", self.dates[self.dates < self.hparams.start_val].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", train end date: \", self.dates[self.dates < self.hparams.start_val].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(f\"val start date: \", self.dates[mask].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", val end date: \", self.dates[mask].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(f\"test start date: \", self.dates[self.dates >= self.hparams.start_test].iloc[0].strftime(\"%Y-%m-%d\"), \n",
    "              \", test end date: \", self.dates[self.dates >= self.hparams.start_test].iloc[-1].strftime(\"%Y-%m-%d\"))\n",
    "        print(\"---\")\n",
    "\n",
    "    def example(self):\n",
    "        \"\"\"Returns a random training example.\"\"\"        \n",
    "        idx = np.random.randint(0, len(self.X_train))\n",
    "        x, y = self.X_train[idx], self.y_train[idx]\n",
    "        return (x, y)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(self.X_val, self.y_val)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = TensorDataset(self.X_test, self.y_test)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         )\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"DataModule\")\n",
    "        parser.add_argument(\"--dataset\", type=str, default=\"small\")\n",
    "        # parser.add_argument(\"--path\", type=str, help=\"path to folder that contains the data\")\n",
    "        parser.add_argument(\"--batch_size\", type=int, default=512)\n",
    "        parser.add_argument(\"--start_val\", type=str, default=\"2014\")\n",
    "        parser.add_argument(\"--start_test\", type=str, default=\"2016\")\n",
    "        parser.add_argument(\"--label_fn\", type=str, default=\"binary\")\n",
    "\n",
    "        return parent_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c562f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                # dm,\n",
    "                input_dim: int,\n",
    "                num_classes: int,\n",
    "                class_weights: torch.Tensor,\n",
    "                no_class_weights: bool,\n",
    "#                 hidden_dim: int,\n",
    "#                 learning_rate: float,\n",
    "                 config: dict,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        # Init variables are saved, so that model can be reloaded cleanly if necessary\n",
    "#         self.save_hyperparameters(ignore=[\"class_weights\"])\n",
    "        self.save_hyperparameters()\n",
    "        #ignore \"dm\" is crucial if dm is passed\n",
    "        \n",
    "        if config is not None:\n",
    "            self.hidden_dim = config[\"hidden_dim\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "        else:\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.learning_rate = learning_rate\n",
    "        \n",
    "        middle_layer = []\n",
    "        for i in range(3):\n",
    "            middle_layer.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "#             middle_layer.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "            middle_layer.append(nn.ReLU(inplace=True))\n",
    "            middle_layer.append(nn.Dropout())\n",
    "        \n",
    "        \n",
    "        #model\n",
    "        self.first = nn.Sequential(nn.Linear(input_dim, self.hidden_dim), nn.ReLU())\n",
    "#         self.middle = nn.Sequential(*[nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ReLU()) for i in range(3)])\n",
    "        self.middle = nn.Sequential(*middle_layer)\n",
    "        self.last = nn.Linear(self.hidden_dim, num_classes)\n",
    "        \n",
    "        #sample weights\n",
    "        if not self.hparams.no_class_weights:\n",
    "            self.class_weights = class_weights\n",
    "            self.class_weights = self.class_weights.cuda() # Move to cuda, otherwise mismatch of devices # in train/val\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "#         print(\"---\")\n",
    "#         print(\"class_weights:\", self.class_weights)\n",
    "#         print(\"device of class_weights:\", self.class_weights.device)\n",
    "#         print(\"device of class:\", self.device)\n",
    "#         print(\"---\")\n",
    "\n",
    "        #metrics\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.train_bal_acc = torchmetrics.Accuracy(\n",
    "        num_classes=num_classes, average=\"macro\") # should be equal to sklearn bal. acc.\n",
    "\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "        self.val_bal_acc= torchmetrics.Accuracy(\n",
    "            num_classes=num_classes, average=\"macro\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.last(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x) #logits\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y, weight=self.class_weights)\n",
    "        self.log(\"loss/loss\", loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        \n",
    "        self.train_acc(y_hat, y)\n",
    "        self.log(\"acc/train\", self.train_acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        self.train_bal_acc(y_hat, y)\n",
    "        self.log(\"bal_acc/train\", self.train_bal_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x) #logits\n",
    "        \n",
    "#         self.log(\"hp_metric\", torch.mean(y_hat.argmax(dim=-1).float()).item(), prog_bar=True) # average prediction class\n",
    "        self.log(\"mean_pred\", torch.mean(y_hat.argmax(dim=-1).float()).item(), prog_bar=True)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y, weight=self.class_weights)\n",
    "        self.log(\"loss/val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        self.val_acc(y_hat, y)\n",
    "        self.log(\"acc/val\", self.val_acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        self.val_bal_acc(y_hat, y)\n",
    "        self.log(\"bal_acc/val\", self.val_bal_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return {\"val_loss\": loss}\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        self.st_total = time.time()\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.st = time.time()\n",
    "        self.steps = self.global_step\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        elapsed = time.time() - self.st\n",
    "        steps_done = self.global_step - self.steps\n",
    "        self.log(\"time/step\", elapsed / steps_done)\n",
    "\n",
    "    def on_train_end(self):\n",
    "        elapsed = time.time() - self.st_total\n",
    "        print(f\"Total Training Time: {time.strftime('%H:%M:%S', time.gmtime(elapsed))}\")\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y, weight=self.class_weights)\n",
    "\n",
    "        self.log(\"loss/test_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"FFN\")\n",
    "        parser.add_argument(\"--no_class_weights\", action='store_true')\n",
    "        parser.add_argument(\"--hidden_dim\", type=int, default=100)\n",
    "        parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=1e-2)\n",
    "\n",
    "        return parent_parser\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16bf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFN(\n",
    "input_dim=15,\n",
    "num_classes=2,\n",
    "class_weights=None,\n",
    "no_class_weights=True,\n",
    "#     hidden_dim=HIDDEN_DIM,\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "config={\"hidden_dim\": 50, \"lr\": 1e-2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc41658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFN(\n",
      "  (first): Sequential(\n",
      "    (0): Linear(in_features=15, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (middle): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (last): Linear(in_features=50, out_features=2, bias=True)\n",
      "  (train_acc): Accuracy()\n",
      "  (train_bal_acc): Accuracy()\n",
      "  (val_acc): Accuracy()\n",
      "  (val_bal_acc): Accuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8151d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune_callback = TuneReportCallback(\n",
    "#     {\n",
    "#         \"val_loss\": \"loss/val_loss\",\n",
    "#         \"val_bal_acc\": \"bal_acc/val\",\n",
    "#         \"mean_pred\": \"mean_pred\"\n",
    "#     },\n",
    "#     on=\"validation_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e134539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#         monitor=\"loss/val_loss\",\n",
    "#         save_top_k=1,\n",
    "#         mode=\"min\",\n",
    "#         filename='epoch={epoch}-val_loss={loss/val_loss:.3f}-val_bacc={bal_acc/val:.4f}',\n",
    "#         auto_insert_metric_name=False,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37e86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "        monitor=\"loss/val_loss\", \n",
    "        mode=\"min\", \n",
    "        patience=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a3eeccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_callback = TuneReportCheckpointCallback(\n",
    "    metrics={\n",
    "        \"loss\": \"loss/loss\",\n",
    "        \"mean_pred\": \"mean_pred\",\n",
    "        \"val_loss\": \"loss/val_loss\",\n",
    "        \"val_bal_acc\": \"bal_acc/val\"\n",
    "    },\n",
    "    filename=\"checkpoint\",\n",
    "    on=\"validation_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98283591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist_tune(config, max_epochs=10, num_gpus=1, checkpoint_dir=None):\n",
    "#     data_dir = os.path.expanduser(data_dir)\n",
    "    \n",
    "    # will seed trainer (init of weights in NN?)\n",
    "    seed_everything(42, workers=True)\n",
    "    \n",
    "    print(\"------\")\n",
    "    print(np.random.uniform(0, 100, size=1).item())\n",
    "    print(\"------\")\n",
    "    \n",
    "    dm = MyDataModule(\n",
    "    path=path_data, \n",
    "    dataset=\"small\",\n",
    "#     batch_size=BATCH_SIZE, \n",
    "    start_val=\"1997\", \n",
    "    start_test=\"1998\",\n",
    "    label_fn=\"binary\",\n",
    "    config=config,\n",
    "    )\n",
    "    \n",
    "    dm.setup()\n",
    "    \n",
    "    model = FFN(\n",
    "    input_dim=dm.input_dim,\n",
    "    num_classes=dm.num_classes,\n",
    "    class_weights=dm.class_weights,\n",
    "    no_class_weights=False,\n",
    "#     hidden_dim=HIDDEN_DIM,\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "    config=config,\n",
    "    )\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        deterministic=True,\n",
    "        max_epochs=max_epochs,\n",
    "        gpus=num_gpus,\n",
    "        logger=pl.loggers.TensorBoardLogger(\n",
    "        save_dir=tune.get_trial_dir(), name=\"\", version=\".\"),\n",
    "        enable_progress_bar=True,\n",
    "        callbacks=[\n",
    "#                    checkpoint_callback, \n",
    "                   early_stop_callback,\n",
    "                   tune_callback, \n",
    "                  ],\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, datamodule=dm)\n",
    "    \n",
    "#     print(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40a9a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_mnist_asha(num_samples=2, max_epochs=5, gpus_per_trial=1,):\n",
    "    config = {\n",
    "        \"hidden_dim\": tune.choice([50, 100]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([256, 512]),\n",
    "#         \"hidden_dim\": tune.choice([32]),\n",
    "#         \"lr\": tune.choice([1e-2]),\n",
    "#         \"batch_size\": tune.choice([512]),\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=[\"hidden_dim\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"val_loss\", \"val_bal_acc\", \"mean_pred\", \"training_iteration\"])\n",
    "\n",
    "    train_fn_with_parameters = tune.with_parameters(train_mnist_tune,\n",
    "                                                    max_epochs=max_epochs,\n",
    "                                                    num_gpus=gpus_per_trial,\n",
    "#                                                     data_dir=data_dir,\n",
    "                                                   )\n",
    "    resources_per_trial = {\"cpu\": 1, \"gpu\": gpus_per_trial}\n",
    "    \n",
    "    analysis = tune.run(train_fn_with_parameters,\n",
    "        local_dir=\"./logs\",\n",
    "        resources_per_trial=resources_per_trial,\n",
    "        metric=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        name=\"tune_mnist_asha\",\n",
    "        keep_checkpoints_num=1, # only keep best checkpoint\n",
    "        checkpoint_score_attr=\"min-val_loss\",\n",
    "        )\n",
    "\n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "    \n",
    "    best_trial = analysis.get_best_trial(\"val_loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial >>last<< validation loss: {}\".format(\n",
    "        best_trial.last_result[\"val_loss\"]))\n",
    "    print(\"Best trial >>last epoch<< validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"val_bal_acc\"]))\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "817fd608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 10:39:41,037\tERROR syncer.py:147 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-13 10:39:41 (running for 00:00:00.17)\n",
      "Memory usage on this node: 6.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m ------\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 37.454011884736246\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-13 10:39:50 (running for 00:00:09.70)\n",
      "Memory usage on this node: 8.5/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:39:55 (running for 00:00:14.73)\n",
      "Memory usage on this node: 8.5/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:00 (running for 00:00:19.76)\n",
      "Memory usage on this node: 8.6/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:05 (running for 00:00:24.78)\n",
      "Memory usage on this node: 8.6/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:10 (running for 00:00:29.82)\n",
      "Memory usage on this node: 8.6/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:15 (running for 00:00:34.84)\n",
      "Memory usage on this node: 8.6/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m class_weights: tensor([1.5913, 2.6912])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m device of class_weights: cpu\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m ---\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m # of input data: 3823386 with shape: (3823386, 17)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m # of training samples: 38419 with X_train of shape: torch.Size([38419, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m # of validation samples: 50879 with X_val of shape: torch.Size([50879, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m # of test samples: 3734088 with X_test of shape: torch.Size([3734088, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m train start date:  1996-01-31 , train end date:  1996-12-31\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m val start date:  1997-01-31 , val end date:  1997-12-31\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m test start date:  1998-01-31 , test end date:  2021-11-30\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m FFN(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   (first): Sequential(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (0): Linear(in_features=15, out_features=50, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (1): ReLU()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   )\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   (middle): Sequential(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (1): ReLU(inplace=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (2): Dropout(p=0.5, inplace=False)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (4): ReLU(inplace=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (5): Dropout(p=0.5, inplace=False)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (7): ReLU(inplace=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m     (8): Dropout(p=0.5, inplace=False)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   )\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   (last): Linear(in_features=50, out_features=2, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   (train_acc): Accuracy()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   (train_bal_acc): Accuracy()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   (val_acc): Accuracy()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   (val_bal_acc): Accuracy()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m )\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:20 (running for 00:00:39.89)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:25 (running for 00:00:44.91)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:30 (running for 00:00:49.95)\n",
      "Memory usage on this node: 8.9/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:35 (running for 00:00:54.97)\n",
      "Memory usage on this node: 8.9/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:40 (running for 00:00:59.99)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:45 (running for 00:01:05.02)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m class_weights: tensor([1.5913, 2.6912])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m device of class_weights: cpu\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m ---\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m # of input data: 3823386 with shape: (3823386, 17)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m # of training samples: 38419 with X_train of shape: torch.Size([38419, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m # of validation samples: 50879 with X_val of shape: torch.Size([50879, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m # of test samples: 3734088 with X_test of shape: torch.Size([3734088, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m train start date:  1996-01-31 , train end date:  1996-12-31\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m val start date:  1997-01-31 , val end date:  1997-12-31\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m test start date:  1998-01-31 , test end date:  2021-11-30\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m ---\n",
      "Sanity Checking: 0it [00:00, ?it/s])\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m   | Name          | Type       | Params\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m ---------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 0 | first         | Sequential | 800   \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 1 | middle        | Sequential | 7.7 K \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 2 | last          | Linear     | 102   \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 3 | train_acc     | Accuracy   | 0     \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 4 | train_bal_acc | Accuracy   | 0     \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 5 | val_acc       | Accuracy   | 0     \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 6 | val_bal_acc   | Accuracy   | 0     \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m ---------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 8.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 8.6 K     Total params\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m 0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:50 (running for 00:01:10.06)\n",
      "Memory usage on this node: 9.4/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/350 [00:00<?, ?it/s]                           \n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:40:55 (running for 00:01:15.10)\n",
      "Memory usage on this node: 10.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 8/350 [00:02<02:01,  2.83it/s, loss=0.698, v_num=., loss/loss=0.677]\n",
      "Epoch 0:   2%|▏         | 8/350 [00:02<02:01,  2.82it/s, loss=0.702, v_num=., loss/loss=0.730]\n",
      "Epoch 0:   5%|▌         | 18/350 [00:02<00:54,  6.09it/s, loss=0.699, v_num=., loss/loss=0.696]\n",
      "Epoch 0:   8%|▊         | 27/350 [00:03<00:36,  8.80it/s, loss=0.698, v_num=., loss/loss=0.688]\n",
      "Epoch 0:   8%|▊         | 28/350 [00:03<00:35,  9.09it/s, loss=0.696, v_num=., loss/loss=0.692]\n",
      "Epoch 0:  11%|█         | 38/350 [00:03<00:26, 11.89it/s, loss=0.694, v_num=., loss/loss=0.697]\n",
      "Epoch 0:  14%|█▍        | 49/350 [00:03<00:20, 14.74it/s, loss=0.688, v_num=., loss/loss=0.681]\n",
      "Epoch 0:  17%|█▋        | 60/350 [00:03<00:16, 17.41it/s, loss=0.693, v_num=., loss/loss=0.706]\n",
      "Epoch 0:  20%|██        | 70/350 [00:03<00:14, 19.63it/s, loss=0.7, v_num=., loss/loss=0.692]  \n",
      "Epoch 0:  23%|██▎       | 81/350 [00:03<00:12, 21.95it/s, loss=0.694, v_num=., loss/loss=0.692]\n",
      "Epoch 0:  26%|██▌       | 91/350 [00:03<00:10, 23.87it/s, loss=0.692, v_num=., loss/loss=0.684]\n",
      "Epoch 0:  29%|██▉       | 101/350 [00:03<00:09, 25.73it/s, loss=0.7, v_num=., loss/loss=0.696]  \n",
      "Epoch 0:  29%|██▉       | 102/350 [00:03<00:09, 25.91it/s, loss=0.699, v_num=., loss/loss=0.680]\n",
      "Epoch 0:  32%|███▏      | 112/350 [00:04<00:08, 27.62it/s, loss=0.704, v_num=., loss/loss=0.696]\n",
      "Epoch 0:  35%|███▌      | 123/350 [00:04<00:07, 29.44it/s, loss=0.691, v_num=., loss/loss=0.684]\n",
      "Epoch 0:  38%|███▊      | 133/350 [00:04<00:07, 30.96it/s, loss=0.693, v_num=., loss/loss=0.773]\n",
      "Epoch 0:  41%|████      | 143/350 [00:04<00:06, 32.44it/s, loss=0.703, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  43%|████▎     | 151/350 [00:04<00:05, 33.60it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A68)\u001b[0m \n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:01 (running for 00:01:20.16)\n",
      "Memory usage on this node: 10.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  43%|████▎     | 152/350 [00:07<00:09, 20.02it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  44%|████▎     | 153/350 [00:07<00:09, 20.13it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  44%|████▍     | 154/350 [00:07<00:09, 20.24it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  44%|████▍     | 155/350 [00:07<00:09, 20.36it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  45%|████▍     | 156/350 [00:07<00:09, 20.47it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  45%|████▍     | 157/350 [00:07<00:09, 20.57it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  45%|████▌     | 158/350 [00:07<00:09, 20.68it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  45%|████▌     | 159/350 [00:07<00:09, 20.79it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  46%|████▌     | 160/350 [00:07<00:09, 20.89it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  46%|████▌     | 161/350 [00:07<00:08, 21.00it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  46%|████▋     | 162/350 [00:07<00:08, 21.11it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  47%|████▋     | 163/350 [00:07<00:08, 21.22it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:   7%|▋         | 13/199 [00:00<00:01, 120.95it/s]\u001b[A\n",
      "Epoch 0:  47%|████▋     | 164/350 [00:07<00:08, 21.32it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  47%|████▋     | 165/350 [00:07<00:08, 21.43it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  47%|████▋     | 166/350 [00:07<00:08, 21.54it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  48%|████▊     | 167/350 [00:07<00:08, 21.64it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  48%|████▊     | 168/350 [00:07<00:08, 21.75it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  48%|████▊     | 169/350 [00:07<00:08, 21.85it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  49%|████▊     | 170/350 [00:07<00:08, 21.95it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  49%|████▉     | 171/350 [00:07<00:08, 22.06it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  49%|████▉     | 172/350 [00:07<00:08, 22.16it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  49%|████▉     | 173/350 [00:07<00:07, 22.27it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  50%|████▉     | 174/350 [00:07<00:07, 22.36it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  50%|█████     | 175/350 [00:07<00:07, 22.46it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  50%|█████     | 176/350 [00:07<00:07, 22.57it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  13%|█▎        | 26/199 [00:00<00:01, 115.32it/s]\u001b[A\n",
      "Epoch 0:  51%|█████     | 177/350 [00:07<00:07, 22.67it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  51%|█████     | 178/350 [00:07<00:07, 22.78it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  51%|█████     | 179/350 [00:07<00:07, 22.88it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  51%|█████▏    | 180/350 [00:07<00:07, 22.98it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  52%|█████▏    | 181/350 [00:07<00:07, 23.09it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  52%|█████▏    | 182/350 [00:07<00:07, 23.19it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  52%|█████▏    | 183/350 [00:07<00:07, 23.29it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  53%|█████▎    | 184/350 [00:07<00:07, 23.39it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  53%|█████▎    | 185/350 [00:07<00:07, 23.49it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  53%|█████▎    | 186/350 [00:07<00:06, 23.59it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  53%|█████▎    | 187/350 [00:07<00:06, 23.69it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  54%|█████▎    | 188/350 [00:07<00:06, 23.79it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  19%|█▉        | 38/199 [00:00<00:01, 115.35it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 189/350 [00:07<00:06, 23.89it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  54%|█████▍    | 190/350 [00:07<00:06, 23.99it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  55%|█████▍    | 191/350 [00:07<00:06, 24.09it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  55%|█████▍    | 192/350 [00:07<00:06, 24.19it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  55%|█████▌    | 193/350 [00:07<00:06, 24.29it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  55%|█████▌    | 194/350 [00:07<00:06, 24.39it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  56%|█████▌    | 195/350 [00:07<00:06, 24.49it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  56%|█████▌    | 196/350 [00:07<00:06, 24.59it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  56%|█████▋    | 197/350 [00:07<00:06, 24.69it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  57%|█████▋    | 198/350 [00:07<00:06, 24.79it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  57%|█████▋    | 199/350 [00:07<00:06, 24.89it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  57%|█████▋    | 200/350 [00:08<00:06, 24.99it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation DataLoader 0:  25%|██▌       | 50/199 [00:00<00:01, 116.40it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 201/350 [00:08<00:05, 25.08it/s, loss=0.706, v_num=., loss/loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  58%|█████▊    | 202/350 [00:08<00:05, 25.18it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  58%|█████▊    | 203/350 [00:08<00:05, 25.28it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  58%|█████▊    | 204/350 [00:08<00:05, 25.37it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  59%|█████▊    | 205/350 [00:08<00:05, 25.47it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  59%|█████▉    | 206/350 [00:08<00:05, 25.57it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  59%|█████▉    | 207/350 [00:08<00:05, 25.67it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  59%|█████▉    | 208/350 [00:08<00:05, 25.77it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  60%|█████▉    | 209/350 [00:08<00:05, 25.87it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  60%|██████    | 210/350 [00:08<00:05, 25.96it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  60%|██████    | 211/350 [00:08<00:05, 26.06it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  61%|██████    | 212/350 [00:08<00:05, 26.16it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  31%|███       | 62/199 [00:00<00:01, 116.56it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 213/350 [00:08<00:05, 26.25it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  61%|██████    | 214/350 [00:08<00:05, 26.33it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  61%|██████▏   | 215/350 [00:08<00:05, 26.42it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  62%|██████▏   | 216/350 [00:08<00:05, 26.51it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  62%|██████▏   | 217/350 [00:08<00:04, 26.61it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  62%|██████▏   | 218/350 [00:08<00:04, 26.70it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  63%|██████▎   | 219/350 [00:08<00:04, 26.80it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  63%|██████▎   | 220/350 [00:08<00:04, 26.89it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  63%|██████▎   | 221/350 [00:08<00:04, 26.99it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  63%|██████▎   | 222/350 [00:08<00:04, 27.09it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  64%|██████▎   | 223/350 [00:08<00:04, 27.18it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  64%|██████▍   | 224/350 [00:08<00:04, 27.27it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  37%|███▋      | 74/199 [00:00<00:01, 115.24it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 225/350 [00:08<00:04, 27.36it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  65%|██████▍   | 226/350 [00:08<00:04, 27.46it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  65%|██████▍   | 227/350 [00:08<00:04, 27.55it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  65%|██████▌   | 228/350 [00:08<00:04, 27.65it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  65%|██████▌   | 229/350 [00:08<00:04, 27.74it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  66%|██████▌   | 230/350 [00:08<00:04, 27.83it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  66%|██████▌   | 231/350 [00:08<00:04, 27.92it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  66%|██████▋   | 232/350 [00:08<00:04, 28.02it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  67%|██████▋   | 233/350 [00:08<00:04, 28.11it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  67%|██████▋   | 234/350 [00:08<00:04, 28.20it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  67%|██████▋   | 235/350 [00:08<00:04, 28.29it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  67%|██████▋   | 236/350 [00:08<00:04, 28.38it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  43%|████▎     | 86/199 [00:00<00:00, 116.57it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 237/350 [00:08<00:03, 28.48it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  68%|██████▊   | 238/350 [00:08<00:03, 28.57it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  68%|██████▊   | 239/350 [00:08<00:03, 28.66it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  69%|██████▊   | 240/350 [00:08<00:03, 28.75it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  69%|██████▉   | 241/350 [00:08<00:03, 28.84it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  69%|██████▉   | 242/350 [00:08<00:03, 28.92it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  69%|██████▉   | 243/350 [00:08<00:03, 29.01it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  70%|██████▉   | 244/350 [00:08<00:03, 29.10it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  70%|███████   | 245/350 [00:08<00:03, 29.19it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  70%|███████   | 246/350 [00:08<00:03, 29.28it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  71%|███████   | 247/350 [00:08<00:03, 29.37it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  71%|███████   | 248/350 [00:08<00:03, 29.46it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  49%|████▉     | 98/199 [00:00<00:00, 116.50it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 249/350 [00:08<00:03, 29.55it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  71%|███████▏  | 250/350 [00:08<00:03, 29.64it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  72%|███████▏  | 251/350 [00:08<00:03, 29.73it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  72%|███████▏  | 252/350 [00:08<00:03, 29.82it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  72%|███████▏  | 253/350 [00:08<00:03, 29.91it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  73%|███████▎  | 254/350 [00:08<00:03, 30.00it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  73%|███████▎  | 255/350 [00:08<00:03, 30.08it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  73%|███████▎  | 256/350 [00:08<00:03, 30.17it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  73%|███████▎  | 257/350 [00:08<00:03, 30.26it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  74%|███████▎  | 258/350 [00:08<00:03, 30.35it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  74%|███████▍  | 259/350 [00:08<00:02, 30.44it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  74%|███████▍  | 260/350 [00:08<00:02, 30.52it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  55%|█████▌    | 110/199 [00:00<00:00, 116.83it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▍  | 261/350 [00:08<00:02, 30.60it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  75%|███████▍  | 262/350 [00:08<00:02, 30.69it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  75%|███████▌  | 263/350 [00:08<00:02, 30.78it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  75%|███████▌  | 264/350 [00:08<00:02, 30.86it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  76%|███████▌  | 265/350 [00:08<00:02, 30.95it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  76%|███████▌  | 266/350 [00:08<00:02, 31.04it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  76%|███████▋  | 267/350 [00:08<00:02, 31.13it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  77%|███████▋  | 268/350 [00:08<00:02, 31.21it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  77%|███████▋  | 269/350 [00:08<00:02, 31.30it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  77%|███████▋  | 270/350 [00:08<00:02, 31.38it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  77%|███████▋  | 271/350 [00:08<00:02, 31.46it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  78%|███████▊  | 272/350 [00:08<00:02, 31.54it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation DataLoader 0:  61%|██████▏   | 122/199 [00:01<00:00, 115.28it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 273/350 [00:08<00:02, 31.61it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  78%|███████▊  | 274/350 [00:08<00:02, 31.70it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  79%|███████▊  | 275/350 [00:08<00:02, 31.78it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  79%|███████▉  | 276/350 [00:08<00:02, 31.87it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  79%|███████▉  | 277/350 [00:08<00:02, 31.96it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  79%|███████▉  | 278/350 [00:08<00:02, 32.04it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  80%|███████▉  | 279/350 [00:08<00:02, 32.12it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  80%|████████  | 280/350 [00:08<00:02, 32.21it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  80%|████████  | 281/350 [00:08<00:02, 32.30it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  81%|████████  | 282/350 [00:08<00:02, 32.38it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  81%|████████  | 283/350 [00:08<00:02, 32.47it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  81%|████████  | 284/350 [00:08<00:02, 32.55it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  81%|████████▏ | 285/350 [00:08<00:01, 32.63it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  68%|██████▊   | 135/199 [00:01<00:00, 117.34it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 286/350 [00:08<00:01, 32.71it/s, loss=0.706, v_num=., loss/loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  82%|████████▏ | 287/350 [00:08<00:01, 32.80it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  82%|████████▏ | 288/350 [00:08<00:01, 32.88it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  83%|████████▎ | 289/350 [00:08<00:01, 32.97it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  83%|████████▎ | 290/350 [00:08<00:01, 33.05it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  83%|████████▎ | 291/350 [00:08<00:01, 33.13it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  83%|████████▎ | 292/350 [00:08<00:01, 33.22it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  84%|████████▎ | 293/350 [00:08<00:01, 33.29it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  84%|████████▍ | 294/350 [00:08<00:01, 33.38it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  84%|████████▍ | 295/350 [00:08<00:01, 33.46it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  85%|████████▍ | 296/350 [00:08<00:01, 33.54it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  85%|████████▍ | 297/350 [00:08<00:01, 33.62it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  74%|███████▍  | 147/199 [00:01<00:00, 117.36it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 298/350 [00:08<00:01, 33.70it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  85%|████████▌ | 299/350 [00:08<00:01, 33.77it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  86%|████████▌ | 300/350 [00:08<00:01, 33.84it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  86%|████████▌ | 301/350 [00:08<00:01, 33.92it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  86%|████████▋ | 302/350 [00:08<00:01, 34.01it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  87%|████████▋ | 303/350 [00:08<00:01, 34.09it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  87%|████████▋ | 304/350 [00:08<00:01, 34.17it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  87%|████████▋ | 305/350 [00:08<00:01, 34.25it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  87%|████████▋ | 306/350 [00:08<00:01, 34.33it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  88%|████████▊ | 307/350 [00:08<00:01, 34.41it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  88%|████████▊ | 308/350 [00:08<00:01, 34.49it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  88%|████████▊ | 309/350 [00:08<00:01, 34.57it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  80%|███████▉  | 159/199 [00:01<00:00, 117.39it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 310/350 [00:08<00:01, 34.65it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  89%|████████▉ | 311/350 [00:08<00:01, 34.72it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  89%|████████▉ | 312/350 [00:08<00:01, 34.79it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  89%|████████▉ | 313/350 [00:08<00:01, 34.86it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  90%|████████▉ | 314/350 [00:08<00:01, 34.93it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  90%|█████████ | 315/350 [00:08<00:00, 35.00it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  90%|█████████ | 316/350 [00:09<00:00, 35.04it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  91%|█████████ | 317/350 [00:09<00:00, 35.11it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  91%|█████████ | 318/350 [00:09<00:00, 35.19it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  91%|█████████ | 319/350 [00:09<00:00, 35.27it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  91%|█████████▏| 320/350 [00:09<00:00, 35.34it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  92%|█████████▏| 321/350 [00:09<00:00, 35.42it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  86%|████████▌ | 171/199 [00:01<00:00, 109.17it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 322/350 [00:09<00:00, 35.49it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  92%|█████████▏| 323/350 [00:09<00:00, 35.55it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  93%|█████████▎| 324/350 [00:09<00:00, 35.62it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  93%|█████████▎| 325/350 [00:09<00:00, 35.69it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  93%|█████████▎| 326/350 [00:09<00:00, 35.77it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  93%|█████████▎| 327/350 [00:09<00:00, 35.85it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  94%|█████████▎| 328/350 [00:09<00:00, 35.92it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  94%|█████████▍| 329/350 [00:09<00:00, 36.00it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  94%|█████████▍| 330/350 [00:09<00:00, 36.07it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  95%|█████████▍| 331/350 [00:09<00:00, 36.15it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  95%|█████████▍| 332/350 [00:09<00:00, 36.23it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  95%|█████████▌| 333/350 [00:09<00:00, 36.30it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  92%|█████████▏| 183/199 [00:01<00:00, 109.69it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 334/350 [00:09<00:00, 36.38it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  96%|█████████▌| 335/350 [00:09<00:00, 36.45it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  96%|█████████▌| 336/350 [00:09<00:00, 36.53it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  96%|█████████▋| 337/350 [00:09<00:00, 36.61it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  97%|█████████▋| 338/350 [00:09<00:00, 36.68it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  97%|█████████▋| 339/350 [00:09<00:00, 36.75it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Result for train_mnist_tune_56334_00000:\n",
      "  date: 2022-07-13_10-41-03\n",
      "  done: false\n",
      "  experiment_id: 982c1c173bd44ceabdf99b78b60d4d2d\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6985145807266235\n",
      "  mean_pred: 1.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 1268\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 78.25173377990723\n",
      "  time_this_iter_s: 78.25173377990723\n",
      "  time_total_s: 78.25173377990723\n",
      "  timestamp: 1657701663\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '56334_00000'\n",
      "  val_bal_acc: 0.5\n",
      "  val_loss: 0.6931675672531128\n",
      "  warmup_time: 0.004000186920166016\n",
      "  \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 0:  97%|█████████▋| 340/350 [00:09<00:00, 36.82it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  97%|█████████▋| 341/350 [00:09<00:00, 36.90it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  98%|█████████▊| 342/350 [00:09<00:00, 36.97it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  98%|█████████▊| 343/350 [00:09<00:00, 37.05it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  98%|█████████▊| 344/350 [00:09<00:00, 37.13it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  99%|█████████▊| 345/350 [00:09<00:00, 37.20it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  99%|█████████▉| 346/350 [00:09<00:00, 37.28it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Validation DataLoader 0:  98%|█████████▊| 196/199 [00:01<00:00, 113.73it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 347/350 [00:09<00:00, 37.36it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0:  99%|█████████▉| 348/350 [00:09<00:00, 37.44it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0: 100%|█████████▉| 349/350 [00:09<00:00, 37.52it/s, loss=0.706, v_num=., loss/loss=0.699]\n",
      "Epoch 0: 100%|██████████| 350/350 [00:09<00:00, 37.48it/s, loss=0.706, v_num=., loss/loss=0.699, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500]\n",
      "                                                                           \u001b[A\n",
      "Epoch 0: 100%|██████████| 350/350 [00:09<00:00, 37.45it/s, loss=0.706, v_num=., loss/loss=0.699, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:   0%|          | 0/350 [00:00<?, ?it/s, loss=0.706, v_num=., loss/loss=0.699, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]          \n",
      "Epoch 1:   0%|          | 1/350 [00:03<20:49,  3.58s/it, loss=0.704, v_num=., loss/loss=0.694, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:   3%|▎         | 11/350 [00:03<01:54,  2.96it/s, loss=0.696, v_num=., loss/loss=0.692, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 21/350 [00:03<01:00,  5.48it/s, loss=0.694, v_num=., loss/loss=0.699, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:   9%|▊         | 30/350 [00:03<00:41,  7.62it/s, loss=0.694, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:   9%|▉         | 31/350 [00:03<00:40,  7.85it/s, loss=0.695, v_num=., loss/loss=0.699, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  12%|█▏        | 41/350 [00:04<00:30, 10.09it/s, loss=0.692, v_num=., loss/loss=0.683, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  15%|█▍        | 51/350 [00:04<00:24, 12.19it/s, loss=0.686, v_num=., loss/loss=0.694, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  17%|█▋        | 58/350 [00:04<00:21, 13.55it/s, loss=0.684, v_num=., loss/loss=0.706, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  17%|█▋        | 59/350 [00:04<00:21, 13.73it/s, loss=0.685, v_num=., loss/loss=0.712, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  19%|█▉        | 68/350 [00:04<00:18, 15.39it/s, loss=0.693, v_num=., loss/loss=0.691, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  19%|█▉        | 68/350 [00:04<00:18, 15.39it/s, loss=0.694, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  22%|██▏       | 78/350 [00:04<00:15, 17.18it/s, loss=0.698, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  25%|██▌       | 89/350 [00:04<00:13, 19.09it/s, loss=0.694, v_num=., loss/loss=0.696, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  28%|██▊       | 98/350 [00:04<00:12, 20.58it/s, loss=0.695, v_num=., loss/loss=0.735, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  31%|███       | 109/350 [00:04<00:10, 22.30it/s, loss=0.702, v_num=., loss/loss=0.694, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  34%|███▎      | 118/350 [00:04<00:09, 23.65it/s, loss=0.698, v_num=., loss/loss=0.649, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  34%|███▍      | 119/350 [00:05<00:09, 23.79it/s, loss=0.696, v_num=., loss/loss=0.702, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:08 (running for 00:01:27.96)\n",
      "Memory usage on this node: 11.0/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931675672531128 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693168 |           0.5 |           1 |                    1 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Epoch 1:  37%|███▋      | 129/350 [00:05<00:08, 25.19it/s, loss=0.681, v_num=., loss/loss=0.688, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  39%|███▉      | 138/350 [00:05<00:08, 26.42it/s, loss=0.7, v_num=., loss/loss=0.733, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]  \n",
      "Epoch 1:  43%|████▎     | 149/350 [00:05<00:07, 27.90it/s, loss=0.709, v_num=., loss/loss=0.692, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  43%|████▎     | 150/350 [00:05<00:07, 28.02it/s, loss=0.71, v_num=., loss/loss=0.692, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517] \n",
      "Epoch 1:  43%|████▎     | 151/350 [00:05<00:07, 28.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A68)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 152/350 [00:08<00:11, 17.94it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  44%|████▎     | 153/350 [00:08<00:10, 18.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  44%|████▍     | 154/350 [00:08<00:10, 18.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  44%|████▍     | 155/350 [00:08<00:10, 18.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  45%|████▍     | 156/350 [00:08<00:10, 18.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 1:  45%|████▍     | 157/350 [00:08<00:10, 18.44it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 1:  45%|████▌     | 158/350 [00:08<00:10, 18.54it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  45%|████▌     | 159/350 [00:08<00:10, 18.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  46%|████▌     | 160/350 [00:08<00:10, 18.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  46%|████▌     | 161/350 [00:08<00:10, 18.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  46%|████▋     | 162/350 [00:08<00:09, 18.94it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Validation DataLoader 0:   6%|▌         | 12/199 [00:00<00:01, 119.18it/s]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 163/350 [00:08<00:09, 19.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  47%|████▋     | 164/350 [00:08<00:09, 19.13it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  47%|████▋     | 165/350 [00:08<00:09, 19.23it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  47%|████▋     | 166/350 [00:08<00:09, 19.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  48%|████▊     | 167/350 [00:08<00:09, 19.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  48%|████▊     | 168/350 [00:08<00:09, 19.53it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  48%|████▊     | 169/350 [00:08<00:09, 19.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  49%|████▊     | 170/350 [00:08<00:09, 19.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  49%|████▉     | 171/350 [00:08<00:09, 19.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 1:  49%|████▉     | 172/350 [00:08<00:08, 19.92it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  11%|█         | 22/199 [00:00<00:01, 119.18it/s]\u001b[A\r",
      "Epoch 1:  49%|████▉     | 173/350 [00:08<00:08, 20.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  12%|█▏        | 23/199 [00:00<00:01, 119.18it/s]\u001b[A\r",
      "Epoch 1:  50%|████▉     | 174/350 [00:08<00:08, 20.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  12%|█▏        | 24/199 [00:00<00:01, 119.18it/s]\u001b[A\r",
      "Epoch 1:  50%|█████     | 175/350 [00:08<00:08, 20.21it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  13%|█▎        | 25/199 [00:00<00:01, 120.85it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  13%|█▎        | 25/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  50%|█████     | 176/350 [00:08<00:08, 20.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  13%|█▎        | 26/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  51%|█████     | 177/350 [00:08<00:08, 20.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  14%|█▎        | 27/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  51%|█████     | 178/350 [00:08<00:08, 20.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  14%|█▍        | 28/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  51%|█████     | 179/350 [00:08<00:08, 20.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  15%|█▍        | 29/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  51%|█████▏    | 180/350 [00:08<00:08, 20.68it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  15%|█▌        | 30/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  52%|█████▏    | 181/350 [00:08<00:08, 20.78it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  16%|█▌        | 31/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  52%|█████▏    | 182/350 [00:08<00:08, 20.88it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  52%|█████▏    | 182/350 [00:08<00:08, 20.88it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  16%|█▌        | 32/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  52%|█████▏    | 183/350 [00:08<00:07, 20.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  17%|█▋        | 33/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  53%|█████▎    | 184/350 [00:08<00:07, 21.07it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  17%|█▋        | 34/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  53%|█████▎    | 185/350 [00:08<00:07, 21.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 35/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  53%|█████▎    | 186/350 [00:08<00:07, 21.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 36/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  53%|█████▎    | 187/350 [00:08<00:07, 21.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▊        | 37/199 [00:00<00:01, 120.85it/s]\u001b[A\r",
      "Epoch 1:  54%|█████▎    | 188/350 [00:08<00:07, 21.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▉        | 38/199 [00:00<00:01, 118.18it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▉        | 38/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  54%|█████▍    | 189/350 [00:08<00:07, 21.52it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|█▉        | 39/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  54%|█████▍    | 190/350 [00:08<00:07, 21.62it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|██        | 40/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  55%|█████▍    | 191/350 [00:08<00:07, 21.70it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  21%|██        | 41/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  55%|█████▍    | 192/350 [00:08<00:07, 21.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  21%|██        | 42/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  55%|█████▌    | 193/350 [00:08<00:07, 21.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  22%|██▏       | 43/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  55%|█████▌    | 194/350 [00:08<00:07, 21.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  22%|██▏       | 44/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  56%|█████▌    | 195/350 [00:08<00:07, 22.08it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  56%|█████▌    | 195/350 [00:08<00:07, 22.08it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 45/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  56%|█████▌    | 196/350 [00:08<00:06, 22.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 46/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  56%|█████▋    | 197/350 [00:08<00:06, 22.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▎       | 47/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  57%|█████▋    | 198/350 [00:08<00:06, 22.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▍       | 48/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  57%|█████▋    | 199/350 [00:08<00:06, 22.45it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▍       | 49/199 [00:00<00:01, 118.18it/s]\u001b[A\r",
      "Epoch 1:  57%|█████▋    | 200/350 [00:08<00:06, 22.54it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▌       | 50/199 [00:00<00:01, 118.26it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▌       | 50/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  57%|█████▋    | 201/350 [00:08<00:06, 22.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 51/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  58%|█████▊    | 202/350 [00:08<00:06, 22.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 52/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  58%|█████▊    | 203/350 [00:08<00:06, 22.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 53/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  58%|█████▊    | 204/350 [00:08<00:06, 22.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 54/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  59%|█████▊    | 205/350 [00:08<00:06, 22.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 55/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  59%|█████▉    | 206/350 [00:08<00:06, 23.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 56/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  59%|█████▉    | 207/350 [00:08<00:06, 23.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▊       | 57/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  59%|█████▉    | 208/350 [00:08<00:06, 23.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  59%|█████▉    | 208/350 [00:08<00:06, 23.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▉       | 58/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  60%|█████▉    | 209/350 [00:08<00:06, 23.36it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|██▉       | 59/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  60%|██████    | 210/350 [00:08<00:05, 23.45it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|███       | 60/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  60%|██████    | 211/350 [00:08<00:05, 23.54it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 61/199 [00:00<00:01, 118.26it/s]\u001b[A\r",
      "Epoch 1:  61%|██████    | 212/350 [00:08<00:05, 23.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 62/199 [00:00<00:01, 118.25it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 62/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  61%|██████    | 213/350 [00:08<00:05, 23.71it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 63/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  61%|██████    | 214/350 [00:08<00:05, 23.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 64/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  61%|██████▏   | 215/350 [00:09<00:05, 23.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 65/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  62%|██████▏   | 216/350 [00:09<00:05, 23.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 66/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  62%|██████▏   | 217/350 [00:09<00:05, 24.06it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▎      | 67/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  62%|██████▏   | 218/350 [00:09<00:05, 24.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▍      | 68/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  63%|██████▎   | 219/350 [00:09<00:05, 24.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▍      | 69/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  63%|██████▎   | 220/350 [00:09<00:05, 24.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▌      | 70/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  63%|██████▎   | 221/350 [00:09<00:05, 24.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  63%|██████▎   | 221/350 [00:09<00:05, 24.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 71/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  63%|██████▎   | 222/350 [00:09<00:05, 24.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 72/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  64%|██████▎   | 223/350 [00:09<00:05, 24.60it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 73/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  64%|██████▍   | 224/350 [00:09<00:05, 24.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 74/199 [00:00<00:01, 118.25it/s]\u001b[A\r",
      "Epoch 1:  64%|██████▍   | 225/350 [00:09<00:05, 24.77it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 75/199 [00:00<00:01, 119.58it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 75/199 [00:00<00:01, 119.58it/s]\u001b[A\r",
      "Epoch 1:  65%|██████▍   | 226/350 [00:09<00:04, 24.86it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 76/199 [00:00<00:01, 119.58it/s]\u001b[A\r",
      "Epoch 1:  65%|██████▍   | 227/350 [00:09<00:04, 24.95it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▊      | 77/199 [00:00<00:01, 119.58it/s]\u001b[A\r",
      "Epoch 1:  65%|██████▌   | 228/350 [00:09<00:04, 25.03it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▉      | 78/199 [00:00<00:01, 119.58it/s]\u001b[A\r",
      "Epoch 1:  65%|██████▌   | 229/350 [00:09<00:04, 25.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  40%|███▉      | 79/199 [00:00<00:01, 119.58it/s]\u001b[A\r",
      "Epoch 1:  66%|██████▌   | 230/350 [00:09<00:04, 25.21it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  40%|████      | 80/199 [00:00<00:00, 119.58it/s]\u001b[A\r",
      "Epoch 1:  66%|██████▌   | 231/350 [00:09<00:04, 25.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 81/199 [00:00<00:00, 119.58it/s]\u001b[A\r",
      "Epoch 1:  66%|██████▋   | 232/350 [00:09<00:04, 25.38it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 82/199 [00:00<00:00, 119.58it/s]\u001b[A\r",
      "Epoch 1:  67%|██████▋   | 233/350 [00:09<00:04, 25.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 83/199 [00:00<00:00, 119.58it/s]\u001b[A\r",
      "Epoch 1:  67%|██████▋   | 234/350 [00:09<00:04, 25.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  67%|██████▋   | 234/350 [00:09<00:04, 25.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 84/199 [00:00<00:00, 119.58it/s]\u001b[A\r",
      "Epoch 1:  67%|██████▋   | 235/350 [00:09<00:04, 25.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 85/199 [00:00<00:00, 119.58it/s]\u001b[A\r",
      "Epoch 1:  67%|██████▋   | 236/350 [00:09<00:04, 25.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 86/199 [00:00<00:00, 119.58it/s]\u001b[A\r",
      "Epoch 1:  68%|██████▊   | 237/350 [00:09<00:04, 25.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▎     | 87/199 [00:00<00:00, 119.58it/s]\u001b[A\r",
      "Epoch 1:  68%|██████▊   | 238/350 [00:09<00:04, 25.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 88/199 [00:00<00:00, 121.09it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 88/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  68%|██████▊   | 239/350 [00:09<00:04, 25.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▍     | 89/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  69%|██████▊   | 240/350 [00:09<00:04, 26.07it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▌     | 90/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  69%|██████▉   | 241/350 [00:09<00:04, 26.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 91/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  69%|██████▉   | 242/350 [00:09<00:04, 26.23it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 92/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  69%|██████▉   | 243/350 [00:09<00:04, 26.31it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 93/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  70%|██████▉   | 244/350 [00:09<00:04, 26.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 94/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  70%|███████   | 245/350 [00:09<00:03, 26.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 95/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  70%|███████   | 246/350 [00:09<00:03, 26.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 96/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  71%|███████   | 247/350 [00:09<00:03, 26.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  71%|███████   | 247/350 [00:09<00:03, 26.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▊     | 97/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  71%|███████   | 248/350 [00:09<00:03, 26.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▉     | 98/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  71%|███████   | 249/350 [00:09<00:03, 26.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|████▉     | 99/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  71%|███████▏  | 250/350 [00:09<00:03, 26.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|█████     | 100/199 [00:00<00:00, 121.09it/s]\u001b[A\r",
      "Epoch 1:  72%|███████▏  | 251/350 [00:09<00:03, 26.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████     | 101/199 [00:00<00:00, 119.20it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████     | 101/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  72%|███████▏  | 252/350 [00:09<00:03, 27.07it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████▏    | 102/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  72%|███████▏  | 253/350 [00:09<00:03, 27.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  52%|█████▏    | 103/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  73%|███████▎  | 254/350 [00:09<00:03, 27.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  52%|█████▏    | 104/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  73%|███████▎  | 255/350 [00:09<00:03, 27.32it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  53%|█████▎    | 105/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  73%|███████▎  | 256/350 [00:09<00:03, 27.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  53%|█████▎    | 106/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  73%|███████▎  | 257/350 [00:09<00:03, 27.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  54%|█████▍    | 107/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  74%|███████▎  | 258/350 [00:09<00:03, 27.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  54%|█████▍    | 108/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  74%|███████▍  | 259/350 [00:09<00:03, 27.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  55%|█████▍    | 109/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  74%|███████▍  | 260/350 [00:09<00:03, 27.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  74%|███████▍  | 260/350 [00:09<00:03, 27.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  55%|█████▌    | 110/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  75%|███████▍  | 261/350 [00:09<00:03, 27.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  56%|█████▌    | 111/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  75%|███████▍  | 262/350 [00:09<00:03, 27.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  56%|█████▋    | 112/199 [00:00<00:00, 119.20it/s]\u001b[A\r",
      "Epoch 1:  75%|███████▌  | 263/350 [00:09<00:03, 27.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 113/199 [00:00<00:00, 119.27it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 113/199 [00:00<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  75%|███████▌  | 264/350 [00:09<00:03, 28.06it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 114/199 [00:00<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  76%|███████▌  | 265/350 [00:09<00:03, 28.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 115/199 [00:00<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  76%|███████▌  | 266/350 [00:09<00:02, 28.22it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 116/199 [00:00<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  76%|███████▋  | 267/350 [00:09<00:02, 28.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  59%|█████▉    | 117/199 [00:00<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  77%|███████▋  | 268/350 [00:09<00:02, 28.37it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  59%|█████▉    | 118/199 [00:00<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  77%|███████▋  | 269/350 [00:09<00:02, 28.45it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  60%|█████▉    | 119/199 [00:01<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  77%|███████▋  | 270/350 [00:09<00:02, 28.53it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  60%|██████    | 120/199 [00:01<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  77%|███████▋  | 271/350 [00:09<00:02, 28.61it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  61%|██████    | 121/199 [00:01<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  78%|███████▊  | 272/350 [00:09<00:02, 28.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  61%|██████▏   | 122/199 [00:01<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  78%|███████▊  | 273/350 [00:09<00:02, 28.77it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  78%|███████▊  | 273/350 [00:09<00:02, 28.77it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  62%|██████▏   | 123/199 [00:01<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  78%|███████▊  | 274/350 [00:09<00:02, 28.85it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  62%|██████▏   | 124/199 [00:01<00:00, 119.27it/s]\u001b[A\r",
      "Epoch 1:  79%|███████▊  | 275/350 [00:09<00:02, 28.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 125/199 [00:01<00:00, 117.58it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 125/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  79%|███████▉  | 276/350 [00:09<00:02, 29.01it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 126/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  79%|███████▉  | 277/350 [00:09<00:02, 29.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  64%|██████▍   | 127/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  79%|███████▉  | 278/350 [00:09<00:02, 29.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  64%|██████▍   | 128/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  80%|███████▉  | 279/350 [00:09<00:02, 29.25it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  65%|██████▍   | 129/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  80%|████████  | 280/350 [00:09<00:02, 29.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  65%|██████▌   | 130/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  80%|████████  | 281/350 [00:09<00:02, 29.41it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  66%|██████▌   | 131/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  81%|████████  | 282/350 [00:09<00:02, 29.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  66%|██████▋   | 132/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  81%|████████  | 283/350 [00:09<00:02, 29.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  67%|██████▋   | 133/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  81%|████████  | 284/350 [00:09<00:02, 29.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  67%|██████▋   | 134/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  81%|████████▏ | 285/350 [00:09<00:02, 29.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  68%|██████▊   | 135/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  82%|████████▏ | 286/350 [00:09<00:02, 29.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  82%|████████▏ | 286/350 [00:09<00:02, 29.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  68%|██████▊   | 136/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  82%|████████▏ | 287/350 [00:09<00:02, 29.88it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 137/199 [00:01<00:00, 117.58it/s]\u001b[A\r",
      "Epoch 1:  82%|████████▏ | 288/350 [00:09<00:02, 29.96it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 138/199 [00:01<00:00, 118.68it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 138/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  83%|████████▎ | 289/350 [00:09<00:02, 30.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  70%|██████▉   | 139/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  83%|████████▎ | 290/350 [00:09<00:01, 30.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  70%|███████   | 140/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  83%|████████▎ | 291/350 [00:09<00:01, 30.20it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  71%|███████   | 141/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  83%|████████▎ | 292/350 [00:09<00:01, 30.27it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  71%|███████▏  | 142/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  84%|████████▎ | 293/350 [00:09<00:01, 30.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  72%|███████▏  | 143/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  84%|████████▍ | 294/350 [00:09<00:01, 30.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  72%|███████▏  | 144/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  84%|████████▍ | 295/350 [00:09<00:01, 30.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  73%|███████▎  | 145/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  85%|████████▍ | 296/350 [00:09<00:01, 30.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  73%|███████▎  | 146/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  85%|████████▍ | 297/350 [00:09<00:01, 30.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  74%|███████▍  | 147/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  85%|████████▌ | 298/350 [00:09<00:01, 30.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  74%|███████▍  | 148/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  85%|████████▌ | 299/350 [00:09<00:01, 30.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  85%|████████▌ | 299/350 [00:09<00:01, 30.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▍  | 149/199 [00:01<00:00, 118.68it/s]\u001b[A\r",
      "Epoch 1:  86%|████████▌ | 300/350 [00:09<00:01, 30.87it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▌  | 150/199 [00:01<00:00, 117.37it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▌  | 150/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  86%|████████▌ | 301/350 [00:09<00:01, 30.94it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  76%|███████▌  | 151/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  86%|████████▋ | 302/350 [00:09<00:01, 31.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  76%|███████▋  | 152/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  87%|████████▋ | 303/350 [00:09<00:01, 31.10it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  77%|███████▋  | 153/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  87%|████████▋ | 304/350 [00:09<00:01, 31.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  77%|███████▋  | 154/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  87%|████████▋ | 305/350 [00:09<00:01, 31.25it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  78%|███████▊  | 155/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  87%|████████▋ | 306/350 [00:09<00:01, 31.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  78%|███████▊  | 156/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  88%|████████▊ | 307/350 [00:09<00:01, 31.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  79%|███████▉  | 157/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  88%|████████▊ | 308/350 [00:09<00:01, 31.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  79%|███████▉  | 158/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  88%|████████▊ | 309/350 [00:09<00:01, 31.55it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  80%|███████▉  | 159/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  89%|████████▊ | 310/350 [00:09<00:01, 31.62it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  80%|████████  | 160/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  89%|████████▉ | 311/350 [00:09<00:01, 31.68it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████  | 161/199 [00:01<00:00, 117.37it/s]\u001b[A\r",
      "Epoch 1:  89%|████████▉ | 312/350 [00:09<00:01, 31.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  89%|████████▉ | 312/350 [00:09<00:01, 31.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████▏ | 162/199 [00:01<00:00, 113.83it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████▏ | 162/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  89%|████████▉ | 313/350 [00:09<00:01, 31.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  82%|████████▏ | 163/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  90%|████████▉ | 314/350 [00:09<00:01, 31.87it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  82%|████████▏ | 164/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  90%|█████████ | 315/350 [00:09<00:01, 31.94it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  83%|████████▎ | 165/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  90%|█████████ | 316/350 [00:09<00:01, 32.00it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  83%|████████▎ | 166/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  91%|█████████ | 317/350 [00:09<00:01, 32.07it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  84%|████████▍ | 167/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  91%|█████████ | 318/350 [00:09<00:00, 32.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  84%|████████▍ | 168/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  91%|█████████ | 319/350 [00:09<00:00, 32.22it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  85%|████████▍ | 169/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  91%|█████████▏| 320/350 [00:09<00:00, 32.29it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  85%|████████▌ | 170/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  92%|█████████▏| 321/350 [00:09<00:00, 32.36it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  86%|████████▌ | 171/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  92%|█████████▏| 322/350 [00:09<00:00, 32.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  86%|████████▋ | 172/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  92%|█████████▏| 323/350 [00:09<00:00, 32.50it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 173/199 [00:01<00:00, 113.83it/s]\u001b[A\r",
      "Epoch 1:  93%|█████████▎| 324/350 [00:09<00:00, 32.58it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 174/199 [00:01<00:00, 110.81it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 174/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  93%|█████████▎| 325/350 [00:09<00:00, 32.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  93%|█████████▎| 325/350 [00:09<00:00, 32.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:13 (running for 00:01:33.00)\n",
      "Memory usage on this node: 11.0/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931675672531128 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693168 |           0.5 |           1 |                    1 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  88%|████████▊ | 175/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  93%|█████████▎| 326/350 [00:09<00:00, 32.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  88%|████████▊ | 176/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  93%|█████████▎| 327/350 [00:09<00:00, 32.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  89%|████████▉ | 177/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  94%|█████████▎| 328/350 [00:09<00:00, 32.86it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  89%|████████▉ | 178/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  94%|█████████▍| 329/350 [00:09<00:00, 32.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  90%|████████▉ | 179/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  94%|█████████▍| 330/350 [00:09<00:00, 33.01it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  90%|█████████ | 180/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  95%|█████████▍| 331/350 [00:10<00:00, 33.08it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  91%|█████████ | 181/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  95%|█████████▍| 332/350 [00:10<00:00, 33.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  91%|█████████▏| 182/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  95%|█████████▌| 333/350 [00:10<00:00, 33.22it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  92%|█████████▏| 183/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  95%|█████████▌| 334/350 [00:10<00:00, 33.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  92%|█████████▏| 184/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  96%|█████████▌| 335/350 [00:10<00:00, 33.37it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 185/199 [00:01<00:00, 110.81it/s]\u001b[A\r",
      "Epoch 1:  96%|█████████▌| 336/350 [00:10<00:00, 33.44it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 186/199 [00:01<00:00, 112.98it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 186/199 [00:01<00:00, 112.98it/s]\u001b[A\r",
      "Epoch 1:  96%|█████████▋| 337/350 [00:10<00:00, 33.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  94%|█████████▍| 187/199 [00:01<00:00, 112.98it/s]\u001b[A\r",
      "Epoch 1:  97%|█████████▋| 338/350 [00:10<00:00, 33.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\r",
      "Epoch 1:  97%|█████████▋| 338/350 [00:10<00:00, 33.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  94%|█████████▍| 188/199 [00:01<00:00, 112.98it/s]\u001b[A\r",
      "Epoch 1:  97%|█████████▋| 339/350 [00:10<00:00, 33.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_mnist_tune_56334_00000:\n",
      "  date: 2022-07-13_10-41-13\n",
      "  done: false\n",
      "  experiment_id: 982c1c173bd44ceabdf99b78b60d4d2d\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6934348940849304\n",
      "  mean_pred: 1.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 1268\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 88.4482741355896\n",
      "  time_this_iter_s: 10.196540355682373\n",
      "  time_total_s: 88.4482741355896\n",
      "  timestamp: 1657701673\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: '56334_00000'\n",
      "  val_bal_acc: 0.5\n",
      "  val_loss: 0.6931039690971375\n",
      "  warmup_time: 0.004000186920166016\n",
      "  \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 1:  97%|█████████▋| 340/350 [00:10<00:00, 33.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  97%|█████████▋| 341/350 [00:10<00:00, 33.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  98%|█████████▊| 342/350 [00:10<00:00, 33.87it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  98%|█████████▊| 343/350 [00:10<00:00, 33.94it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  98%|█████████▊| 344/350 [00:10<00:00, 34.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  99%|█████████▊| 345/350 [00:10<00:00, 34.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  99%|█████████▉| 346/350 [00:10<00:00, 34.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  99%|█████████▉| 347/350 [00:10<00:00, 34.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1:  99%|█████████▉| 348/350 [00:10<00:00, 34.31it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1: 100%|█████████▉| 349/350 [00:10<00:00, 34.39it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Validation DataLoader 0: 100%|██████████| 199/199 [00:01<00:00, 117.50it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 350/350 [00:10<00:00, 34.46it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 1: 100%|██████████| 350/350 [00:10<00:00, 34.36it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.517]\n",
      "Epoch 2:   0%|          | 0/350 [00:00<?, ?it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]          \n",
      "Epoch 2:   0%|          | 1/350 [00:03<21:04,  3.62s/it, loss=0.706, v_num=., loss/loss=0.695, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:   3%|▎         | 10/350 [00:03<02:08,  2.65it/s, loss=0.692, v_num=., loss/loss=0.690, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:   5%|▌         | 19/350 [00:03<01:07,  4.88it/s, loss=0.694, v_num=., loss/loss=0.691, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:   8%|▊         | 28/350 [00:04<00:46,  6.99it/s, loss=0.693, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  11%|█         | 37/350 [00:04<00:34,  8.98it/s, loss=0.692, v_num=., loss/loss=0.687, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  13%|█▎        | 47/350 [00:04<00:27, 11.10it/s, loss=0.689, v_num=., loss/loss=0.644, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  13%|█▎        | 47/350 [00:04<00:27, 11.10it/s, loss=0.688, v_num=., loss/loss=0.671, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  16%|█▋        | 57/350 [00:04<00:22, 13.10it/s, loss=0.684, v_num=., loss/loss=0.636, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  19%|█▉        | 66/350 [00:04<00:19, 14.80it/s, loss=0.692, v_num=., loss/loss=0.692, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  22%|██▏       | 76/350 [00:04<00:16, 16.62it/s, loss=0.696, v_num=., loss/loss=0.697, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  25%|██▍       | 86/350 [00:04<00:14, 18.34it/s, loss=0.694, v_num=., loss/loss=0.691, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  27%|██▋       | 95/350 [00:04<00:12, 19.81it/s, loss=0.692, v_num=., loss/loss=0.698, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  30%|██▉       | 104/350 [00:04<00:11, 21.22it/s, loss=0.701, v_num=., loss/loss=0.692, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  33%|███▎      | 114/350 [00:05<00:10, 22.72it/s, loss=0.704, v_num=., loss/loss=0.699, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:19 (running for 00:01:38.18)\n",
      "Memory usage on this node: 11.1/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931039690971375 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693104 |           0.5 |           1 |                    2 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Epoch 2:  35%|███▌      | 124/350 [00:05<00:09, 24.14it/s, loss=0.688, v_num=., loss/loss=0.676, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  38%|███▊      | 134/350 [00:05<00:08, 25.51it/s, loss=0.689, v_num=., loss/loss=0.707, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  39%|███▊      | 135/350 [00:05<00:08, 25.64it/s, loss=0.691, v_num=., loss/loss=0.741, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  41%|████▏     | 145/350 [00:05<00:07, 26.97it/s, loss=0.705, v_num=., loss/loss=0.694, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  43%|████▎     | 151/350 [00:05<00:07, 27.76it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A68)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 152/350 [00:08<00:11, 17.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  44%|████▎     | 153/350 [00:08<00:11, 17.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  44%|████▍     | 154/350 [00:08<00:10, 17.94it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  44%|████▍     | 155/350 [00:08<00:10, 18.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  45%|████▍     | 156/350 [00:08<00:10, 18.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  45%|████▍     | 157/350 [00:08<00:10, 18.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  45%|████▌     | 158/350 [00:08<00:10, 18.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  45%|████▌     | 159/350 [00:08<00:10, 18.44it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  46%|████▌     | 160/350 [00:08<00:10, 18.54it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  46%|████▌     | 161/350 [00:08<00:10, 18.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 2:  46%|████▋     | 162/350 [00:08<00:10, 18.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation DataLoader 0:   6%|▌         | 12/199 [00:00<00:01, 116.94it/s]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 163/350 [00:08<00:09, 18.83it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  47%|████▋     | 164/350 [00:08<00:09, 18.92it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  47%|████▋     | 165/350 [00:08<00:09, 19.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  47%|████▋     | 166/350 [00:08<00:09, 19.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  48%|████▊     | 167/350 [00:08<00:09, 19.21it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  48%|████▊     | 168/350 [00:08<00:09, 19.31it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  48%|████▊     | 169/350 [00:08<00:09, 19.41it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  49%|████▊     | 170/350 [00:08<00:09, 19.50it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  49%|████▉     | 171/350 [00:08<00:09, 19.60it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  49%|████▉     | 172/350 [00:08<00:09, 19.70it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  49%|████▉     | 173/350 [00:08<00:08, 19.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  50%|████▉     | 174/350 [00:08<00:08, 19.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  50%|█████     | 175/350 [00:08<00:08, 19.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Validation DataLoader 0:  13%|█▎        | 25/199 [00:00<00:01, 121.32it/s]\u001b[A\n",
      "Epoch 2:  50%|█████     | 176/350 [00:08<00:08, 20.08it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 2:  51%|█████     | 177/350 [00:08<00:08, 20.18it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  14%|█▎        | 27/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  51%|█████     | 178/350 [00:08<00:08, 20.27it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  14%|█▍        | 28/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  51%|█████     | 179/350 [00:08<00:08, 20.37it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  15%|█▍        | 29/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  51%|█████▏    | 180/350 [00:08<00:08, 20.46it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  15%|█▌        | 30/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  52%|█████▏    | 181/350 [00:08<00:08, 20.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  16%|█▌        | 31/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  52%|█████▏    | 182/350 [00:08<00:08, 20.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  52%|█████▏    | 182/350 [00:08<00:08, 20.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  16%|█▌        | 32/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  52%|█████▏    | 183/350 [00:08<00:08, 20.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  17%|█▋        | 33/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  53%|█████▎    | 184/350 [00:08<00:07, 20.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  17%|█▋        | 34/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  53%|█████▎    | 185/350 [00:08<00:07, 20.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 35/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  53%|█████▎    | 186/350 [00:08<00:07, 21.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 36/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  53%|█████▎    | 187/350 [00:08<00:07, 21.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▊        | 37/199 [00:00<00:01, 121.32it/s]\u001b[A\r",
      "Epoch 2:  54%|█████▎    | 188/350 [00:08<00:07, 21.21it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▉        | 38/199 [00:00<00:01, 120.03it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▉        | 38/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  54%|█████▍    | 189/350 [00:08<00:07, 21.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|█▉        | 39/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  54%|█████▍    | 190/350 [00:08<00:07, 21.39it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|██        | 40/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  55%|█████▍    | 191/350 [00:08<00:07, 21.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  21%|██        | 41/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  55%|█████▍    | 192/350 [00:08<00:07, 21.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  21%|██        | 42/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  55%|█████▌    | 193/350 [00:08<00:07, 21.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  22%|██▏       | 43/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  55%|█████▌    | 194/350 [00:08<00:07, 21.75it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  22%|██▏       | 44/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  56%|█████▌    | 195/350 [00:08<00:07, 21.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  56%|█████▌    | 195/350 [00:08<00:07, 21.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 45/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  56%|█████▌    | 196/350 [00:08<00:07, 21.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 46/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  56%|█████▋    | 197/350 [00:08<00:06, 22.03it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▎       | 47/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  57%|█████▋    | 198/350 [00:08<00:06, 22.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▍       | 48/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  57%|█████▋    | 199/350 [00:08<00:06, 22.21it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▍       | 49/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  57%|█████▋    | 200/350 [00:08<00:06, 22.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▌       | 50/199 [00:00<00:01, 120.03it/s]\u001b[A\r",
      "Epoch 2:  57%|█████▋    | 201/350 [00:08<00:06, 22.39it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 51/199 [00:00<00:01, 119.05it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 51/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  58%|█████▊    | 202/350 [00:08<00:06, 22.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 52/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  58%|█████▊    | 203/350 [00:08<00:06, 22.58it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 53/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  58%|█████▊    | 204/350 [00:08<00:06, 22.67it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 54/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  59%|█████▊    | 205/350 [00:09<00:06, 22.76it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 55/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  59%|█████▉    | 206/350 [00:09<00:06, 22.85it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 56/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  59%|█████▉    | 207/350 [00:09<00:06, 22.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▊       | 57/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  59%|█████▉    | 208/350 [00:09<00:06, 23.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  59%|█████▉    | 208/350 [00:09<00:06, 23.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▉       | 58/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  60%|█████▉    | 209/350 [00:09<00:06, 23.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|██▉       | 59/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  60%|██████    | 210/350 [00:09<00:06, 23.20it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|███       | 60/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  60%|██████    | 211/350 [00:09<00:05, 23.29it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 61/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  61%|██████    | 212/350 [00:09<00:05, 23.38it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 62/199 [00:00<00:01, 119.05it/s]\u001b[A\r",
      "Epoch 2:  61%|██████    | 213/350 [00:09<00:05, 23.46it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 63/199 [00:00<00:01, 118.35it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 63/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  61%|██████    | 214/350 [00:09<00:05, 23.55it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 64/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  61%|██████▏   | 215/350 [00:09<00:05, 23.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 65/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  62%|██████▏   | 216/350 [00:09<00:05, 23.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 66/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  62%|██████▏   | 217/350 [00:09<00:05, 23.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▎      | 67/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  62%|██████▏   | 218/350 [00:09<00:05, 23.88it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▍      | 68/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  63%|██████▎   | 219/350 [00:09<00:05, 23.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▍      | 69/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  63%|██████▎   | 220/350 [00:09<00:05, 24.06it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▌      | 70/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  63%|██████▎   | 221/350 [00:09<00:05, 24.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  63%|██████▎   | 221/350 [00:09<00:05, 24.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 71/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  63%|██████▎   | 222/350 [00:09<00:05, 24.23it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 72/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  64%|██████▎   | 223/350 [00:09<00:05, 24.32it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 73/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  64%|██████▍   | 224/350 [00:09<00:05, 24.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 74/199 [00:00<00:01, 118.35it/s]\u001b[A\r",
      "Epoch 2:  64%|██████▍   | 225/350 [00:09<00:05, 24.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 75/199 [00:00<00:01, 115.37it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 75/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  65%|██████▍   | 226/350 [00:09<00:05, 24.58it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 76/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  65%|██████▍   | 227/350 [00:09<00:04, 24.67it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▊      | 77/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  65%|██████▌   | 228/350 [00:09<00:04, 24.75it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▉      | 78/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  65%|██████▌   | 229/350 [00:09<00:04, 24.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  40%|███▉      | 79/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  66%|██████▌   | 230/350 [00:09<00:04, 24.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  40%|████      | 80/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  66%|██████▌   | 231/350 [00:09<00:04, 25.01it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 81/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  66%|██████▋   | 232/350 [00:09<00:04, 25.10it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 82/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  67%|██████▋   | 233/350 [00:09<00:04, 25.19it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 83/199 [00:00<00:01, 115.37it/s]\u001b[A\r",
      "Epoch 2:  67%|██████▋   | 234/350 [00:09<00:04, 25.27it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  67%|██████▋   | 234/350 [00:09<00:04, 25.27it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 84/199 [00:00<00:00, 115.37it/s]\u001b[A\r",
      "Epoch 2:  67%|██████▋   | 235/350 [00:09<00:04, 25.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 85/199 [00:00<00:00, 115.37it/s]\u001b[A\r",
      "Epoch 2:  67%|██████▋   | 236/350 [00:09<00:04, 25.44it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 86/199 [00:00<00:00, 115.37it/s]\u001b[A\r",
      "Epoch 2:  68%|██████▊   | 237/350 [00:09<00:04, 25.52it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▎     | 87/199 [00:00<00:00, 115.37it/s]\u001b[A\r",
      "Epoch 2:  68%|██████▊   | 238/350 [00:09<00:04, 25.61it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 88/199 [00:00<00:00, 117.55it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 88/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  68%|██████▊   | 239/350 [00:09<00:04, 25.70it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▍     | 89/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  69%|██████▊   | 240/350 [00:09<00:04, 25.78it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▌     | 90/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  69%|██████▉   | 241/350 [00:09<00:04, 25.86it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 91/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  69%|██████▉   | 242/350 [00:09<00:04, 25.95it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 92/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  69%|██████▉   | 243/350 [00:09<00:04, 26.03it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 93/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  70%|██████▉   | 244/350 [00:09<00:04, 26.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 94/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  70%|███████   | 245/350 [00:09<00:04, 26.20it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 95/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  70%|███████   | 246/350 [00:09<00:03, 26.27it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 96/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  71%|███████   | 247/350 [00:09<00:03, 26.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  71%|███████   | 247/350 [00:09<00:03, 26.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▊     | 97/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  71%|███████   | 248/350 [00:09<00:03, 26.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▉     | 98/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  71%|███████   | 249/350 [00:09<00:03, 26.52it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|████▉     | 99/199 [00:00<00:00, 117.55it/s]\u001b[A\r",
      "Epoch 2:  71%|███████▏  | 250/350 [00:09<00:03, 26.60it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|█████     | 100/199 [00:00<00:00, 116.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|█████     | 100/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  72%|███████▏  | 251/350 [00:09<00:03, 26.68it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████     | 101/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  72%|███████▏  | 252/350 [00:09<00:03, 26.77it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████▏    | 102/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  72%|███████▏  | 253/350 [00:09<00:03, 26.85it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  52%|█████▏    | 103/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  73%|███████▎  | 254/350 [00:09<00:03, 26.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  52%|█████▏    | 104/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  73%|███████▎  | 255/350 [00:09<00:03, 27.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  53%|█████▎    | 105/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  73%|███████▎  | 256/350 [00:09<00:03, 27.10it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  53%|█████▎    | 106/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  73%|███████▎  | 257/350 [00:09<00:03, 27.18it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  54%|█████▍    | 107/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  74%|███████▎  | 258/350 [00:09<00:03, 27.27it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  54%|█████▍    | 108/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  74%|███████▍  | 259/350 [00:09<00:03, 27.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  55%|█████▍    | 109/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  74%|███████▍  | 260/350 [00:09<00:03, 27.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  74%|███████▍  | 260/350 [00:09<00:03, 27.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  55%|█████▌    | 110/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  75%|███████▍  | 261/350 [00:09<00:03, 27.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  56%|█████▌    | 111/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  75%|███████▍  | 262/350 [00:09<00:03, 27.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  56%|█████▋    | 112/199 [00:00<00:00, 116.50it/s]\u001b[A\r",
      "Epoch 2:  75%|███████▌  | 263/350 [00:09<00:03, 27.67it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 113/199 [00:00<00:00, 118.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 113/199 [00:00<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  75%|███████▌  | 264/350 [00:09<00:03, 27.75it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 114/199 [00:00<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  76%|███████▌  | 265/350 [00:09<00:03, 27.83it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 115/199 [00:00<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  76%|███████▌  | 266/350 [00:09<00:03, 27.91it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 116/199 [00:00<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  76%|███████▋  | 267/350 [00:09<00:02, 27.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  59%|█████▉    | 117/199 [00:00<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  77%|███████▋  | 268/350 [00:09<00:02, 28.08it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  59%|█████▉    | 118/199 [00:00<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  77%|███████▋  | 269/350 [00:09<00:02, 28.16it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  60%|█████▉    | 119/199 [00:01<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  77%|███████▋  | 270/350 [00:09<00:02, 28.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  60%|██████    | 120/199 [00:01<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  77%|███████▋  | 271/350 [00:09<00:02, 28.32it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  61%|██████    | 121/199 [00:01<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  78%|███████▊  | 272/350 [00:09<00:02, 28.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  61%|██████▏   | 122/199 [00:01<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  78%|███████▊  | 273/350 [00:09<00:02, 28.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  78%|███████▊  | 273/350 [00:09<00:02, 28.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  62%|██████▏   | 123/199 [00:01<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  78%|███████▊  | 274/350 [00:09<00:02, 28.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  62%|██████▏   | 124/199 [00:01<00:00, 118.50it/s]\u001b[A\r",
      "Epoch 2:  79%|███████▊  | 275/350 [00:09<00:02, 28.62it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 125/199 [00:01<00:00, 117.56it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 125/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  79%|███████▉  | 276/350 [00:09<00:02, 28.70it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 126/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  79%|███████▉  | 277/350 [00:09<00:02, 28.78it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  64%|██████▍   | 127/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  79%|███████▉  | 278/350 [00:09<00:02, 28.85it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  64%|██████▍   | 128/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  80%|███████▉  | 279/350 [00:09<00:02, 28.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  65%|██████▍   | 129/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  80%|████████  | 280/350 [00:09<00:02, 29.01it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  65%|██████▌   | 130/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  80%|████████  | 281/350 [00:09<00:02, 29.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  66%|██████▌   | 131/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  81%|████████  | 282/350 [00:09<00:02, 29.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  66%|██████▋   | 132/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  81%|████████  | 283/350 [00:09<00:02, 29.25it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  67%|██████▋   | 133/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  81%|████████  | 284/350 [00:09<00:02, 29.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  67%|██████▋   | 134/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  81%|████████▏ | 285/350 [00:09<00:02, 29.41it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  68%|██████▊   | 135/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  82%|████████▏ | 286/350 [00:09<00:02, 29.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  82%|████████▏ | 286/350 [00:09<00:02, 29.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  68%|██████▊   | 136/199 [00:01<00:00, 117.56it/s]\u001b[A\r",
      "Epoch 2:  82%|████████▏ | 287/350 [00:09<00:02, 29.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 137/199 [00:01<00:00, 118.14it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 137/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  82%|████████▏ | 288/350 [00:09<00:02, 29.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 138/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  83%|████████▎ | 289/350 [00:09<00:02, 29.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  70%|██████▉   | 139/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  83%|████████▎ | 290/350 [00:09<00:02, 29.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  70%|███████   | 140/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  83%|████████▎ | 291/350 [00:09<00:01, 29.87it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  71%|███████   | 141/199 [00:01<00:00, 118.14it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Epoch 2:  83%|████████▎ | 292/350 [00:09<00:01, 29.95it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  71%|███████▏  | 142/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  84%|████████▎ | 293/350 [00:09<00:01, 30.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  72%|███████▏  | 143/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  84%|████████▍ | 294/350 [00:09<00:01, 30.10it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  72%|███████▏  | 144/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  84%|████████▍ | 295/350 [00:09<00:01, 30.18it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  73%|███████▎  | 145/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  85%|████████▍ | 296/350 [00:09<00:01, 30.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  73%|███████▎  | 146/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  85%|████████▍ | 297/350 [00:09<00:01, 30.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  74%|███████▍  | 147/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  85%|████████▌ | 298/350 [00:09<00:01, 30.41it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  74%|███████▍  | 148/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  85%|████████▌ | 299/350 [00:09<00:01, 30.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  85%|████████▌ | 299/350 [00:09<00:01, 30.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▍  | 149/199 [00:01<00:00, 118.14it/s]\u001b[A\r",
      "Epoch 2:  86%|████████▌ | 300/350 [00:09<00:01, 30.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▌  | 150/199 [00:01<00:00, 119.30it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▌  | 150/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  86%|████████▌ | 301/350 [00:09<00:01, 30.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  76%|███████▌  | 151/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  86%|████████▋ | 302/350 [00:09<00:01, 30.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  76%|███████▋  | 152/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  87%|████████▋ | 303/350 [00:09<00:01, 30.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  77%|███████▋  | 153/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  87%|████████▋ | 304/350 [00:09<00:01, 30.86it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  77%|███████▋  | 154/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  87%|████████▋ | 305/350 [00:09<00:01, 30.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  78%|███████▊  | 155/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  87%|████████▋ | 306/350 [00:09<00:01, 31.00it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  78%|███████▊  | 156/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  88%|████████▊ | 307/350 [00:09<00:01, 31.08it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  79%|███████▉  | 157/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  88%|████████▊ | 308/350 [00:09<00:01, 31.16it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  79%|███████▉  | 158/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  88%|████████▊ | 309/350 [00:09<00:01, 31.23it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  80%|███████▉  | 159/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  89%|████████▊ | 310/350 [00:09<00:01, 31.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  80%|████████  | 160/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  89%|████████▉ | 311/350 [00:09<00:01, 31.37it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████  | 161/199 [00:01<00:00, 119.30it/s]\u001b[A\r",
      "Epoch 2:  89%|████████▉ | 312/350 [00:09<00:01, 31.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  89%|████████▉ | 312/350 [00:09<00:01, 31.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████▏ | 162/199 [00:01<00:00, 113.71it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████▏ | 162/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  89%|████████▉ | 313/350 [00:09<00:01, 31.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  82%|████████▏ | 163/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  90%|████████▉ | 314/350 [00:09<00:01, 31.55it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  82%|████████▏ | 164/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  90%|█████████ | 315/350 [00:09<00:01, 31.61it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  83%|████████▎ | 165/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  90%|█████████ | 316/350 [00:09<00:01, 31.67it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  83%|████████▎ | 166/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  91%|█████████ | 317/350 [00:09<00:01, 31.75it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  84%|████████▍ | 167/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  91%|█████████ | 318/350 [00:09<00:01, 31.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:24 (running for 00:01:43.22)\n",
      "Memory usage on this node: 11.1/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931039690971375 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693104 |           0.5 |           1 |                    2 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  84%|████████▍ | 168/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  91%|█████████ | 319/350 [00:10<00:00, 31.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  85%|████████▍ | 169/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  91%|█████████▏| 320/350 [00:10<00:00, 31.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  85%|████████▌ | 170/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  92%|█████████▏| 321/350 [00:10<00:00, 32.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  86%|████████▌ | 171/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  92%|█████████▏| 322/350 [00:10<00:00, 32.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  86%|████████▋ | 172/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  92%|█████████▏| 323/350 [00:10<00:00, 32.19it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 173/199 [00:01<00:00, 113.71it/s]\u001b[A\r",
      "Epoch 2:  93%|█████████▎| 324/350 [00:10<00:00, 32.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 174/199 [00:01<00:00, 112.20it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 174/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  93%|█████████▎| 325/350 [00:10<00:00, 32.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  93%|█████████▎| 325/350 [00:10<00:00, 32.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  88%|████████▊ | 175/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  93%|█████████▎| 326/350 [00:10<00:00, 32.41it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  88%|████████▊ | 176/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  93%|█████████▎| 327/350 [00:10<00:00, 32.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  89%|████████▉ | 177/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  94%|█████████▎| 328/350 [00:10<00:00, 32.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  89%|████████▉ | 178/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  94%|█████████▍| 329/350 [00:10<00:00, 32.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  90%|████████▉ | 179/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  94%|█████████▍| 330/350 [00:10<00:00, 32.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  90%|█████████ | 180/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  95%|█████████▍| 331/350 [00:10<00:00, 32.76it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  91%|█████████ | 181/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  95%|█████████▍| 332/350 [00:10<00:00, 32.83it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  91%|█████████▏| 182/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  95%|█████████▌| 333/350 [00:10<00:00, 32.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  92%|█████████▏| 183/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  95%|█████████▌| 334/350 [00:10<00:00, 32.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  92%|█████████▏| 184/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  96%|█████████▌| 335/350 [00:10<00:00, 33.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 185/199 [00:01<00:00, 112.20it/s]\u001b[A\r",
      "Epoch 2:  96%|█████████▌| 336/350 [00:10<00:00, 33.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 186/199 [00:01<00:00, 113.39it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 186/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  96%|█████████▋| 337/350 [00:10<00:00, 33.19it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  94%|█████████▍| 187/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  97%|█████████▋| 338/350 [00:10<00:00, 33.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\r",
      "Epoch 2:  97%|█████████▋| 338/350 [00:10<00:00, 33.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  94%|█████████▍| 188/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  97%|█████████▋| 339/350 [00:10<00:00, 33.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  95%|█████████▍| 189/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  97%|█████████▋| 340/350 [00:10<00:00, 33.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  95%|█████████▌| 190/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  97%|█████████▋| 341/350 [00:10<00:00, 33.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  96%|█████████▌| 191/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  98%|█████████▊| 342/350 [00:10<00:00, 33.54it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  96%|█████████▋| 192/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  98%|█████████▊| 343/350 [00:10<00:00, 33.61it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  97%|█████████▋| 193/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  98%|█████████▊| 344/350 [00:10<00:00, 33.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  97%|█████████▋| 194/199 [00:01<00:00, 113.39it/s]\u001b[A\r",
      "Epoch 2:  99%|█████████▊| 345/350 [00:10<00:00, 33.76it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Result for train_mnist_tune_56334_00000:\n",
      "  date: 2022-07-13_10-41-24\n",
      "  done: false\n",
      "  experiment_id: 982c1c173bd44ceabdf99b78b60d4d2d\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.6934373378753662\n",
      "  mean_pred: 1.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 1268\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 98.73646450042725\n",
      "  time_this_iter_s: 10.288190364837646\n",
      "  time_total_s: 98.73646450042725\n",
      "  timestamp: 1657701684\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: '56334_00000'\n",
      "  val_bal_acc: 0.5\n",
      "  val_loss: 0.6931049227714539\n",
      "  warmup_time: 0.004000186920166016\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 2:  99%|█████████▉| 346/350 [00:10<00:00, 33.83it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  99%|█████████▉| 347/350 [00:10<00:00, 33.91it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2:  99%|█████████▉| 348/350 [00:10<00:00, 33.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 2: 100%|█████████▉| 349/350 [00:10<00:00, 34.06it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Validation DataLoader 0: 100%|██████████| 199/199 [00:01<00:00, 117.89it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 350/350 [00:10<00:00, 34.05it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.519]\n",
      "Epoch 3:   0%|          | 0/350 [00:00<?, ?it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]          \n",
      "Epoch 3:   1%|▏         | 5/350 [00:03<04:01,  1.43it/s, loss=0.695, v_num=., loss/loss=0.701, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:   2%|▏         | 6/350 [00:03<03:20,  1.71it/s, loss=0.694, v_num=., loss/loss=0.694, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:   5%|▍         | 16/350 [00:03<01:15,  4.42it/s, loss=0.694, v_num=., loss/loss=0.694, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:   7%|▋         | 26/350 [00:03<00:46,  6.94it/s, loss=0.693, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  10%|█         | 36/350 [00:03<00:33,  9.31it/s, loss=0.693, v_num=., loss/loss=0.704, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  13%|█▎        | 45/350 [00:03<00:26, 11.33it/s, loss=0.691, v_num=., loss/loss=0.698, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  15%|█▌        | 54/350 [00:04<00:22, 13.24it/s, loss=0.688, v_num=., loss/loss=0.708, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  18%|█▊        | 64/350 [00:04<00:18, 15.27it/s, loss=0.69, v_num=., loss/loss=0.702, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520] \n",
      "Epoch 3:  21%|██        | 74/350 [00:04<00:16, 17.19it/s, loss=0.694, v_num=., loss/loss=0.691, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  21%|██▏       | 75/350 [00:04<00:15, 17.38it/s, loss=0.695, v_num=., loss/loss=0.694, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  24%|██▍       | 85/350 [00:04<00:13, 19.16it/s, loss=0.694, v_num=., loss/loss=0.692, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  27%|██▋       | 96/350 [00:04<00:12, 21.06it/s, loss=0.692, v_num=., loss/loss=0.706, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  30%|███       | 106/350 [00:04<00:10, 22.68it/s, loss=0.701, v_num=., loss/loss=0.695, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  31%|███       | 107/350 [00:04<00:10, 22.83it/s, loss=0.701, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  33%|███▎      | 117/350 [00:04<00:09, 24.38it/s, loss=0.702, v_num=., loss/loss=0.689, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  36%|███▌      | 126/350 [00:04<00:08, 25.71it/s, loss=0.682, v_num=., loss/loss=0.632, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  36%|███▋      | 127/350 [00:04<00:08, 25.84it/s, loss=0.681, v_num=., loss/loss=0.670, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  39%|███▉      | 137/350 [00:05<00:07, 27.24it/s, loss=0.696, v_num=., loss/loss=0.708, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:29 (running for 00:01:48.45)\n",
      "Memory usage on this node: 11.0/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: None | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931049227714539 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    3 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Epoch 3:  42%|████▏     | 147/350 [00:05<00:07, 28.59it/s, loss=0.709, v_num=., loss/loss=0.692, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  43%|████▎     | 151/350 [00:05<00:06, 29.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A68)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 3:  43%|████▎     | 152/350 [00:08<00:10, 18.31it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  44%|████▎     | 153/350 [00:08<00:10, 18.41it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  44%|████▍     | 154/350 [00:08<00:10, 18.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  44%|████▍     | 155/350 [00:08<00:10, 18.61it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  45%|████▍     | 156/350 [00:08<00:10, 18.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  45%|████▍     | 157/350 [00:08<00:10, 18.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  45%|████▌     | 158/350 [00:08<00:10, 18.92it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  45%|████▌     | 159/350 [00:08<00:10, 19.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  46%|████▌     | 160/350 [00:08<00:09, 19.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  46%|████▌     | 161/350 [00:08<00:09, 19.22it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  46%|████▋     | 162/350 [00:08<00:09, 19.32it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  47%|████▋     | 163/350 [00:08<00:09, 19.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:   7%|▋         | 13/199 [00:00<00:01, 121.55it/s]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 164/350 [00:08<00:09, 19.53it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  47%|████▋     | 165/350 [00:08<00:09, 19.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 3:  47%|████▋     | 166/350 [00:08<00:09, 19.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:   8%|▊         | 16/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  48%|████▊     | 167/350 [00:08<00:09, 19.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:   9%|▊         | 17/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  48%|████▊     | 168/350 [00:08<00:09, 19.92it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:   9%|▉         | 18/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  48%|████▊     | 169/350 [00:08<00:09, 20.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  48%|████▊     | 169/350 [00:08<00:09, 20.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  10%|▉         | 19/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  49%|████▊     | 170/350 [00:08<00:08, 20.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  10%|█         | 20/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  49%|████▉     | 171/350 [00:08<00:08, 20.22it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  11%|█         | 21/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  49%|████▉     | 172/350 [00:08<00:08, 20.32it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  11%|█         | 22/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  49%|████▉     | 173/350 [00:08<00:08, 20.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  12%|█▏        | 23/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  50%|████▉     | 174/350 [00:08<00:08, 20.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  12%|█▏        | 24/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  50%|█████     | 175/350 [00:08<00:08, 20.61it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  13%|█▎        | 25/199 [00:00<00:01, 121.55it/s]\u001b[A\r",
      "Epoch 3:  50%|█████     | 176/350 [00:08<00:08, 20.71it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  13%|█▎        | 26/199 [00:00<00:01, 121.67it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  13%|█▎        | 26/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  51%|█████     | 177/350 [00:08<00:08, 20.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  14%|█▎        | 27/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  51%|█████     | 178/350 [00:08<00:08, 20.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  14%|█▍        | 28/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  51%|█████     | 179/350 [00:08<00:08, 20.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  15%|█▍        | 29/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  51%|█████▏    | 180/350 [00:08<00:08, 21.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  15%|█▌        | 30/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  52%|█████▏    | 181/350 [00:08<00:07, 21.18it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  16%|█▌        | 31/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  52%|█████▏    | 182/350 [00:08<00:07, 21.28it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  52%|█████▏    | 182/350 [00:08<00:07, 21.28it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  16%|█▌        | 32/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  52%|█████▏    | 183/350 [00:08<00:07, 21.37it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  17%|█▋        | 33/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  53%|█████▎    | 184/350 [00:08<00:07, 21.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  17%|█▋        | 34/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  53%|█████▎    | 185/350 [00:08<00:07, 21.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 35/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  53%|█████▎    | 186/350 [00:08<00:07, 21.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 36/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  53%|█████▎    | 187/350 [00:08<00:07, 21.76it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▊        | 37/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  54%|█████▎    | 188/350 [00:08<00:07, 21.85it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▉        | 38/199 [00:00<00:01, 121.67it/s]\u001b[A\r",
      "Epoch 3:  54%|█████▍    | 189/350 [00:08<00:07, 21.95it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|█▉        | 39/199 [00:00<00:01, 119.41it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|█▉        | 39/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  54%|█████▍    | 190/350 [00:08<00:07, 22.05it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|██        | 40/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  55%|█████▍    | 191/350 [00:08<00:07, 22.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  21%|██        | 41/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  55%|█████▍    | 192/350 [00:08<00:07, 22.23it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  21%|██        | 42/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  55%|█████▌    | 193/350 [00:08<00:07, 22.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  22%|██▏       | 43/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  55%|█████▌    | 194/350 [00:08<00:06, 22.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  22%|██▏       | 44/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  56%|█████▌    | 195/350 [00:08<00:06, 22.52it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  56%|█████▌    | 195/350 [00:08<00:06, 22.52it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 45/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  56%|█████▌    | 196/350 [00:08<00:06, 22.61it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 46/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  56%|█████▋    | 197/350 [00:08<00:06, 22.70it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▎       | 47/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  57%|█████▋    | 198/350 [00:08<00:06, 22.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▍       | 48/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  57%|█████▋    | 199/350 [00:08<00:06, 22.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▍       | 49/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  57%|█████▋    | 200/350 [00:08<00:06, 22.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▌       | 50/199 [00:00<00:01, 119.41it/s]\u001b[A\r",
      "Epoch 3:  57%|█████▋    | 201/350 [00:08<00:06, 23.07it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 51/199 [00:00<00:01, 119.15it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 51/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  58%|█████▊    | 202/350 [00:08<00:06, 23.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 52/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  58%|█████▊    | 203/350 [00:08<00:06, 23.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 53/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  58%|█████▊    | 204/350 [00:08<00:06, 23.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 54/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  59%|█████▊    | 205/350 [00:08<00:06, 23.45it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 55/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  59%|█████▉    | 206/350 [00:08<00:06, 23.54it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 56/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  59%|█████▉    | 207/350 [00:08<00:06, 23.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▊       | 57/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  59%|█████▉    | 208/350 [00:08<00:05, 23.71it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  59%|█████▉    | 208/350 [00:08<00:05, 23.71it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▉       | 58/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  60%|█████▉    | 209/350 [00:08<00:05, 23.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|██▉       | 59/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  60%|██████    | 210/350 [00:08<00:05, 23.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|███       | 60/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  60%|██████    | 211/350 [00:08<00:05, 23.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 61/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  61%|██████    | 212/350 [00:08<00:05, 24.08it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 62/199 [00:00<00:01, 119.15it/s]\u001b[A\r",
      "Epoch 3:  61%|██████    | 213/350 [00:08<00:05, 24.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 63/199 [00:00<00:01, 118.31it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 63/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  61%|██████    | 214/350 [00:08<00:05, 24.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 64/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  61%|██████▏   | 215/350 [00:08<00:05, 24.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 65/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  62%|██████▏   | 216/350 [00:08<00:05, 24.44it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 66/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  62%|██████▏   | 217/350 [00:08<00:05, 24.53it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▎      | 67/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  62%|██████▏   | 218/350 [00:08<00:05, 24.62it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▍      | 68/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  63%|██████▎   | 219/350 [00:08<00:05, 24.71it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▍      | 69/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  63%|██████▎   | 220/350 [00:08<00:05, 24.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▌      | 70/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  63%|██████▎   | 221/350 [00:08<00:05, 24.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  63%|██████▎   | 221/350 [00:08<00:05, 24.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 71/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  63%|██████▎   | 222/350 [00:08<00:05, 24.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 72/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  64%|██████▎   | 223/350 [00:08<00:05, 25.07it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 73/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  64%|██████▍   | 224/350 [00:08<00:05, 25.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 74/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  64%|██████▍   | 225/350 [00:08<00:04, 25.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 75/199 [00:00<00:01, 118.31it/s]\u001b[A\r",
      "Epoch 3:  65%|██████▍   | 226/350 [00:08<00:04, 25.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 76/199 [00:00<00:01, 119.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 76/199 [00:00<00:01, 119.50it/s]\u001b[A\r",
      "Epoch 3:  65%|██████▍   | 227/350 [00:08<00:04, 25.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▊      | 77/199 [00:00<00:01, 119.50it/s]\u001b[A\r",
      "Epoch 3:  65%|██████▌   | 228/350 [00:08<00:04, 25.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▉      | 78/199 [00:00<00:01, 119.50it/s]\u001b[A\r",
      "Epoch 3:  65%|██████▌   | 229/350 [00:08<00:04, 25.60it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  40%|███▉      | 79/199 [00:00<00:01, 119.50it/s]\u001b[A\r",
      "Epoch 3:  66%|██████▌   | 230/350 [00:08<00:04, 25.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  40%|████      | 80/199 [00:00<00:00, 119.50it/s]\u001b[A\r",
      "Epoch 3:  66%|██████▌   | 231/350 [00:08<00:04, 25.78it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 81/199 [00:00<00:00, 119.50it/s]\u001b[A\r",
      "Epoch 3:  66%|██████▋   | 232/350 [00:08<00:04, 25.86it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 82/199 [00:00<00:00, 119.50it/s]\u001b[A\r",
      "Epoch 3:  67%|██████▋   | 233/350 [00:08<00:04, 25.95it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 83/199 [00:00<00:00, 119.50it/s]\u001b[A\r",
      "Epoch 3:  67%|██████▋   | 234/350 [00:08<00:04, 26.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  67%|██████▋   | 234/350 [00:08<00:04, 26.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 84/199 [00:00<00:00, 119.50it/s]\u001b[A\r",
      "Epoch 3:  67%|██████▋   | 235/350 [00:08<00:04, 26.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 85/199 [00:00<00:00, 119.50it/s]\u001b[A\r",
      "Epoch 3:  67%|██████▋   | 236/350 [00:09<00:04, 26.21it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 86/199 [00:00<00:00, 119.50it/s]\u001b[A\r",
      "Epoch 3:  68%|██████▊   | 237/350 [00:09<00:04, 26.29it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▎     | 87/199 [00:00<00:00, 119.50it/s]\u001b[A\r",
      "Epoch 3:  68%|██████▊   | 238/350 [00:09<00:04, 26.37it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 88/199 [00:00<00:00, 117.96it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 88/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  68%|██████▊   | 239/350 [00:09<00:04, 26.46it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▍     | 89/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  69%|██████▊   | 240/350 [00:09<00:04, 26.55it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▌     | 90/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  69%|██████▉   | 241/350 [00:09<00:04, 26.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 91/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  69%|██████▉   | 242/350 [00:09<00:04, 26.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 92/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  69%|██████▉   | 243/350 [00:09<00:03, 26.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 93/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  70%|██████▉   | 244/350 [00:09<00:03, 26.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 94/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  70%|███████   | 245/350 [00:09<00:03, 26.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 95/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  70%|███████   | 246/350 [00:09<00:03, 27.06it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 96/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  71%|███████   | 247/350 [00:09<00:03, 27.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  71%|███████   | 247/350 [00:09<00:03, 27.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▊     | 97/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  71%|███████   | 248/350 [00:09<00:03, 27.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▉     | 98/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  71%|███████   | 249/350 [00:09<00:03, 27.32it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|████▉     | 99/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  71%|███████▏  | 250/350 [00:09<00:03, 27.41it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|█████     | 100/199 [00:00<00:00, 117.96it/s]\u001b[A\r",
      "Epoch 3:  72%|███████▏  | 251/350 [00:09<00:03, 27.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████     | 101/199 [00:00<00:00, 119.17it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████     | 101/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  72%|███████▏  | 252/350 [00:09<00:03, 27.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████▏    | 102/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  72%|███████▏  | 253/350 [00:09<00:03, 27.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  52%|█████▏    | 103/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  73%|███████▎  | 254/350 [00:09<00:03, 27.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  52%|█████▏    | 104/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  73%|███████▎  | 255/350 [00:09<00:03, 27.83it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  53%|█████▎    | 105/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  73%|███████▎  | 256/350 [00:09<00:03, 27.91it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  53%|█████▎    | 106/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  73%|███████▎  | 257/350 [00:09<00:03, 28.00it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  54%|█████▍    | 107/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  74%|███████▎  | 258/350 [00:09<00:03, 28.08it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  54%|█████▍    | 108/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  74%|███████▍  | 259/350 [00:09<00:03, 28.16it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  55%|█████▍    | 109/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  74%|███████▍  | 260/350 [00:09<00:03, 28.25it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  74%|███████▍  | 260/350 [00:09<00:03, 28.25it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  55%|█████▌    | 110/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  75%|███████▍  | 261/350 [00:09<00:03, 28.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  56%|█████▌    | 111/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  75%|███████▍  | 262/350 [00:09<00:03, 28.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  56%|█████▋    | 112/199 [00:00<00:00, 119.17it/s]\u001b[A\r",
      "Epoch 3:  75%|███████▌  | 263/350 [00:09<00:03, 28.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 113/199 [00:00<00:00, 119.03it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 113/199 [00:00<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  75%|███████▌  | 264/350 [00:09<00:03, 28.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 114/199 [00:00<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  76%|███████▌  | 265/350 [00:09<00:02, 28.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 115/199 [00:00<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  76%|███████▌  | 266/350 [00:09<00:02, 28.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 116/199 [00:00<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  76%|███████▋  | 267/350 [00:09<00:02, 28.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  59%|█████▉    | 117/199 [00:00<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  77%|███████▋  | 268/350 [00:09<00:02, 28.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  59%|█████▉    | 118/199 [00:00<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  77%|███████▋  | 269/350 [00:09<00:02, 28.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  60%|█████▉    | 119/199 [00:01<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  77%|███████▋  | 270/350 [00:09<00:02, 29.05it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  60%|██████    | 120/199 [00:01<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  77%|███████▋  | 271/350 [00:09<00:02, 29.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  61%|██████    | 121/199 [00:01<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  78%|███████▊  | 272/350 [00:09<00:02, 29.22it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  61%|██████▏   | 122/199 [00:01<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  78%|███████▊  | 273/350 [00:09<00:02, 29.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  78%|███████▊  | 273/350 [00:09<00:02, 29.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  62%|██████▏   | 123/199 [00:01<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  78%|███████▊  | 274/350 [00:09<00:02, 29.38it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  62%|██████▏   | 124/199 [00:01<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  79%|███████▊  | 275/350 [00:09<00:02, 29.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 125/199 [00:01<00:00, 119.03it/s]\u001b[A\r",
      "Epoch 3:  79%|███████▉  | 276/350 [00:09<00:02, 29.55it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 126/199 [00:01<00:00, 119.61it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 126/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  79%|███████▉  | 277/350 [00:09<00:02, 29.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  64%|██████▍   | 127/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  79%|███████▉  | 278/350 [00:09<00:02, 29.71it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  64%|██████▍   | 128/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  80%|███████▉  | 279/350 [00:09<00:02, 29.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  65%|██████▍   | 129/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  80%|████████  | 280/350 [00:09<00:02, 29.87it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  65%|██████▌   | 130/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  80%|████████  | 281/350 [00:09<00:02, 29.95it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  66%|██████▌   | 131/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  81%|████████  | 282/350 [00:09<00:02, 30.03it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  66%|██████▋   | 132/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  81%|████████  | 283/350 [00:09<00:02, 30.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  67%|██████▋   | 133/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  81%|████████  | 284/350 [00:09<00:02, 30.19it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  67%|██████▋   | 134/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  81%|████████▏ | 285/350 [00:09<00:02, 30.27it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  68%|██████▊   | 135/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  82%|████████▏ | 286/350 [00:09<00:02, 30.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  82%|████████▏ | 286/350 [00:09<00:02, 30.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  68%|██████▊   | 136/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  82%|████████▏ | 287/350 [00:09<00:02, 30.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 137/199 [00:01<00:00, 119.61it/s]\u001b[A\r",
      "Epoch 3:  82%|████████▏ | 288/350 [00:09<00:02, 30.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 138/199 [00:01<00:00, 119.59it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 138/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  83%|████████▎ | 289/350 [00:09<00:01, 30.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  70%|██████▉   | 139/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  83%|████████▎ | 290/350 [00:09<00:01, 30.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  70%|███████   | 140/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  83%|████████▎ | 291/350 [00:09<00:01, 30.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  71%|███████   | 141/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  83%|████████▎ | 292/350 [00:09<00:01, 30.80it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  71%|███████▏  | 142/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  84%|████████▎ | 293/350 [00:09<00:01, 30.88it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  72%|███████▏  | 143/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  84%|████████▍ | 294/350 [00:09<00:01, 30.95it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  72%|███████▏  | 144/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  84%|████████▍ | 295/350 [00:09<00:01, 31.03it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  73%|███████▎  | 145/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  85%|████████▍ | 296/350 [00:09<00:01, 31.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  73%|███████▎  | 146/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  85%|████████▍ | 297/350 [00:09<00:01, 31.18it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  74%|███████▍  | 147/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  85%|████████▌ | 298/350 [00:09<00:01, 31.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  74%|███████▍  | 148/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  85%|████████▌ | 299/350 [00:09<00:01, 31.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 3:  85%|████████▌ | 299/350 [00:09<00:01, 31.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▍  | 149/199 [00:01<00:00, 119.59it/s]\u001b[A\r",
      "Epoch 3:  86%|████████▌ | 300/350 [00:09<00:01, 31.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▌  | 150/199 [00:01<00:00, 116.84it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▌  | 150/199 [00:01<00:00, 116.84it/s]\u001b[A\r",
      "Epoch 3:  86%|████████▌ | 301/350 [00:09<00:01, 31.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  76%|███████▌  | 151/199 [00:01<00:00, 116.84it/s]\u001b[A\r",
      "Epoch 3:  86%|████████▋ | 302/350 [00:09<00:01, 31.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  76%|███████▋  | 152/199 [00:01<00:00, 116.84it/s]\u001b[A\r",
      "Epoch 3:  87%|████████▋ | 303/350 [00:09<00:01, 31.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  77%|███████▋  | 153/199 [00:01<00:00, 116.84it/s]\u001b[A\r",
      "Epoch 3:  87%|████████▋ | 304/350 [00:09<00:01, 31.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  77%|███████▋  | 154/199 [00:01<00:00, 116.84it/s]\u001b[A\r",
      "Epoch 3:  87%|████████▋ | 305/350 [00:09<00:01, 31.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  78%|███████▊  | 155/199 [00:01<00:00, 116.84it/s]\u001b[A\r",
      "Epoch 3:  87%|████████▋ | 306/350 [00:09<00:01, 31.88it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  78%|███████▊  | 156/199 [00:01<00:00, 116.84it/s]\u001b[A\r",
      "Epoch 3:  88%|████████▊ | 307/350 [00:09<00:01, 31.96it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 3:  88%|████████▊ | 308/350 [00:09<00:01, 32.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  88%|████████▊ | 309/350 [00:09<00:01, 32.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  89%|████████▊ | 310/350 [00:09<00:01, 32.18it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  89%|████████▉ | 311/350 [00:09<00:01, 32.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  89%|████████▉ | 312/350 [00:09<00:01, 32.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:  81%|████████▏ | 162/199 [00:01<00:00, 113.15it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 313/350 [00:09<00:01, 32.36it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  90%|████████▉ | 314/350 [00:09<00:01, 32.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  90%|█████████ | 315/350 [00:09<00:01, 32.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  90%|█████████ | 316/350 [00:09<00:01, 32.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  91%|█████████ | 317/350 [00:09<00:01, 32.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 3:  91%|█████████ | 318/350 [00:09<00:00, 32.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  91%|█████████ | 319/350 [00:09<00:00, 32.77it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  91%|█████████▏| 320/350 [00:09<00:00, 32.85it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  92%|█████████▏| 321/350 [00:09<00:00, 32.92it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  92%|█████████▏| 322/350 [00:09<00:00, 33.00it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  92%|█████████▏| 323/350 [00:09<00:00, 33.07it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  93%|█████████▎| 324/350 [00:09<00:00, 33.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:  87%|████████▋ | 174/199 [00:01<00:00, 111.84it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 325/350 [00:09<00:00, 33.23it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  93%|█████████▎| 326/350 [00:09<00:00, 33.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  93%|█████████▎| 327/350 [00:09<00:00, 33.38it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  94%|█████████▎| 328/350 [00:09<00:00, 33.45it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  94%|█████████▍| 329/350 [00:09<00:00, 33.53it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  94%|█████████▍| 330/350 [00:09<00:00, 33.60it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  95%|█████████▍| 331/350 [00:09<00:00, 33.67it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 3:  95%|█████████▍| 332/350 [00:09<00:00, 33.75it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 3:  95%|█████████▌| 333/350 [00:09<00:00, 33.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  95%|█████████▌| 334/350 [00:09<00:00, 33.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  96%|█████████▌| 335/350 [00:09<00:00, 33.96it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  96%|█████████▌| 336/350 [00:09<00:00, 34.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  96%|█████████▋| 337/350 [00:09<00:00, 34.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:  94%|█████████▍| 187/199 [00:01<00:00, 115.15it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 338/350 [00:09<00:00, 34.18it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  97%|█████████▋| 339/350 [00:09<00:00, 34.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  97%|█████████▋| 340/350 [00:09<00:00, 34.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  97%|█████████▋| 341/350 [00:09<00:00, 34.41it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  98%|█████████▊| 342/350 [00:09<00:00, 34.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  98%|█████████▊| 343/350 [00:09<00:00, 34.56it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  98%|█████████▊| 344/350 [00:09<00:00, 34.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  99%|█████████▊| 345/350 [00:09<00:00, 34.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  99%|█████████▉| 346/350 [00:09<00:00, 34.77it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3:  99%|█████████▉| 347/350 [00:09<00:00, 34.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Result for train_mnist_tune_56334_00000:\n",
      "  date: 2022-07-13_10-41-34\n",
      "  done: false\n",
      "  experiment_id: 982c1c173bd44ceabdf99b78b60d4d2d\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.6934381723403931\n",
      "  mean_pred: 1.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 1268\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 108.7534761428833\n",
      "  time_this_iter_s: 10.017011642456055\n",
      "  time_total_s: 108.7534761428833\n",
      "  timestamp: 1657701694\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: '56334_00000'\n",
      "  val_bal_acc: 0.5\n",
      "  val_loss: 0.6931052803993225\n",
      "  warmup_time: 0.004000186920166016\n",
      "  \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 3:  99%|█████████▉| 348/350 [00:09<00:00, 34.91it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3: 100%|█████████▉| 349/350 [00:09<00:00, 34.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 3: 100%|██████████| 350/350 [00:10<00:00, 34.96it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:   0%|          | 0/350 [00:00<?, ?it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:   2%|▏         | 6/350 [00:03<03:20,  1.71it/s, loss=0.694, v_num=., loss/loss=0.694, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:   4%|▍         | 15/350 [00:03<01:20,  4.16it/s, loss=0.693, v_num=., loss/loss=0.689, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:   7%|▋         | 24/350 [00:03<00:50,  6.46it/s, loss=0.694, v_num=., loss/loss=0.695, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:   9%|▉         | 33/350 [00:03<00:36,  8.61it/s, loss=0.693, v_num=., loss/loss=0.691, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  10%|▉         | 34/350 [00:03<00:35,  8.83it/s, loss=0.692, v_num=., loss/loss=0.679, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  12%|█▏        | 42/350 [00:03<00:29, 10.62it/s, loss=0.69, v_num=., loss/loss=0.671, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520] \n",
      "Epoch 4:  12%|█▏        | 43/350 [00:03<00:28, 10.84it/s, loss=0.691, v_num=., loss/loss=0.716, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  15%|█▌        | 53/350 [00:04<00:22, 12.98it/s, loss=0.686, v_num=., loss/loss=0.699, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  18%|█▊        | 62/350 [00:04<00:19, 14.82it/s, loss=0.691, v_num=., loss/loss=0.723, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  20%|██        | 71/350 [00:04<00:16, 16.54it/s, loss=0.695, v_num=., loss/loss=0.712, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  21%|██        | 72/350 [00:04<00:16, 16.72it/s, loss=0.695, v_num=., loss/loss=0.690, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  23%|██▎       | 82/350 [00:04<00:14, 18.57it/s, loss=0.694, v_num=., loss/loss=0.695, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  27%|██▋       | 93/350 [00:04<00:12, 20.48it/s, loss=0.691, v_num=., loss/loss=0.686, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  27%|██▋       | 94/350 [00:04<00:12, 20.65it/s, loss=0.691, v_num=., loss/loss=0.701, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  30%|██▉       | 104/350 [00:04<00:11, 22.26it/s, loss=0.7, v_num=., loss/loss=0.692, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]  \n",
      "Epoch 4:  33%|███▎      | 114/350 [00:04<00:09, 23.83it/s, loss=0.704, v_num=., loss/loss=0.699, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  33%|███▎      | 115/350 [00:04<00:09, 23.99it/s, loss=0.704, v_num=., loss/loss=0.695, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  36%|███▌      | 125/350 [00:04<00:08, 25.44it/s, loss=0.685, v_num=., loss/loss=0.653, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:39 (running for 00:01:58.45)\n",
      "Memory usage on this node: 11.1/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    4 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Epoch 4:  39%|███▊      | 135/350 [00:05<00:08, 26.85it/s, loss=0.691, v_num=., loss/loss=0.741, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  39%|███▉      | 136/350 [00:05<00:07, 26.98it/s, loss=0.695, v_num=., loss/loss=0.768, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  42%|████▏     | 146/350 [00:05<00:07, 28.30it/s, loss=0.708, v_num=., loss/loss=0.691, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  43%|████▎     | 151/350 [00:05<00:06, 28.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A68)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Validation:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 152/350 [00:08<00:10, 18.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 4:  44%|████▎     | 153/350 [00:08<00:10, 18.38it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  44%|████▍     | 154/350 [00:08<00:10, 18.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  44%|████▍     | 155/350 [00:08<00:10, 18.58it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  45%|████▍     | 156/350 [00:08<00:10, 18.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  45%|████▍     | 157/350 [00:08<00:10, 18.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  45%|████▌     | 158/350 [00:08<00:10, 18.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  45%|████▌     | 159/350 [00:08<00:10, 18.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  46%|████▌     | 160/350 [00:08<00:09, 19.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  46%|████▌     | 161/350 [00:08<00:09, 19.19it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:   6%|▌         | 11/199 [00:00<00:01, 106.43it/s]\u001b[A\n",
      "Epoch 4:  46%|████▋     | 162/350 [00:08<00:09, 19.29it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  47%|████▋     | 163/350 [00:08<00:09, 19.39it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  47%|████▋     | 164/350 [00:08<00:09, 19.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  47%|████▋     | 165/350 [00:08<00:09, 19.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 4:  47%|████▋     | 166/350 [00:08<00:09, 19.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:   8%|▊         | 16/199 [00:00<00:01, 106.43it/s]\u001b[A\r",
      "Epoch 4:  48%|████▊     | 167/350 [00:08<00:09, 19.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:   9%|▊         | 17/199 [00:00<00:01, 106.43it/s]\u001b[A\r",
      "Epoch 4:  48%|████▊     | 168/350 [00:08<00:09, 19.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:   9%|▉         | 18/199 [00:00<00:01, 106.43it/s]\u001b[A\r",
      "Epoch 4:  48%|████▊     | 169/350 [00:08<00:09, 19.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  48%|████▊     | 169/350 [00:08<00:09, 19.99it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  10%|▉         | 19/199 [00:00<00:01, 106.43it/s]\u001b[A\r",
      "Epoch 4:  49%|████▊     | 170/350 [00:08<00:08, 20.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  10%|█         | 20/199 [00:00<00:01, 106.43it/s]\u001b[A\r",
      "Epoch 4:  49%|████▉     | 171/350 [00:08<00:08, 20.18it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  11%|█         | 21/199 [00:00<00:01, 106.43it/s]\u001b[A\r",
      "Epoch 4:  49%|████▉     | 172/350 [00:08<00:08, 20.28it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  11%|█         | 22/199 [00:00<00:01, 106.43it/s]\u001b[A\r",
      "Epoch 4:  49%|████▉     | 173/350 [00:08<00:08, 20.38it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  12%|█▏        | 23/199 [00:00<00:01, 106.43it/s]\u001b[A\r",
      "Epoch 4:  50%|████▉     | 174/350 [00:08<00:08, 20.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  12%|█▏        | 24/199 [00:00<00:01, 114.74it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  12%|█▏        | 24/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  50%|█████     | 175/350 [00:08<00:08, 20.58it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  13%|█▎        | 25/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  50%|█████     | 176/350 [00:08<00:08, 20.68it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  13%|█▎        | 26/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  51%|█████     | 177/350 [00:08<00:08, 20.77it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  14%|█▎        | 27/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  51%|█████     | 178/350 [00:08<00:08, 20.87it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  14%|█▍        | 28/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  51%|█████     | 179/350 [00:08<00:08, 20.96it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  15%|█▍        | 29/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  51%|█████▏    | 180/350 [00:08<00:08, 21.05it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  15%|█▌        | 30/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  52%|█████▏    | 181/350 [00:08<00:07, 21.15it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  16%|█▌        | 31/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  52%|█████▏    | 182/350 [00:08<00:07, 21.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  52%|█████▏    | 182/350 [00:08<00:07, 21.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  16%|█▌        | 32/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  52%|█████▏    | 183/350 [00:08<00:07, 21.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  17%|█▋        | 33/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  53%|█████▎    | 184/350 [00:08<00:07, 21.44it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  17%|█▋        | 34/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  53%|█████▎    | 185/350 [00:08<00:07, 21.53it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 35/199 [00:00<00:01, 114.74it/s]\u001b[A\r",
      "Epoch 4:  53%|█████▎    | 186/350 [00:08<00:07, 21.63it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 36/199 [00:00<00:01, 114.98it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  18%|█▊        | 36/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  53%|█████▎    | 187/350 [00:08<00:07, 21.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▊        | 37/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  54%|█████▎    | 188/350 [00:08<00:07, 21.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  19%|█▉        | 38/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  54%|█████▍    | 189/350 [00:08<00:07, 21.91it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|█▉        | 39/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  54%|█████▍    | 190/350 [00:08<00:07, 22.01it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  20%|██        | 40/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  55%|█████▍    | 191/350 [00:08<00:07, 22.10it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  21%|██        | 41/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  55%|█████▍    | 192/350 [00:08<00:07, 22.20it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  21%|██        | 42/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  55%|█████▌    | 193/350 [00:08<00:07, 22.29it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  22%|██▏       | 43/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  55%|█████▌    | 194/350 [00:08<00:06, 22.39it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  22%|██▏       | 44/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  56%|█████▌    | 195/350 [00:08<00:06, 22.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  56%|█████▌    | 195/350 [00:08<00:06, 22.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 45/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  56%|█████▌    | 196/350 [00:08<00:06, 22.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 46/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  56%|█████▋    | 197/350 [00:08<00:06, 22.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▎       | 47/199 [00:00<00:01, 114.98it/s]\u001b[A\r",
      "Epoch 4:  57%|█████▋    | 198/350 [00:08<00:06, 22.75it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▍       | 48/199 [00:00<00:01, 115.82it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▍       | 48/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  57%|█████▋    | 199/350 [00:08<00:06, 22.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▍       | 49/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  57%|█████▋    | 200/350 [00:08<00:06, 22.94it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▌       | 50/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  57%|█████▋    | 201/350 [00:08<00:06, 23.03it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 51/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  58%|█████▊    | 202/350 [00:08<00:06, 23.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 52/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  58%|█████▊    | 203/350 [00:08<00:06, 23.22it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 53/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  58%|█████▊    | 204/350 [00:08<00:06, 23.31it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 54/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  59%|█████▊    | 205/350 [00:08<00:06, 23.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 55/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  59%|█████▉    | 206/350 [00:08<00:06, 23.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 56/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  59%|█████▉    | 207/350 [00:08<00:06, 23.58it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▊       | 57/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  59%|█████▉    | 208/350 [00:08<00:06, 23.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  59%|█████▉    | 208/350 [00:08<00:06, 23.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▉       | 58/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  60%|█████▉    | 209/350 [00:08<00:05, 23.75it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|██▉       | 59/199 [00:00<00:01, 115.82it/s]\u001b[A\r",
      "Epoch 4:  60%|██████    | 210/350 [00:08<00:05, 23.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|███       | 60/199 [00:00<00:01, 115.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  30%|███       | 60/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  60%|██████    | 211/350 [00:08<00:05, 23.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 61/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  61%|██████    | 212/350 [00:08<00:05, 24.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 62/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  61%|██████    | 213/350 [00:08<00:05, 24.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 63/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  61%|██████    | 214/350 [00:08<00:05, 24.21it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 64/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  61%|██████▏   | 215/350 [00:08<00:05, 24.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 65/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  62%|██████▏   | 216/350 [00:08<00:05, 24.39it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 66/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  62%|██████▏   | 217/350 [00:08<00:05, 24.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▎      | 67/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  62%|██████▏   | 218/350 [00:08<00:05, 24.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▍      | 68/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  63%|██████▎   | 219/350 [00:08<00:05, 24.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▍      | 69/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  63%|██████▎   | 220/350 [00:08<00:05, 24.75it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▌      | 70/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  63%|██████▎   | 221/350 [00:08<00:05, 24.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  63%|██████▎   | 221/350 [00:08<00:05, 24.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 71/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  63%|██████▎   | 222/350 [00:08<00:05, 24.93it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 72/199 [00:00<00:01, 115.11it/s]\u001b[A\r",
      "Epoch 4:  64%|██████▎   | 223/350 [00:08<00:05, 25.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 73/199 [00:00<00:01, 118.22it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 73/199 [00:00<00:01, 118.22it/s]\u001b[A\r",
      "Epoch 4:  64%|██████▍   | 224/350 [00:08<00:05, 25.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 74/199 [00:00<00:01, 118.22it/s]\u001b[A\r",
      "Epoch 4:  64%|██████▍   | 225/350 [00:08<00:04, 25.20it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 75/199 [00:00<00:01, 118.22it/s]\u001b[A\r",
      "Epoch 4:  65%|██████▍   | 226/350 [00:08<00:04, 25.28it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 76/199 [00:00<00:01, 118.22it/s]\u001b[A\r",
      "Epoch 4:  65%|██████▍   | 227/350 [00:08<00:04, 25.37it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▊      | 77/199 [00:00<00:01, 118.22it/s]\u001b[A\r",
      "Epoch 4:  65%|██████▌   | 228/350 [00:08<00:04, 25.46it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▉      | 78/199 [00:00<00:01, 118.22it/s]\u001b[A\r",
      "Epoch 4:  65%|██████▌   | 229/350 [00:08<00:04, 25.55it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  40%|███▉      | 79/199 [00:00<00:01, 118.22it/s]\u001b[A\r",
      "Epoch 4:  66%|██████▌   | 230/350 [00:08<00:04, 25.64it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  40%|████      | 80/199 [00:00<00:01, 118.22it/s]\u001b[A\r",
      "Epoch 4:  66%|██████▌   | 231/350 [00:08<00:04, 25.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 81/199 [00:00<00:00, 118.22it/s]\u001b[A\r",
      "Epoch 4:  66%|██████▋   | 232/350 [00:08<00:04, 25.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 82/199 [00:00<00:00, 118.22it/s]\u001b[A\r",
      "Epoch 4:  67%|██████▋   | 233/350 [00:08<00:04, 25.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 83/199 [00:00<00:00, 118.22it/s]\u001b[A\r",
      "Epoch 4:  67%|██████▋   | 234/350 [00:09<00:04, 25.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  67%|██████▋   | 234/350 [00:09<00:04, 25.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 84/199 [00:00<00:00, 118.22it/s]\u001b[A\r",
      "Epoch 4:  67%|██████▋   | 235/350 [00:09<00:04, 26.06it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 85/199 [00:00<00:00, 116.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 85/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  67%|██████▋   | 236/350 [00:09<00:04, 26.14it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 86/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  68%|██████▊   | 237/350 [00:09<00:04, 26.22it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▎     | 87/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  68%|██████▊   | 238/350 [00:09<00:04, 26.31it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 88/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  68%|██████▊   | 239/350 [00:09<00:04, 26.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▍     | 89/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  69%|██████▊   | 240/350 [00:09<00:04, 26.48it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▌     | 90/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  69%|██████▉   | 241/350 [00:09<00:04, 26.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 91/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  69%|██████▉   | 242/350 [00:09<00:04, 26.66it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 92/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  69%|██████▉   | 243/350 [00:09<00:04, 26.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 93/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  70%|██████▉   | 244/350 [00:09<00:03, 26.83it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 94/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  70%|███████   | 245/350 [00:09<00:03, 26.92it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 95/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  70%|███████   | 246/350 [00:09<00:03, 27.00it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 96/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  71%|███████   | 247/350 [00:09<00:03, 27.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  71%|███████   | 247/350 [00:09<00:03, 27.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▊     | 97/199 [00:00<00:00, 116.10it/s]\u001b[A\r",
      "Epoch 4:  71%|███████   | 248/350 [00:09<00:03, 27.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▉     | 98/199 [00:00<00:00, 117.99it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▉     | 98/199 [00:00<00:00, 117.99it/s]\u001b[A\r",
      "Epoch 4:  71%|███████   | 249/350 [00:09<00:03, 27.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|████▉     | 99/199 [00:00<00:00, 117.99it/s]\u001b[A\r",
      "Epoch 4:  71%|███████▏  | 250/350 [00:09<00:03, 27.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  50%|█████     | 100/199 [00:00<00:00, 117.99it/s]\u001b[A\r",
      "Epoch 4:  72%|███████▏  | 251/350 [00:09<00:03, 27.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████     | 101/199 [00:00<00:00, 117.99it/s]\u001b[A\r",
      "Epoch 4:  72%|███████▏  | 252/350 [00:09<00:03, 27.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 4:  72%|███████▏  | 253/350 [00:09<00:03, 27.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  73%|███████▎  | 254/350 [00:09<00:03, 27.67it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  73%|███████▎  | 255/350 [00:09<00:03, 27.76it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  73%|███████▎  | 256/350 [00:09<00:03, 27.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  73%|███████▎  | 257/350 [00:09<00:03, 27.92it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  74%|███████▎  | 258/350 [00:09<00:03, 28.00it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  74%|███████▍  | 259/350 [00:09<00:03, 28.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  74%|███████▍  | 260/350 [00:09<00:03, 28.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:  55%|█████▌    | 110/199 [00:00<00:00, 117.64it/s]\u001b[A\n",
      "Epoch 4:  75%|███████▍  | 261/350 [00:09<00:03, 28.25it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  75%|███████▍  | 262/350 [00:09<00:03, 28.34it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  75%|███████▌  | 263/350 [00:09<00:03, 28.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  75%|███████▌  | 264/350 [00:09<00:03, 28.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 4:  76%|███████▌  | 265/350 [00:09<00:02, 28.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  76%|███████▌  | 266/350 [00:09<00:02, 28.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  76%|███████▋  | 267/350 [00:09<00:02, 28.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  77%|███████▋  | 268/350 [00:09<00:02, 28.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  77%|███████▋  | 269/350 [00:09<00:02, 28.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  77%|███████▋  | 270/350 [00:09<00:02, 28.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  77%|███████▋  | 271/350 [00:09<00:02, 29.05it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  78%|███████▊  | 272/350 [00:09<00:02, 29.13it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:  61%|██████▏   | 122/199 [00:01<00:00, 115.82it/s]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 273/350 [00:09<00:02, 29.21it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  78%|███████▊  | 274/350 [00:09<00:02, 29.30it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  79%|███████▊  | 275/350 [00:09<00:02, 29.38it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  79%|███████▉  | 276/350 [00:09<00:02, 29.46it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  79%|███████▉  | 277/350 [00:09<00:02, 29.54it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 4:  79%|███████▉  | 278/350 [00:09<00:02, 29.62it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  80%|███████▉  | 279/350 [00:09<00:02, 29.70it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  80%|████████  | 280/350 [00:09<00:02, 29.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  80%|████████  | 281/350 [00:09<00:02, 29.87it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  81%|████████  | 282/350 [00:09<00:02, 29.95it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  81%|████████  | 283/350 [00:09<00:02, 30.03it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  81%|████████  | 284/350 [00:09<00:02, 30.11it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  81%|████████▏ | 285/350 [00:09<00:02, 30.19it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:  68%|██████▊   | 135/199 [00:01<00:00, 118.82it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 286/350 [00:09<00:02, 30.27it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  82%|████████▏ | 287/350 [00:09<00:02, 30.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  82%|████████▏ | 288/350 [00:09<00:02, 30.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  83%|████████▎ | 289/350 [00:09<00:01, 30.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  83%|████████▎ | 290/350 [00:09<00:01, 30.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  83%|████████▎ | 291/350 [00:09<00:01, 30.67it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 4:  83%|████████▎ | 292/350 [00:09<00:01, 30.73it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 4:  84%|████████▎ | 293/350 [00:09<00:01, 30.81it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  84%|████████▍ | 294/350 [00:09<00:01, 30.89it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  84%|████████▍ | 295/350 [00:09<00:01, 30.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  85%|████████▍ | 296/350 [00:09<00:01, 31.04it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  85%|████████▍ | 297/350 [00:09<00:01, 31.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Validation DataLoader 0:  74%|███████▍  | 147/199 [00:01<00:00, 118.05it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 298/350 [00:09<00:01, 31.20it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  85%|████████▌ | 299/350 [00:09<00:01, 31.28it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  86%|████████▌ | 300/350 [00:09<00:01, 31.36it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  86%|████████▌ | 301/350 [00:09<00:01, 31.43it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  86%|████████▋ | 302/350 [00:09<00:01, 31.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  87%|████████▋ | 303/350 [00:09<00:01, 31.59it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  87%|████████▋ | 304/350 [00:09<00:01, 31.67it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  87%|████████▋ | 305/350 [00:09<00:01, 31.74it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Epoch 4:  87%|████████▋ | 306/350 [00:09<00:01, 31.82it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "Epoch 4:  88%|████████▊ | 307/350 [00:09<00:01, 31.90it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  79%|███████▉  | 157/199 [00:01<00:00, 118.05it/s]\u001b[A\r",
      "Epoch 4:  88%|████████▊ | 308/350 [00:09<00:01, 31.97it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  79%|███████▉  | 158/199 [00:01<00:00, 118.05it/s]\u001b[A\r",
      "Epoch 4:  88%|████████▊ | 309/350 [00:09<00:01, 32.05it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  80%|███████▉  | 159/199 [00:01<00:00, 118.58it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  80%|███████▉  | 159/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  89%|████████▊ | 310/350 [00:09<00:01, 32.12it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  80%|████████  | 160/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  89%|████████▉ | 311/350 [00:09<00:01, 32.19it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████  | 161/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  89%|████████▉ | 312/350 [00:09<00:01, 32.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  89%|████████▉ | 312/350 [00:09<00:01, 32.26it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████▏ | 162/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  89%|████████▉ | 313/350 [00:09<00:01, 32.33it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  82%|████████▏ | 163/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  90%|████████▉ | 314/350 [00:09<00:01, 32.40it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  82%|████████▏ | 164/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  90%|█████████ | 315/350 [00:09<00:01, 32.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  83%|████████▎ | 165/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  90%|█████████ | 316/350 [00:09<00:01, 32.51it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  83%|████████▎ | 166/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  91%|█████████ | 317/350 [00:09<00:01, 32.58it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  84%|████████▍ | 167/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  91%|█████████ | 318/350 [00:09<00:00, 32.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  84%|████████▍ | 168/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  91%|█████████ | 319/350 [00:09<00:00, 32.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  85%|████████▍ | 169/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  91%|█████████▏| 320/350 [00:09<00:00, 32.79it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  85%|████████▌ | 170/199 [00:01<00:00, 118.58it/s]\u001b[A\r",
      "Epoch 4:  92%|█████████▏| 321/350 [00:09<00:00, 32.87it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  86%|████████▌ | 171/199 [00:01<00:00, 111.30it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  86%|████████▌ | 171/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  92%|█████████▏| 322/350 [00:09<00:00, 32.94it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  86%|████████▋ | 172/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  92%|█████████▏| 323/350 [00:09<00:00, 33.02it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 173/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  93%|█████████▎| 324/350 [00:09<00:00, 33.09it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 174/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  93%|█████████▎| 325/350 [00:09<00:00, 33.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  93%|█████████▎| 325/350 [00:09<00:00, 33.17it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  88%|████████▊ | 175/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  93%|█████████▎| 326/350 [00:09<00:00, 33.24it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  88%|████████▊ | 176/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  93%|█████████▎| 327/350 [00:09<00:00, 33.32it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  89%|████████▉ | 177/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  94%|█████████▎| 328/350 [00:09<00:00, 33.39it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  89%|████████▉ | 178/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  94%|█████████▍| 329/350 [00:09<00:00, 33.47it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  90%|████████▉ | 179/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  94%|█████████▍| 330/350 [00:09<00:00, 33.54it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  90%|█████████ | 180/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  95%|█████████▍| 331/350 [00:09<00:00, 33.62it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  91%|█████████ | 181/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  95%|█████████▍| 332/350 [00:09<00:00, 33.69it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  91%|█████████▏| 182/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  95%|█████████▌| 333/350 [00:09<00:00, 33.77it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  92%|█████████▏| 183/199 [00:01<00:00, 111.30it/s]\u001b[A\r",
      "Epoch 4:  95%|█████████▌| 334/350 [00:09<00:00, 33.84it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  92%|█████████▏| 184/199 [00:01<00:00, 115.14it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  92%|█████████▏| 184/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  96%|█████████▌| 335/350 [00:09<00:00, 33.91it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 185/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  96%|█████████▌| 336/350 [00:09<00:00, 33.98it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 186/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  96%|█████████▋| 337/350 [00:09<00:00, 34.05it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  94%|█████████▍| 187/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  97%|█████████▋| 338/350 [00:09<00:00, 34.13it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\r",
      "Epoch 4:  97%|█████████▋| 338/350 [00:09<00:00, 34.13it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  94%|█████████▍| 188/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  97%|█████████▋| 339/350 [00:09<00:00, 34.20it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  95%|█████████▍| 189/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  97%|█████████▋| 340/350 [00:09<00:00, 34.28it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  95%|█████████▌| 190/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  97%|█████████▋| 341/350 [00:09<00:00, 34.35it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  96%|█████████▌| 191/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  98%|█████████▊| 342/350 [00:09<00:00, 34.42it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  96%|█████████▋| 192/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  98%|█████████▊| 343/350 [00:09<00:00, 34.49it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  97%|█████████▋| 193/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  98%|█████████▊| 344/350 [00:09<00:00, 34.57it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  97%|█████████▋| 194/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  99%|█████████▊| 345/350 [00:09<00:00, 34.65it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  98%|█████████▊| 195/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  99%|█████████▉| 346/350 [00:09<00:00, 34.72it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  98%|█████████▊| 196/199 [00:01<00:00, 115.14it/s]\u001b[A\r",
      "Epoch 4:  99%|█████████▉| 347/350 [00:09<00:00, 34.78it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  99%|█████████▉| 197/199 [00:01<00:00, 117.82it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  99%|█████████▉| 197/199 [00:01<00:00, 117.82it/s]\u001b[A\r",
      "Epoch 4:  99%|█████████▉| 348/350 [00:09<00:00, 34.86it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0:  99%|█████████▉| 198/199 [00:01<00:00, 117.82it/s]\u001b[A\r",
      "Epoch 4: 100%|█████████▉| 349/350 [00:09<00:00, 34.92it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "Result for train_mnist_tune_56334_00000:\n",
      "  date: 2022-07-13_10-41-44\n",
      "  done: true\n",
      "  experiment_id: 982c1c173bd44ceabdf99b78b60d4d2d\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.6934382319450378\n",
      "  mean_pred: 1.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 1268\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 118.78744840621948\n",
      "  time_this_iter_s: 10.033972263336182\n",
      "  time_total_s: 118.78744840621948\n",
      "  timestamp: 1657701704\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: '56334_00000'\n",
      "  val_bal_acc: 0.5\n",
      "  val_loss: 0.6931052803993225\n",
      "  warmup_time: 0.004000186920166016\n",
      "  \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=1268)\u001b[0m \r",
      "Validation DataLoader 0: 100%|██████████| 199/199 [00:01<00:00, 117.82it/s]\u001b[A\r",
      "Epoch 4: 100%|██████████| 350/350 [00:10<00:00, 35.00it/s, loss=0.707, v_num=., loss/loss=0.693, mean_pred=1.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.520]\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:44 (running for 00:02:03.55)\n",
      "Memory usage on this node: 11.1/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status   | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00000 | RUNNING  | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "| train_mnist_tune_56334_00001 | PENDING  |                |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "+------------------------------+----------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-13 10:41:44,797\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\python.exe\" C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=55716 --object-store-name=tcp://127.0.0.1:56101 --raylet-name=tcp://127.0.0.1:60199 --redis-address=None --storage=None --temp-dir=C:\\Users\\Mathiass\\AppData\\Local\\Temp\\ray --metrics-agent-port=59706 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:57982 --redis-password=5241590000000000 --startup-token=8 --runtime-env-hash=137120697\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m ------\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 37.454011884736246\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m ------\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:49 (running for 00:02:08.80)\n",
      "Memory usage on this node: 9.0/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:54 (running for 00:02:13.84)\n",
      "Memory usage on this node: 8.6/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:41:59 (running for 00:02:18.87)\n",
      "Memory usage on this node: 8.6/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:04 (running for 00:02:23.90)\n",
      "Memory usage on this node: 8.5/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:09 (running for 00:02:28.94)\n",
      "Memory usage on this node: 8.5/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:14 (running for 00:02:33.97)\n",
      "Memory usage on this node: 8.5/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:19 (running for 00:02:39.01)\n",
      "Memory usage on this node: 8.5/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m class_weights: tensor([1.5913, 2.6912])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m device of class_weights: cpu\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m ---\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m # of input data: 3823386 with shape: (3823386, 17)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m # of training samples: 38419 with X_train of shape: torch.Size([38419, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m # of validation samples: 50879 with X_val of shape: torch.Size([50879, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m # of test samples: 3734088 with X_test of shape: torch.Size([3734088, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m train start date:  1996-01-31 , train end date:  1996-12-31\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m val start date:  1997-01-31 , val end date:  1997-12-31\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m test start date:  1998-01-31 , test end date:  2021-11-30\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m C:\\Users\\Mathiass\\Anaconda3\\envs\\masterthesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m FFN(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   (first): Sequential(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (0): Linear(in_features=15, out_features=50, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (1): ReLU()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   )\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   (middle): Sequential(\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (1): ReLU(inplace=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (2): Dropout(p=0.5, inplace=False)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (4): ReLU(inplace=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (5): Dropout(p=0.5, inplace=False)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (7): ReLU(inplace=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m     (8): Dropout(p=0.5, inplace=False)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   )\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   (last): Linear(in_features=50, out_features=2, bias=True)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   (train_acc): Accuracy()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   (train_bal_acc): Accuracy()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   (val_acc): Accuracy()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   (val_bal_acc): Accuracy()\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m )\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:24 (running for 00:02:44.04)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:29 (running for 00:02:49.07)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:34 (running for 00:02:54.10)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:40 (running for 00:02:59.13)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:45 (running for 00:03:04.16)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:50 (running for 00:03:09.20)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:42:55 (running for 00:03:14.24)\n",
      "Memory usage on this node: 8.8/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m class_weights: tensor([1.5913, 2.6912])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m device of class_weights: cpu\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m ---\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m # of input data: 3823386 with shape: (3823386, 17)\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m # of training samples: 38419 with X_train of shape: torch.Size([38419, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m # of validation samples: 50879 with X_val of shape: torch.Size([50879, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m # of test samples: 3734088 with X_test of shape: torch.Size([3734088, 15])\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m train start date:  1996-01-31 , train end date:  1996-12-31\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m val start date:  1997-01-31 , val end date:  1997-12-31\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m test start date:  1998-01-31 , test end date:  2021-11-30\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m ---\n",
      "Sanity Checking: 0it [00:00, ?it/s])\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m   | Name          | Type       | Params\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m ---------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 0 | first         | Sequential | 800   \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 1 | middle        | Sequential | 7.7 K \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 2 | last          | Linear     | 102   \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 3 | train_acc     | Accuracy   | 0     \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 4 | train_bal_acc | Accuracy   | 0     \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 5 | val_acc       | Accuracy   | 0     \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 6 | val_bal_acc   | Accuracy   | 0     \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m ---------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 8.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 8.6 K     Total params\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m 0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/176 [00:00<?, ?it/s]                           \n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:43:00 (running for 00:03:19.27)\n",
      "Memory usage on this node: 10.7/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 3/176 [00:02<02:37,  1.10it/s, loss=0.692, v_num=., loss/loss=0.690]\n",
      "Epoch 0:   7%|▋         | 12/176 [00:02<00:38,  4.21it/s, loss=0.692, v_num=., loss/loss=0.681]\n",
      "Epoch 0:  11%|█▏        | 20/176 [00:02<00:23,  6.74it/s, loss=0.692, v_num=., loss/loss=0.684]\n",
      "Epoch 0:  12%|█▏        | 21/176 [00:02<00:21,  7.05it/s, loss=0.691, v_num=., loss/loss=0.675]\n",
      "Epoch 0:  18%|█▊        | 32/176 [00:03<00:13, 10.35it/s, loss=0.69, v_num=., loss/loss=0.708] \n",
      "Epoch 0:  19%|█▉        | 33/176 [00:03<00:13, 10.64it/s, loss=0.689, v_num=., loss/loss=0.702]\n",
      "Epoch 0:  24%|██▍       | 43/176 [00:03<00:09, 13.39it/s, loss=0.693, v_num=., loss/loss=0.688]\n",
      "Epoch 0:  25%|██▌       | 44/176 [00:03<00:09, 13.65it/s, loss=0.693, v_num=., loss/loss=0.689]\n",
      "Epoch 0:  31%|███▏      | 55/176 [00:03<00:07, 16.45it/s, loss=0.694, v_num=., loss/loss=0.690]\n",
      "Epoch 0:  31%|███▏      | 55/176 [00:03<00:07, 16.45it/s, loss=0.694, v_num=., loss/loss=0.691]\n",
      "Epoch 0:  32%|███▏      | 56/176 [00:03<00:07, 16.69it/s, loss=0.694, v_num=., loss/loss=0.691]\n",
      "Epoch 0:  32%|███▏      | 56/176 [00:03<00:07, 16.69it/s, loss=0.694, v_num=., loss/loss=0.688]\n",
      "Epoch 0:  38%|███▊      | 67/176 [00:03<00:05, 19.28it/s, loss=0.701, v_num=., loss/loss=0.853]\n",
      "Epoch 0:  43%|████▎     | 76/176 [00:03<00:04, 21.32it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A92)\u001b[0m \n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:43:05 (running for 00:03:24.32)\n",
      "Memory usage on this node: 11.0/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6931675672531128\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |            |               |             |                      |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Validation:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  44%|████▍     | 77/176 [00:06<00:08, 11.54it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  44%|████▍     | 78/176 [00:06<00:08, 11.68it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  45%|████▍     | 79/176 [00:06<00:08, 11.82it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  45%|████▌     | 80/176 [00:06<00:08, 11.95it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  46%|████▌     | 81/176 [00:06<00:07, 12.09it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  47%|████▋     | 82/176 [00:06<00:07, 12.23it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  47%|████▋     | 83/176 [00:06<00:07, 12.36it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  48%|████▊     | 84/176 [00:06<00:07, 12.50it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  48%|████▊     | 85/176 [00:06<00:07, 12.63it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  49%|████▉     | 86/176 [00:06<00:07, 12.77it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  49%|████▉     | 87/176 [00:06<00:06, 12.90it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  50%|█████     | 88/176 [00:06<00:06, 13.04it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  51%|█████     | 89/176 [00:06<00:06, 13.17it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  51%|█████     | 90/176 [00:06<00:06, 13.31it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Validation DataLoader 0:  15%|█▌        | 15/100 [00:00<00:00, 139.30it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 91/176 [00:06<00:06, 13.44it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Epoch 0:  52%|█████▏    | 92/176 [00:06<00:06, 13.57it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  53%|█████▎    | 93/176 [00:06<00:06, 13.70it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  53%|█████▎    | 94/176 [00:06<00:05, 13.84it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  54%|█████▍    | 95/176 [00:06<00:05, 13.97it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  55%|█████▍    | 96/176 [00:06<00:05, 14.10it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  55%|█████▌    | 97/176 [00:06<00:05, 14.23it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  56%|█████▌    | 98/176 [00:06<00:05, 14.37it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  56%|█████▋    | 99/176 [00:06<00:05, 14.50it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  57%|█████▋    | 100/176 [00:06<00:05, 14.63it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  57%|█████▋    | 101/176 [00:06<00:05, 14.76it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  58%|█████▊    | 102/176 [00:06<00:04, 14.89it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  59%|█████▊    | 103/176 [00:06<00:04, 15.02it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  59%|█████▉    | 104/176 [00:06<00:04, 15.15it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  60%|█████▉    | 105/176 [00:06<00:04, 15.28it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Validation DataLoader 0:  30%|███       | 30/100 [00:00<00:00, 139.36it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 106/176 [00:06<00:04, 15.41it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  61%|██████    | 107/176 [00:06<00:04, 15.54it/s, loss=0.706, v_num=., loss/loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 32/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  61%|██████▏   | 108/176 [00:06<00:04, 15.66it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 33/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  62%|██████▏   | 109/176 [00:06<00:04, 15.79it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▍      | 34/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  62%|██████▎   | 110/176 [00:06<00:04, 15.92it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▌      | 35/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  63%|██████▎   | 111/176 [00:06<00:04, 16.05it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 36/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  64%|██████▎   | 112/176 [00:06<00:03, 16.18it/s, loss=0.706, v_num=., loss/loss=0.701]\r",
      "Epoch 0:  64%|██████▎   | 112/176 [00:06<00:03, 16.18it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 37/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  64%|██████▍   | 113/176 [00:06<00:03, 16.31it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 38/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  65%|██████▍   | 114/176 [00:06<00:03, 16.43it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▉      | 39/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  65%|██████▌   | 115/176 [00:06<00:03, 16.56it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  40%|████      | 40/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  66%|██████▌   | 116/176 [00:06<00:03, 16.69it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 41/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  66%|██████▋   | 117/176 [00:06<00:03, 16.82it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 42/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  67%|██████▋   | 118/176 [00:06<00:03, 16.94it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 43/100 [00:00<00:00, 139.36it/s]\u001b[A\r",
      "Epoch 0:  68%|██████▊   | 119/176 [00:06<00:03, 17.06it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 44/100 [00:00<00:00, 137.90it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 44/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  68%|██████▊   | 120/176 [00:06<00:03, 17.19it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▌     | 45/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  69%|██████▉   | 121/176 [00:06<00:03, 17.31it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 46/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  69%|██████▉   | 122/176 [00:06<00:03, 17.43it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 47/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  70%|██████▉   | 123/176 [00:07<00:03, 17.56it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 48/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  70%|███████   | 124/176 [00:07<00:02, 17.68it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▉     | 49/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  71%|███████   | 125/176 [00:07<00:02, 17.81it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  50%|█████     | 50/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  72%|███████▏  | 126/176 [00:07<00:02, 17.93it/s, loss=0.706, v_num=., loss/loss=0.701]\r",
      "Epoch 0:  72%|███████▏  | 126/176 [00:07<00:02, 17.93it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████     | 51/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  72%|███████▏  | 127/176 [00:07<00:02, 18.05it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  52%|█████▏    | 52/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  73%|███████▎  | 128/176 [00:07<00:02, 18.18it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  53%|█████▎    | 53/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  73%|███████▎  | 129/176 [00:07<00:02, 18.30it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  54%|█████▍    | 54/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  74%|███████▍  | 130/176 [00:07<00:02, 18.42it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  55%|█████▌    | 55/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  74%|███████▍  | 131/176 [00:07<00:02, 18.55it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  56%|█████▌    | 56/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  75%|███████▌  | 132/176 [00:07<00:02, 18.67it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 57/100 [00:00<00:00, 137.90it/s]\u001b[A\r",
      "Epoch 0:  76%|███████▌  | 133/176 [00:07<00:02, 18.79it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 58/100 [00:00<00:00, 137.56it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 58/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  76%|███████▌  | 134/176 [00:07<00:02, 18.92it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  59%|█████▉    | 59/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  77%|███████▋  | 135/176 [00:07<00:02, 19.04it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  60%|██████    | 60/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  77%|███████▋  | 136/176 [00:07<00:02, 19.16it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  61%|██████    | 61/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  78%|███████▊  | 137/176 [00:07<00:02, 19.28it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  62%|██████▏   | 62/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  78%|███████▊  | 138/176 [00:07<00:01, 19.40it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 63/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  79%|███████▉  | 139/176 [00:07<00:01, 19.52it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  64%|██████▍   | 64/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  80%|███████▉  | 140/176 [00:07<00:01, 19.64it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  65%|██████▌   | 65/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  80%|████████  | 141/176 [00:07<00:01, 19.76it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Epoch 0:  80%|████████  | 141/176 [00:07<00:01, 19.76it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  66%|██████▌   | 66/100 [00:00<00:00, 137.56it/s]\u001b[A\r",
      "Epoch 0:  81%|████████  | 142/176 [00:07<00:01, 19.88it/s, loss=0.706, v_num=., loss/loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Epoch 0:  81%|████████▏ | 143/176 [00:07<00:01, 20.00it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  82%|████████▏ | 144/176 [00:07<00:01, 20.12it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  82%|████████▏ | 145/176 [00:07<00:01, 20.24it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  83%|████████▎ | 146/176 [00:07<00:01, 20.36it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  84%|████████▎ | 147/176 [00:07<00:01, 20.48it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Validation DataLoader 0:  72%|███████▏  | 72/100 [00:00<00:00, 137.39it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 148/176 [00:07<00:01, 20.60it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  85%|████████▍ | 149/176 [00:07<00:01, 20.71it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  85%|████████▌ | 150/176 [00:07<00:01, 20.83it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  86%|████████▌ | 151/176 [00:07<00:01, 20.95it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  86%|████████▋ | 152/176 [00:07<00:01, 21.06it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  87%|████████▋ | 153/176 [00:07<00:01, 21.17it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  88%|████████▊ | 154/176 [00:07<00:01, 21.27it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  88%|████████▊ | 155/176 [00:07<00:00, 21.37it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Epoch 0:  89%|████████▊ | 156/176 [00:07<00:00, 21.47it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Epoch 0:  89%|████████▉ | 157/176 [00:07<00:00, 21.55it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  90%|████████▉ | 158/176 [00:07<00:00, 21.66it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  90%|█████████ | 159/176 [00:07<00:00, 21.77it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  91%|█████████ | 160/176 [00:07<00:00, 21.88it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  91%|█████████▏| 161/176 [00:07<00:00, 22.00it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Validation DataLoader 0:  86%|████████▌ | 86/100 [00:00<00:00, 122.44it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 162/176 [00:07<00:00, 22.12it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  93%|█████████▎| 163/176 [00:07<00:00, 22.24it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  93%|█████████▎| 164/176 [00:07<00:00, 22.35it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  94%|█████████▍| 165/176 [00:07<00:00, 22.47it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  94%|█████████▍| 166/176 [00:07<00:00, 22.58it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  95%|█████████▍| 167/176 [00:07<00:00, 22.70it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  95%|█████████▌| 168/176 [00:07<00:00, 22.81it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  96%|█████████▌| 169/176 [00:07<00:00, 22.93it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  97%|█████████▋| 170/176 [00:07<00:00, 23.05it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Epoch 0:  97%|█████████▋| 171/176 [00:07<00:00, 23.16it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Result for train_mnist_tune_56334_00001:\n",
      "  date: 2022-07-13_10-43-06\n",
      "  done: false\n",
      "  experiment_id: 1d858cb031d04337b1bb928bb3909bf7\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.7005347013473511\n",
      "  mean_pred: 0.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 3692\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 77.6904456615448\n",
      "  time_this_iter_s: 77.6904456615448\n",
      "  time_total_s: 77.6904456615448\n",
      "  timestamp: 1657701786\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '56334_00001'\n",
      "  val_bal_acc: 0.5\n",
      "  val_loss: 0.692834734916687\n",
      "  warmup_time: 0.003997087478637695\n",
      "  \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Epoch 0:  98%|█████████▊| 172/176 [00:07<00:00, 23.28it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  98%|█████████▊| 173/176 [00:07<00:00, 23.39it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  99%|█████████▉| 174/176 [00:07<00:00, 23.51it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0:  99%|█████████▉| 175/176 [00:07<00:00, 23.63it/s, loss=0.706, v_num=., loss/loss=0.701]\n",
      "Epoch 0: 100%|██████████| 176/176 [00:07<00:00, 23.66it/s, loss=0.706, v_num=., loss/loss=0.701, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500]\n",
      "Epoch 1:   0%|          | 0/176 [00:00<?, ?it/s, loss=0.706, v_num=., loss/loss=0.701, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]          \n",
      "Epoch 1:   2%|▏         | 4/176 [00:04<02:57,  1.03s/it, loss=0.708, v_num=., loss/loss=0.693, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:   8%|▊         | 14/176 [00:04<00:49,  3.30it/s, loss=0.692, v_num=., loss/loss=0.688, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  14%|█▍        | 25/176 [00:04<00:26,  5.72it/s, loss=0.689, v_num=., loss/loss=0.672, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  20%|██        | 36/176 [00:04<00:17,  8.02it/s, loss=0.693, v_num=., loss/loss=0.696, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  27%|██▋       | 47/176 [00:04<00:12, 10.20it/s, loss=0.696, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  27%|██▋       | 48/176 [00:04<00:12, 10.39it/s, loss=0.697, v_num=., loss/loss=0.694, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  33%|███▎      | 58/176 [00:04<00:09, 12.26it/s, loss=0.694, v_num=., loss/loss=0.693, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  34%|███▎      | 59/176 [00:04<00:09, 12.45it/s, loss=0.694, v_num=., loss/loss=0.697, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  40%|███▉      | 70/176 [00:04<00:07, 14.41it/s, loss=0.695, v_num=., loss/loss=0.693, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  43%|████▎     | 76/176 [00:04<00:06, 15.45it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:43:11 (running for 00:03:30.92)\n",
      "Memory usage on this node: 11.2/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.6931039690971375 | Iter 1.000: -0.6930011510848999\n",
      "Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00001 with val_loss=0.692834734916687 and parameters={'hidden_dim': 50, 'lr': 0.006173770394704579, 'batch_size': 512}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00001 | RUNNING    | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |   0.692835 |           0.5 |           0 |                    1 |\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A92)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Validation:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 77/176 [00:07<00:10,  9.63it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  44%|████▍     | 78/176 [00:08<00:10,  9.75it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  45%|████▍     | 79/176 [00:08<00:09,  9.87it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  45%|████▌     | 80/176 [00:08<00:09,  9.98it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  46%|████▌     | 81/176 [00:08<00:09, 10.10it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Epoch 1:  47%|████▋     | 82/176 [00:08<00:09, 10.22it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "Epoch 1:  47%|████▋     | 83/176 [00:08<00:09, 10.33it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  48%|████▊     | 84/176 [00:08<00:08, 10.44it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  48%|████▊     | 85/176 [00:08<00:08, 10.56it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  49%|████▉     | 86/176 [00:08<00:08, 10.67it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  49%|████▉     | 87/176 [00:08<00:08, 10.79it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  50%|█████     | 88/176 [00:08<00:08, 10.90it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  51%|█████     | 89/176 [00:08<00:07, 11.02it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Validation DataLoader 0:  14%|█▍        | 14/100 [00:00<00:00, 134.89it/s]\u001b[A\n",
      "Epoch 1:  51%|█████     | 90/176 [00:08<00:07, 11.13it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  52%|█████▏    | 91/176 [00:08<00:07, 11.24it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  52%|█████▏    | 92/176 [00:08<00:07, 11.36it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  53%|█████▎    | 93/176 [00:08<00:07, 11.47it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  53%|█████▎    | 94/176 [00:08<00:07, 11.58it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  54%|█████▍    | 95/176 [00:08<00:06, 11.69it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  55%|█████▍    | 96/176 [00:08<00:06, 11.81it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  55%|█████▌    | 97/176 [00:08<00:06, 11.92it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Epoch 1:  56%|█████▌    | 98/176 [00:08<00:06, 12.03it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  23%|██▎       | 23/100 [00:00<00:00, 134.89it/s]\u001b[A\r",
      "Epoch 1:  56%|█████▋    | 99/176 [00:08<00:06, 12.14it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  24%|██▍       | 24/100 [00:00<00:00, 134.89it/s]\u001b[A\r",
      "Epoch 1:  57%|█████▋    | 100/176 [00:08<00:06, 12.25it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  25%|██▌       | 25/100 [00:00<00:00, 134.89it/s]\u001b[A\r",
      "Epoch 1:  57%|█████▋    | 101/176 [00:08<00:06, 12.36it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  26%|██▌       | 26/100 [00:00<00:00, 134.89it/s]\u001b[A\r",
      "Epoch 1:  58%|█████▊    | 102/176 [00:08<00:05, 12.48it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  27%|██▋       | 27/100 [00:00<00:00, 134.89it/s]\u001b[A\r",
      "Epoch 1:  59%|█████▊    | 103/176 [00:08<00:05, 12.59it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 28/100 [00:00<00:00, 135.95it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  28%|██▊       | 28/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  59%|█████▉    | 104/176 [00:08<00:05, 12.70it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  29%|██▉       | 29/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  60%|█████▉    | 105/176 [00:08<00:05, 12.81it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\r",
      "Epoch 1:  60%|█████▉    | 105/176 [00:08<00:05, 12.81it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  30%|███       | 30/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  60%|██████    | 106/176 [00:08<00:05, 12.92it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  31%|███       | 31/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  61%|██████    | 107/176 [00:08<00:05, 13.03it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  32%|███▏      | 32/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  61%|██████▏   | 108/176 [00:08<00:05, 13.14it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  33%|███▎      | 33/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  62%|██████▏   | 109/176 [00:08<00:05, 13.25it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  34%|███▍      | 34/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  62%|██████▎   | 110/176 [00:08<00:04, 13.36it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  35%|███▌      | 35/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  63%|██████▎   | 111/176 [00:08<00:04, 13.47it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  36%|███▌      | 36/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  64%|██████▎   | 112/176 [00:08<00:04, 13.58it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  37%|███▋      | 37/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  64%|██████▍   | 113/176 [00:08<00:04, 13.68it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  38%|███▊      | 38/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  65%|██████▍   | 114/176 [00:08<00:04, 13.79it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  39%|███▉      | 39/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  65%|██████▌   | 115/176 [00:08<00:04, 13.90it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  40%|████      | 40/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  66%|██████▌   | 116/176 [00:08<00:04, 14.00it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  41%|████      | 41/100 [00:00<00:00, 135.95it/s]\u001b[A\r",
      "Epoch 1:  66%|██████▋   | 117/176 [00:08<00:04, 14.11it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 42/100 [00:00<00:00, 131.46it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  42%|████▏     | 42/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  67%|██████▋   | 118/176 [00:08<00:04, 14.22it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  43%|████▎     | 43/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  68%|██████▊   | 119/176 [00:08<00:03, 14.32it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  44%|████▍     | 44/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  68%|██████▊   | 120/176 [00:08<00:03, 14.43it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\r",
      "Epoch 1:  68%|██████▊   | 120/176 [00:08<00:03, 14.43it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  45%|████▌     | 45/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  69%|██████▉   | 121/176 [00:08<00:03, 14.54it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  46%|████▌     | 46/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  69%|██████▉   | 122/176 [00:08<00:03, 14.65it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  47%|████▋     | 47/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  70%|██████▉   | 123/176 [00:08<00:03, 14.76it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  48%|████▊     | 48/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  70%|███████   | 124/176 [00:08<00:03, 14.86it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  49%|████▉     | 49/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  71%|███████   | 125/176 [00:08<00:03, 14.97it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  50%|█████     | 50/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  72%|███████▏  | 126/176 [00:08<00:03, 15.08it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  51%|█████     | 51/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  72%|███████▏  | 127/176 [00:08<00:03, 15.19it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  52%|█████▏    | 52/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  73%|███████▎  | 128/176 [00:08<00:03, 15.29it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  53%|█████▎    | 53/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  73%|███████▎  | 129/176 [00:08<00:03, 15.40it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  54%|█████▍    | 54/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  74%|███████▍  | 130/176 [00:08<00:02, 15.50it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  55%|█████▌    | 55/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  74%|███████▍  | 131/176 [00:08<00:02, 15.61it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  56%|█████▌    | 56/100 [00:00<00:00, 131.46it/s]\u001b[A\r",
      "Epoch 1:  75%|███████▌  | 132/176 [00:08<00:02, 15.71it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 57/100 [00:00<00:00, 135.04it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  57%|█████▋    | 57/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  76%|███████▌  | 133/176 [00:08<00:02, 15.82it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  58%|█████▊    | 58/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  76%|███████▌  | 134/176 [00:08<00:02, 15.93it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  59%|█████▉    | 59/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  77%|███████▋  | 135/176 [00:08<00:02, 16.03it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\r",
      "Epoch 1:  77%|███████▋  | 135/176 [00:08<00:02, 16.03it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  60%|██████    | 60/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  77%|███████▋  | 136/176 [00:08<00:02, 16.14it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  61%|██████    | 61/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  78%|███████▊  | 137/176 [00:08<00:02, 16.24it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  62%|██████▏   | 62/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  78%|███████▊  | 138/176 [00:08<00:02, 16.35it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  63%|██████▎   | 63/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  79%|███████▉  | 139/176 [00:08<00:02, 16.45it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  64%|██████▍   | 64/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  80%|███████▉  | 140/176 [00:08<00:02, 16.55it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  65%|██████▌   | 65/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  80%|████████  | 141/176 [00:08<00:02, 16.66it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  66%|██████▌   | 66/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  81%|████████  | 142/176 [00:08<00:02, 16.76it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  67%|██████▋   | 67/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  81%|████████▏ | 143/176 [00:08<00:01, 16.87it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  68%|██████▊   | 68/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  82%|████████▏ | 144/176 [00:08<00:01, 16.97it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  69%|██████▉   | 69/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  82%|████████▏ | 145/176 [00:08<00:01, 17.07it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  70%|███████   | 70/100 [00:00<00:00, 135.04it/s]\u001b[A\r",
      "Epoch 1:  83%|████████▎ | 146/176 [00:08<00:01, 17.17it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  71%|███████   | 71/100 [00:00<00:00, 135.21it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  71%|███████   | 71/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  84%|████████▎ | 147/176 [00:08<00:01, 17.27it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  72%|███████▏  | 72/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  84%|████████▍ | 148/176 [00:08<00:01, 17.38it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  73%|███████▎  | 73/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  85%|████████▍ | 149/176 [00:08<00:01, 17.48it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  74%|███████▍  | 74/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  85%|████████▌ | 150/176 [00:08<00:01, 17.57it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\r",
      "Epoch 1:  85%|████████▌ | 150/176 [00:08<00:01, 17.57it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  75%|███████▌  | 75/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  86%|████████▌ | 151/176 [00:08<00:01, 17.66it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  76%|███████▌  | 76/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  86%|████████▋ | 152/176 [00:08<00:01, 17.75it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  77%|███████▋  | 77/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  87%|████████▋ | 153/176 [00:08<00:01, 17.84it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  78%|███████▊  | 78/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  88%|████████▊ | 154/176 [00:08<00:01, 17.94it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  79%|███████▉  | 79/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  88%|████████▊ | 155/176 [00:08<00:01, 18.04it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  80%|████████  | 80/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  89%|████████▊ | 156/176 [00:08<00:01, 18.13it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  81%|████████  | 81/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  89%|████████▉ | 157/176 [00:08<00:01, 18.23it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  82%|████████▏ | 82/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  90%|████████▉ | 158/176 [00:08<00:00, 18.33it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  83%|████████▎ | 83/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  90%|█████████ | 159/176 [00:08<00:00, 18.43it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  84%|████████▍ | 84/100 [00:00<00:00, 135.21it/s]\u001b[A\r",
      "Epoch 1:  91%|█████████ | 160/176 [00:08<00:00, 18.53it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 10:43:15,663\tINFO tune.py:747 -- Total run time: 214.85 seconds (214.68 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  85%|████████▌ | 85/100 [00:00<00:00, 123.63it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  85%|████████▌ | 85/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  91%|█████████▏| 161/176 [00:08<00:00, 18.63it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  86%|████████▌ | 86/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  92%|█████████▏| 162/176 [00:08<00:00, 18.73it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  87%|████████▋ | 87/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  93%|█████████▎| 163/176 [00:08<00:00, 18.83it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  88%|████████▊ | 88/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  93%|█████████▎| 164/176 [00:08<00:00, 18.92it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  89%|████████▉ | 89/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  94%|█████████▍| 165/176 [00:08<00:00, 19.02it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\r",
      "Epoch 1:  94%|█████████▍| 165/176 [00:08<00:00, 19.02it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  90%|█████████ | 90/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  94%|█████████▍| 166/176 [00:08<00:00, 19.13it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  91%|█████████ | 91/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  95%|█████████▍| 167/176 [00:08<00:00, 19.23it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  92%|█████████▏| 92/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  95%|█████████▌| 168/176 [00:08<00:00, 19.33it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  93%|█████████▎| 93/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  96%|█████████▌| 169/176 [00:08<00:00, 19.42it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  94%|█████████▍| 94/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  97%|█████████▋| 170/176 [00:08<00:00, 19.52it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  95%|█████████▌| 95/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  97%|█████████▋| 171/176 [00:08<00:00, 19.62it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  96%|█████████▌| 96/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  98%|█████████▊| 172/176 [00:08<00:00, 19.72it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  97%|█████████▋| 97/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  98%|█████████▊| 173/176 [00:08<00:00, 19.82it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  98%|█████████▊| 98/100 [00:00<00:00, 123.63it/s]\u001b[A\r",
      "Epoch 1:  99%|█████████▉| 174/176 [00:08<00:00, 19.91it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  99%|█████████▉| 99/100 [00:00<00:00, 127.30it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0:  99%|█████████▉| 99/100 [00:00<00:00, 127.30it/s]\u001b[A\r",
      "Epoch 1:  99%|█████████▉| 175/176 [00:08<00:00, 20.01it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "\u001b[2m\u001b[36m(train_mnist_tune pid=3692)\u001b[0m \r",
      "Validation DataLoader 0: 100%|██████████| 100/100 [00:00<00:00, 127.30it/s]\u001b[A\r",
      "Epoch 1: 100%|██████████| 176/176 [00:08<00:00, 20.11it/s, loss=0.693, v_num=., loss/loss=0.692, mean_pred=0.000, loss/val_loss=0.693, bal_acc/val=0.500, bal_acc/train=0.527]\n",
      "Result for train_mnist_tune_56334_00001:\n",
      "  date: 2022-07-13_10-43-15\n",
      "  done: true\n",
      "  experiment_id: 1d858cb031d04337b1bb928bb3909bf7\n",
      "  hostname: Mathias\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6921765804290771\n",
      "  mean_pred: 1.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 3692\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 86.47560214996338\n",
      "  time_this_iter_s: 8.785156488418579\n",
      "  time_total_s: 86.47560214996338\n",
      "  timestamp: 1657701795\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: '56334_00001'\n",
      "  val_bal_acc: 0.5\n",
      "  val_loss: 0.6936604380607605\n",
      "  warmup_time: 0.003997087478637695\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-13 10:43:15 (running for 00:03:34.69)\n",
      "Memory usage on this node: 11.2/15.9 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 4.000: -0.6931052803993225 | Iter 2.000: -0.693382203578949 | Iter 1.000: -0.6930011510848999\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/5.86 GiB heap, 0.0/2.93 GiB objects\n",
      "Current best trial: 56334_00000 with val_loss=0.6931052803993225 and parameters={'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Result logdir: C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\n",
      "Number of trials: 2/2 (2 TERMINATED)\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "| Trial name                   | status     | loc            |   hidden_dim |         lr |   batch_size |   val_loss |   val_bal_acc |   mean_pred |   training_iteration |\n",
      "|------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------|\n",
      "| train_mnist_tune_56334_00000 | TERMINATED | 127.0.0.1:1268 |           50 | 0.0245261  |          256 |   0.693105 |           0.5 |           1 |                    5 |\n",
      "| train_mnist_tune_56334_00001 | TERMINATED | 127.0.0.1:3692 |           50 | 0.00617377 |          512 |   0.69366  |           0.5 |           1 |                    2 |\n",
      "+------------------------------+------------+----------------+--------------+------------+--------------+------------+---------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Best hyperparameters found were:  {'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Best trial config: {'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
      "Best trial >>last<< validation loss: 0.6931052803993225\n",
      "Best trial >>last epoch<< validation accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "result = tune_mnist_asha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e03ce86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = result.get_best_trial(\"val_loss\", \"min\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c6270e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eee66289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_best_config(\"val_loss\", \"min\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1757c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6349f796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_pred</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_bal_acc</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>...</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/hidden_dim</th>\n",
       "      <th>config/lr</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692835</td>\n",
       "      <td>0.5</td>\n",
       "      <td>77.690446</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>77.690446</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>512</td>\n",
       "      <td>50</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.693435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693104</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.196540</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Mathias</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>88.448274</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>C:\\Users\\Mathiass\\Documents\\Projects\\master-th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  mean_pred  val_loss  val_bal_acc  time_this_iter_s  \\\n",
       "1  0.700535        0.0  0.692835          0.5         77.690446   \n",
       "0  0.693435        1.0  0.693104          0.5         10.196540   \n",
       "\n",
       "   should_checkpoint   done  timesteps_total  episodes_total  \\\n",
       "1               True  False              NaN             NaN   \n",
       "0               True  False              NaN             NaN   \n",
       "\n",
       "   training_iteration  ... hostname    node_ip time_since_restore  \\\n",
       "1                   1  ...  Mathias  127.0.0.1          77.690446   \n",
       "0                   2  ...  Mathias  127.0.0.1          88.448274   \n",
       "\n",
       "   timesteps_since_restore  iterations_since_restore  warmup_time  \\\n",
       "1                        0                         1     0.003997   \n",
       "0                        0                         2     0.004000   \n",
       "\n",
       "  config/batch_size config/hidden_dim  config/lr  \\\n",
       "1               512                50   0.006174   \n",
       "0               256                50   0.024526   \n",
       "\n",
       "                                              logdir  \n",
       "1  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "0  C:\\Users\\Mathiass\\Documents\\Projects\\master-th...  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dataframe(metric=\"val_loss\", mode=\"min\").sort_values(\"val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24034319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6934382319450378,\n",
       " 'mean_pred': 1.0,\n",
       " 'val_loss': 0.6931052803993225,\n",
       " 'val_bal_acc': 0.5,\n",
       " 'time_this_iter_s': 10.033972263336182,\n",
       " 'should_checkpoint': True,\n",
       " 'done': True,\n",
       " 'timesteps_total': None,\n",
       " 'episodes_total': None,\n",
       " 'training_iteration': 5,\n",
       " 'trial_id': '56334_00000',\n",
       " 'experiment_id': '982c1c173bd44ceabdf99b78b60d4d2d',\n",
       " 'date': '2022-07-13_10-41-44',\n",
       " 'timestamp': 1657701704,\n",
       " 'time_total_s': 118.78744840621948,\n",
       " 'pid': 1268,\n",
       " 'hostname': 'Mathias',\n",
       " 'node_ip': '127.0.0.1',\n",
       " 'config': {'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256},\n",
       " 'time_since_restore': 118.78744840621948,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 5,\n",
       " 'warmup_time': 0.004000186920166016,\n",
       " 'experiment_tag': '0_batch_size=256,hidden_dim=50,lr=0.0245'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370d9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed89ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0ddf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4217be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e7c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b8d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = result.dataframe(metric=\"val_loss\", mode=\"min\").sort_values(\"val_loss\").iloc[0, :].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3474be",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1588784",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"2008\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd108530",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca04bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update({\"2009\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b477de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b339965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results = result.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f592143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b4cdb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Checkpoint(persistent, C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\\train_mnist_tune_56334_00001_1_batch_size=512,hidden_dim=50,lr=0.0062_2022-07-13_10-41-44\\checkpoint_epoch=1-step=152\\)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_best_trial(\"val_loss\", \"min\", scope=\"all\").checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886894cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d4302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.get_best_trial().checkpoint.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8febd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_best_trial(\"val_loss\", \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_best_trial(\"val_loss\", \"min\", scope=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad31f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_best_trial(\"val_loss\", \"min\", scope=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0,lr=0.0245_2022-07-09_16-11-58\\checkpoint_epoch=1-step=302\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddfb6488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mathiass\\\\Documents\\\\Projects\\\\master-thesis\\\\notebooks\\\\logs\\\\tune_mnist_asha\\\\train_mnist_tune_56334_00001_1_batch_size=512,hidden_dim=50,lr=0.0062_2022-07-13_10-41-44\\\\checkpoint_epoch=0-step=76\\\\'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_best_checkpoint(result.get_best_trial(\"val_loss\", \"min\", scope=\"all\")).get_internal_representation()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f83c7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mathiass\\\\Documents\\\\Projects\\\\master-thesis\\\\notebooks\\\\logs\\\\tune_mnist_asha\\\\train_mnist_tune_56334_00000_0_batch_size=256,hidden_dim=50,lr=0.0245_2022-07-13_10-39-40\\\\checkpoint_epoch=1-step=302\\\\'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_best_checkpoint(result.get_best_trial(\"val_loss\", \"min\", scope=\"last\")).get_internal_representation()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d9fe697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mathiass\\\\Documents\\\\Projects\\\\master-thesis\\\\notebooks\\\\logs\\\\tune_mnist_asha\\\\train_mnist_tune_56334_00000_0_batch_size=256,hidden_dim=50,lr=0.0245_2022-07-13_10-39-40\\\\checkpoint_epoch=1-step=302\\\\'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_best_checkpoint(result.get_best_trial(), metric=\"val_loss\", mode=\"min\").get_internal_representation()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d88f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_checkpoint.get_internal_representation()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d6f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.default_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf581bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bbd155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = result.get_best_checkpoint(result.get_best_trial(), metric=\"val_loss\", mode=\"min\").get_internal_representation()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ead85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFN.load_from_checkpoint(Path(path)/\"checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efac32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.get_best_trial(\"val_loss\", \"min\", \"last\").checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e978cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FFN()\n",
    "# # trainer = Trainer()\n",
    "# from pathlib import Path\n",
    "# path = Path(r\"C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\\train_mnist_tune_5b9ea_00000_0_batch_size=256,hidden_dim=50,lr=0.0245_2022-07-04_21-20-26\\.\\checkpoints\\epoch=0-val_loss=0.764-val_bacc=0.5235.ckpt\")\n",
    "\n",
    "# # automatically restores model, epoch, step, LR schedulers, apex, etc...\n",
    "# # trainer.fit(model, ckpt_path=path)\n",
    "# model = FFN.load_from_checkpoint(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b66c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_json(r\"C:\\Users\\Mathiass\\Documents\\Projects\\master-thesis\\notebooks\\logs\\tune_mnist_asha\\train_mnist_tune_21877_00000_0_batch_size=256,hidden_dim=50,lr=0.0245_2022-07-05_09-36-06\\result.json\", \n",
    "# lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597279cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe846814",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MyDataModule(\n",
    "path=path_data, \n",
    "dataset=\"small\",\n",
    "#     batch_size=BATCH_SIZE, \n",
    "start_val=\"1998\", \n",
    "start_test=\"1999\",\n",
    "label_fn=\"binary\",\n",
    "config=result.best_config,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "deterministic=True,\n",
    "max_epochs=1,\n",
    "gpus=1,\n",
    "# logger=pl.loggers.TensorBoardLogger(\n",
    "# save_dir=tune.get_trial_dir(), name=\"\", version=\".\"), # SPECIFY SAVE_DIR FOR VALIDATION LOGGING -> default: lightning logs\n",
    "enable_progress_bar=True,\n",
    "# callbacks=[\n",
    "#     tune_callback, \n",
    "#     early_stop_callback\n",
    "# ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfe258",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_result = trainer.validate(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16152f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deafe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters found were:  {'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
    "# Best trial config: {'hidden_dim': 50, 'lr': 0.024526126311336768, 'batch_size': 256}\n",
    "# Best trial >>last<< validation loss: 0.6991798281669617\n",
    "# Best trial >>last epoch<< validation accuracy: 0.5307202339172363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48faa8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084600b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159662dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(\n",
    "#     deterministic=True,\n",
    "#     max_epochs=MAX_EPOCHS,\n",
    "#     gpus=1,\n",
    "#     logger=logger, #=logger or False\n",
    "#     check_val_every_n_epoch=1,\n",
    "#     callbacks=[early_stop_callback, checkpoint_callback], #early stop depends earliest after (patience*check_val_every_n_epoch)\n",
    "#     # enable_checkpointing = False,\n",
    "#     num_sanity_val_steps=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d0fe8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# s_time = time.time()\n",
    "# trainer.fit(model, datamodule=dm)\n",
    "# e_time = time.time()\n",
    "# print(f\"Time to fit: {divmod(e_time - s_time, 60)[0]:2.0f}:{divmod(e_time - s_time, 60)[1]:2.0f}\\\n",
    "#  min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3103b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "init_train = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange((1996+init_train+idx),(2021)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0139fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "years[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f840606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc():\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68038d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[\"abc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"a\", \"b\", \"c\"]\n",
    "for i, k in enumerate(a):\n",
    "    print(i, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce594cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "908bb388",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"test2009\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79572e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1eb4992d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "a.update(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "137ad5de30c222602b906d427f317b23725154a9d2ac1dd9f95e9d3b5697fcc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
